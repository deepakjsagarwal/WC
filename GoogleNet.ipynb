{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:43:39.468094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 10:43:41.833218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50afa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wrapt\n",
    "wrapt.__version__   # should be 1.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/tyagi/Desktop/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TRAIN_IMAGE_COUNT = 8\n",
    "VAL_IMAGE_COUNT = 2\n",
    "TEST_IMAGE_COUNT = 2\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE_BASE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "    \n",
    "FILTER = filter_method(1).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(0).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/V\"+str(variety).zfill(3)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    x_train= x_train + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    y_train = y_train + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    x_val= x_val + np.load(dataset_file_name(v)+\"_val_dataset.npy\").tolist()\n",
    "    y_val = y_val + np.load(dataset_file_name(v)+\"_val_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c752599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, MaxPooling2D, Activation, Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48cd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:])       \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca8be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x,filters_1x1,filters_3x3_reduce,filters_3x3,filters_5x5_reduce,filters_5x5,filters_pool,activation_type='relu'):\n",
    "    path1 = Conv2D(filters_1x1,        (1, 1), padding='same', activation=activation_type)(x)\n",
    "    \n",
    "    path2 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation=activation_type)(x)\n",
    "    path2 = Conv2D(filters_3x3,        (1, 1), padding='same', activation=activation_type)(path2)\n",
    "    \n",
    "    path3 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation=activation_type)(x)\n",
    "    path3 = Conv2D(filters_5x5,        (1, 1), padding='same', activation=activation_type)(path3)\n",
    "    \n",
    "    path4 = MaxPool2D((3, 3),  strides=(1, 1), padding='same')(x)\n",
    "    path4 = Conv2D(filters_pool,       (1, 1), padding='same', activation=activation_type)(path4)\n",
    "    \n",
    "    return tf.concat([path1, path2, path3, path4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686f6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auxiliary_classifier(x,num_classes,activation_type='relu'):\n",
    "    aux = AveragePooling2D((5, 5), strides=3)(x)\n",
    "    aux = Conv2D(128, 1, padding='same', activation=activation_type)(aux)\n",
    "    aux = Flatten()(aux)\n",
    "    aux = Dense(1024, activation=activation_type)(aux)\n",
    "    aux = Dropout(0.7)(aux)\n",
    "    aux = Dense(num_classes, activation='softmax')(aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d8a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogleNetModel(data_num_rows, data_num_cols, num_input_chans=1, num_classes=NUM_VARIETIES, activation_type='relu', dropout_rate=0.0):\n",
    "\n",
    "    inp = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "    input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(inp)\n",
    "    x = Conv2D(64,  7, strides=2, padding='same', activation=activation_type)(input_tensor)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = Conv2D(64,  1, strides=1, padding='same', activation=activation_type)(x)\n",
    "    x = Conv2D(192, 3, strides=1, padding='same', activation=activation_type)(x)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=64 , filters_3x3_reduce=96 , filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=192, filters_3x3_reduce=96 , filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n",
    "    5023\n",
    "    aux1 = auxiliary_classifier(x,num_classes)\n",
    "    \n",
    "    x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n",
    "    \n",
    "    aux2 = auxiliary_classifier(x,num_classes)\n",
    "    \n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs = inp, outputs = [out, aux1, aux2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3528776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoogleNetModel():\n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    activation_type = ACTIVATION_TYPE\n",
    "    wheat_types =  VARIETIES\n",
    "    num_classes = len(wheat_types)\n",
    "    dropout_rate = 0.4\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    x_training = np.array(x_train)\n",
    "    labels_training = np.array(y_train)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_train = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_channel = x_training.shape[3]\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = GoogleNetModel(data_num_rows = N_spatial[0], \n",
    "                           data_num_cols = N_spatial[1],\n",
    "                           num_input_chans = N_channel, \n",
    "                           num_classes = num_classes,\n",
    "                           activation_type = activation_type,\n",
    "                           dropout_rate = dropout_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer=adam_opt, loss=[losses.sparse_categorical_crossentropy,losses.sparse_categorical_crossentropy,losses.sparse_categorical_crossentropy],loss_weights=[1, 0.3, 0.3],metrics=['accuracy'])\n",
    "    print(\"---------Completed---------\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be0c2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df8cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [y_train,y_train,y_train]\n",
    "y_val = [y_val,y_val,y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fd04cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(file_path, data_frame, header=False):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    if not file_exists or not header:\n",
    "        data_frame.to_csv(file_path, index=False, mode='w')\n",
    "    else:\n",
    "        data_frame.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c197541c-df74-4d50-a63a-eb0eab139793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HD 3086', 'PBW 291', 'DBW 187', 'DBW222']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9df49795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c86b54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae202619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:49:29.912235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15500 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:91:00.0, compute capability: 6.1\n",
      "2024-01-19 10:49:29.917147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14934 MB memory:  -> device: 1, name: Quadro P5000, pci bus id: 0000:9b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Completed---------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"GN_\"+\"_IC_\"+str(TRAIN_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "if REMOVE_NOISY_BANDS:\n",
    "    model_name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "if FILTER == \"savgol\":\n",
    "    model_name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "\n",
    "if start_epoch != 1:\n",
    "    model = tf.keras.models.load_model('./GNmodels/'+str(start_epoch-1)+model_name)\n",
    "else:\n",
    "    model = getGoogleNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6025fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b89c2d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resizing (Resizing)            (None, 224, 224, 16  0           ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 64  526912      ['resizing[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 55, 55, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 55, 55, 192)  110784      ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 192)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 27, 27, 96)   18528       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 27, 27, 16)   3088        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 27, 27, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 27, 27, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 27, 27, 128)  12416       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 27, 27, 32)   544         ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 27, 27, 32)   6176        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 27, 27, 256)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 27, 27, 32)   8224        ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 27, 27, 256)  0          ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 27, 27, 192)  24768       ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 27, 27, 96)   3168        ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 27, 27, 64)   16448       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 27, 27, 480)  0           ['conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 480)  0          ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 13, 13, 96)   46176       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 13, 13, 16)   7696        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 480)  0          ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 13, 13, 192)  92352       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 13, 13, 208)  20176       ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 13, 13, 48)   816         ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 13, 13, 64)   30784       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_15[0][0]',              \n",
      "                                                                  'conv2d_17[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]',              \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max_pooling2d_6 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 13, 13, 160)  82080       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 13, 13, 224)  25312       ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_24[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]',              \n",
      "                                                                  'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 13, 13, 256)  33024       ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_28[0][0]',              \n",
      "                                                                  'conv2d_30[0][0]',              \n",
      "                                                                  'conv2d_32[0][0]',              \n",
      "                                                                  'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 13, 13, 144)  73872       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 13, 13, 32)   16416       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 13, 13, 288)  41760       ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 13, 13, 64)   2112        ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (None, 13, 13, 528)  0           ['conv2d_34[0][0]',              \n",
      "                                                                  'conv2d_36[0][0]',              \n",
      "                                                                  'conv2d_38[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 13, 13, 160)  84640       ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 13, 13, 32)   16928       ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 13, 13, 528)  0          ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 13, 13, 256)  135424      ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 13, 13, 320)  51520       ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 13, 13, 128)  4224        ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 13, 13, 128)  67712       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (None, 13, 13, 832)  0           ['conv2d_41[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_45[0][0]',              \n",
      "                                                                  'conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 6, 6, 160)    133280      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 6, 6, 32)     26656       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 6, 6, 832)   0           ['max_pooling2d_10[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 6, 6, 256)    213248      ['max_pooling2d_10[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 6, 6, 320)    51520       ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 6, 6, 128)    4224        ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (None, 6, 6, 832)    0           ['conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_49[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 6, 6, 192)    159936      ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 6, 6, 48)     39984       ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_7[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 3, 3, 512)   0           ['tf.concat_2[0][0]']            \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 3, 3, 528)   0           ['tf.concat_5[0][0]']            \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 6, 6, 384)    319872      ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 6, 6, 384)    74112       ['conv2d_54[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 6, 6, 128)    6272        ['conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 3, 3, 128)    65664       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 128)    67712       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (None, 6, 6, 1024)   0           ['conv2d_53[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]',              \n",
      "                                                                  'conv2d_57[0][0]',              \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1152)         0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1152)         0           ['conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['tf.concat_8[0][0]']            \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         1180672     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1180672     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4)            4100        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            4100        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            4100        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,768,316\n",
      "Trainable params: 5,768,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9576676f-4d83-4ec1-a514-4debb8bcd42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 - 36s - loss: 2.2188 - dense_4_loss: 1.3865 - dense_1_loss: 1.3861 - dense_3_loss: 1.3884 - dense_4_accuracy: 0.2812 - dense_1_accuracy: 0.1562 - dense_3_accuracy: 0.2188 - val_loss: 2.2179 - val_dense_4_loss: 1.3864 - val_dense_1_loss: 1.3858 - val_dense_3_loss: 1.3859 - val_dense_4_accuracy: 0.2500 - val_dense_1_accuracy: 0.2500 - val_dense_3_accuracy: 0.2500 - 36s/epoch - 36s/step\n",
      "INFO:tensorflow:Assets written to: ./GNmodels/1GN__IC_00008_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:49:46.425370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 - 86s - loss: 2.0775 - dense_4_loss: 1.2933 - dense_1_loss: 1.3171 - dense_3_loss: 1.2970 - dense_4_accuracy: 0.3600 - dense_1_accuracy: 0.3739 - dense_3_accuracy: 0.3597 - val_loss: 1.9838 - val_dense_4_loss: 1.2396 - val_dense_1_loss: 1.2600 - val_dense_3_loss: 1.2209 - val_dense_4_accuracy: 0.4069 - val_dense_1_accuracy: 0.4310 - val_dense_3_accuracy: 0.4108 - 86s/epoch - 892ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:51:09.369869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:51:09.379727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:51:09.388012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:51:11.511645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:51:11.533771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:51:11.552446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/1GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/1GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  1\n",
      "added to csv\n",
      "\n",
      "Epoch:  2\n",
      "1/1 - 17s - loss: 2.2200 - dense_4_loss: 1.3848 - dense_1_loss: 1.3900 - dense_3_loss: 1.3940 - dense_4_accuracy: 0.4375 - dense_1_accuracy: 0.1562 - dense_3_accuracy: 0.2500 - val_loss: 2.2178 - val_dense_4_loss: 1.3863 - val_dense_1_loss: 1.3857 - val_dense_3_loss: 1.3859 - val_dense_4_accuracy: 0.2500 - val_dense_1_accuracy: 0.2500 - val_dense_3_accuracy: 0.2500 - 17s/epoch - 17s/step\n",
      "INFO:tensorflow:Assets written to: ./GNmodels/2GN__IC_00008_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:52:27.932959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:52:27.943688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:52:27.951908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:52:30.067965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:52:30.091446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 10:52:30.111600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/2GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/2GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  2\n",
      "added to csv\n",
      "Testing time (s) = 74.72765760001494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, validation_data=(x_val, y_val), shuffle=True)\n",
    "    model.save('./GNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8c251fd-8adb-4bed-8a7a-8316d98d7d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc2cbb5-bc57-4322-866e-433f491d63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2a62d52-ef94-4f6f-a23c-dcf8ddd36ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.946875\n",
      "Confusion Matrix:\n",
      "[[0 0 2 0]\n",
      " [0 0 2 0]\n",
      " [0 0 2 0]\n",
      " [0 0 2 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.25      1.00      0.40         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.06      0.25      0.10         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n",
      "Accuracy: 0.9505208333333334\n",
      "Confusion Matrix:\n",
      "[[0 2 0 0]\n",
      " [0 2 0 0]\n",
      " [0 2 0 0]\n",
      " [0 1 1 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.29      1.00      0.44         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.07      0.25      0.11         8\n",
      "weighted avg       0.07      0.25      0.11         8\n",
      "\n",
      "Accuracy: 0.9390625\n",
      "Confusion Matrix:\n",
      "[[0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.25      1.00      0.40         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.06      0.25      0.10         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for y_pred_label in y_pred_labels:\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ee2d4c9-75f5-483c-a6b6-3cb71aaa1e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4f072-7dc8-4bee-bfd2-7ec6be9596ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37b60357",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d26d0913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resizing (Resizing)            (None, 224, 224, 16  0           ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 64  526912      ['resizing[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 55, 55, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 55, 55, 192)  110784      ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 192)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 27, 27, 96)   18528       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 27, 27, 16)   3088        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 27, 27, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 27, 27, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 27, 27, 128)  12416       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 27, 27, 32)   544         ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 27, 27, 32)   6176        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 27, 27, 256)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 27, 27, 32)   8224        ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 27, 27, 256)  0          ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 27, 27, 192)  24768       ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 27, 27, 96)   3168        ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 27, 27, 64)   16448       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 27, 27, 480)  0           ['conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 480)  0          ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 13, 13, 96)   46176       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 13, 13, 16)   7696        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 480)  0          ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 13, 13, 192)  92352       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 13, 13, 208)  20176       ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 13, 13, 48)   816         ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 13, 13, 64)   30784       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_15[0][0]',              \n",
      "                                                                  'conv2d_17[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]',              \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max_pooling2d_6 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 13, 13, 160)  82080       ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 13, 13, 224)  25312       ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_24[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]',              \n",
      "                                                                  'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 13, 13, 256)  33024       ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_28[0][0]',              \n",
      "                                                                  'conv2d_30[0][0]',              \n",
      "                                                                  'conv2d_32[0][0]',              \n",
      "                                                                  'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 13, 13, 144)  73872       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 13, 13, 32)   16416       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 13, 13, 288)  41760       ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 13, 13, 64)   2112        ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (None, 13, 13, 528)  0           ['conv2d_34[0][0]',              \n",
      "                                                                  'conv2d_36[0][0]',              \n",
      "                                                                  'conv2d_38[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 13, 13, 160)  84640       ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 13, 13, 32)   16928       ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 13, 13, 528)  0          ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 13, 13, 256)  135424      ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 13, 13, 320)  51520       ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 13, 13, 128)  4224        ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 13, 13, 128)  67712       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (None, 13, 13, 832)  0           ['conv2d_41[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_45[0][0]',              \n",
      "                                                                  'conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 6, 6, 160)    133280      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 6, 6, 32)     26656       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 6, 6, 832)   0           ['max_pooling2d_10[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 6, 6, 256)    213248      ['max_pooling2d_10[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 6, 6, 320)    51520       ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 6, 6, 128)    4224        ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (None, 6, 6, 832)    0           ['conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_49[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 6, 6, 192)    159936      ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 6, 6, 48)     39984       ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_7[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 3, 3, 512)   0           ['tf.concat_2[0][0]']            \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 3, 3, 528)   0           ['tf.concat_5[0][0]']            \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 6, 6, 384)    319872      ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 6, 6, 384)    74112       ['conv2d_54[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 6, 6, 128)    6272        ['conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 3, 3, 128)    65664       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 128)    67712       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (None, 6, 6, 1024)   0           ['conv2d_53[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]',              \n",
      "                                                                  'conv2d_57[0][0]',              \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1152)         0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1152)         0           ['conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['tf.concat_8[0][0]']            \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         1180672     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1180672     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4)            4100        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            4100        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            4100        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,768,316\n",
      "Trainable params: 5,768,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e0786e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  101\n",
      "96/96 - 60s - loss: 0.1239 - dense_4_loss: 0.0693 - dense_1_loss: 0.0960 - dense_3_loss: 0.0860 - dense_4_accuracy: 0.9762 - dense_1_accuracy: 0.9635 - dense_3_accuracy: 0.9697 - val_loss: 0.1445 - val_dense_4_loss: 0.0723 - val_dense_1_loss: 0.1252 - val_dense_3_loss: 0.1155 - val_dense_4_accuracy: 0.9753 - val_dense_1_accuracy: 0.9505 - val_dense_3_accuracy: 0.9577 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:02:21.767184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:02:21.776207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:02:21.784091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:02:24.324544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:02:24.343802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:02:24.362254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/101GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/101GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  101\n",
      "added to csv\n",
      "\n",
      "Epoch:  102\n",
      "96/96 - 60s - loss: 0.0907 - dense_4_loss: 0.0498 - dense_1_loss: 0.0764 - dense_3_loss: 0.0601 - dense_4_accuracy: 0.9844 - dense_1_accuracy: 0.9743 - dense_3_accuracy: 0.9798 - val_loss: 0.1779 - val_dense_4_loss: 0.1043 - val_dense_1_loss: 0.1227 - val_dense_3_loss: 0.1228 - val_dense_4_accuracy: 0.9694 - val_dense_1_accuracy: 0.9583 - val_dense_3_accuracy: 0.9622 - 60s/epoch - 630ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:03:40.609586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:03:40.618349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:03:40.626514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:03:42.627473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:03:42.647533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:03:42.665866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/102GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/102GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  102\n",
      "added to csv\n",
      "\n",
      "Epoch:  103\n",
      "96/96 - 60s - loss: 0.0451 - dense_4_loss: 0.0223 - dense_1_loss: 0.0440 - dense_3_loss: 0.0317 - dense_4_accuracy: 0.9919 - dense_1_accuracy: 0.9827 - dense_3_accuracy: 0.9883 - val_loss: 0.1076 - val_dense_4_loss: 0.0566 - val_dense_1_loss: 0.1001 - val_dense_3_loss: 0.0698 - val_dense_4_accuracy: 0.9811 - val_dense_1_accuracy: 0.9635 - val_dense_3_accuracy: 0.9772 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:04:59.072645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:04:59.081699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:04:59.089827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:05:01.114509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:05:01.134841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:05:01.153703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/103GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/103GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  103\n",
      "added to csv\n",
      "\n",
      "Epoch:  104\n",
      "96/96 - 61s - loss: 0.6767 - dense_4_loss: 0.4151 - dense_1_loss: 0.4648 - dense_3_loss: 0.4072 - dense_4_accuracy: 0.8872 - dense_1_accuracy: 0.8698 - dense_3_accuracy: 0.8792 - val_loss: 0.1370 - val_dense_4_loss: 0.0740 - val_dense_1_loss: 0.1168 - val_dense_3_loss: 0.0932 - val_dense_4_accuracy: 0.9779 - val_dense_1_accuracy: 0.9629 - val_dense_3_accuracy: 0.9714 - 61s/epoch - 630ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:06:17.871676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:06:17.880621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:06:17.888774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:06:19.931089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:06:19.950179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:06:19.968834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/104GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/104GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  104\n",
      "added to csv\n",
      "\n",
      "Epoch:  105\n",
      "96/96 - 60s - loss: 0.1325 - dense_4_loss: 0.0759 - dense_1_loss: 0.1059 - dense_3_loss: 0.0828 - dense_4_accuracy: 0.9705 - dense_1_accuracy: 0.9611 - dense_3_accuracy: 0.9686 - val_loss: 0.0746 - val_dense_4_loss: 0.0379 - val_dense_1_loss: 0.0714 - val_dense_3_loss: 0.0509 - val_dense_4_accuracy: 0.9883 - val_dense_1_accuracy: 0.9753 - val_dense_3_accuracy: 0.9837 - 60s/epoch - 626ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:07:35.569926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:07:35.578732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:07:35.587001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:07:38.147537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:07:38.167743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:07:38.186389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/105GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/105GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  105\n",
      "added to csv\n",
      "\n",
      "Epoch:  106\n",
      "96/96 - 60s - loss: 0.0568 - dense_4_loss: 0.0293 - dense_1_loss: 0.0541 - dense_3_loss: 0.0375 - dense_4_accuracy: 0.9889 - dense_1_accuracy: 0.9811 - dense_3_accuracy: 0.9857 - val_loss: 0.0910 - val_dense_4_loss: 0.0506 - val_dense_1_loss: 0.0692 - val_dense_3_loss: 0.0656 - val_dense_4_accuracy: 0.9824 - val_dense_1_accuracy: 0.9720 - val_dense_3_accuracy: 0.9792 - 60s/epoch - 627ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:08:54.072644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:08:54.082164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:08:54.090248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:08:56.069347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:08:56.089442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:08:56.108002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/106GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/106GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  106\n",
      "added to csv\n",
      "\n",
      "Epoch:  107\n",
      "96/96 - 60s - loss: 0.0856 - dense_4_loss: 0.0482 - dense_1_loss: 0.0675 - dense_3_loss: 0.0572 - dense_4_accuracy: 0.9821 - dense_1_accuracy: 0.9754 - dense_3_accuracy: 0.9793 - val_loss: 0.1061 - val_dense_4_loss: 0.0554 - val_dense_1_loss: 0.0896 - val_dense_3_loss: 0.0794 - val_dense_4_accuracy: 0.9779 - val_dense_1_accuracy: 0.9688 - val_dense_3_accuracy: 0.9701 - 60s/epoch - 629ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:10:12.718642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:10:12.727473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:10:12.735669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:10:14.771692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:10:14.791144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:10:14.809841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/107GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/107GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  107\n",
      "added to csv\n",
      "\n",
      "Epoch:  108\n",
      "96/96 - 60s - loss: 0.1236 - dense_4_loss: 0.0737 - dense_1_loss: 0.0863 - dense_3_loss: 0.0800 - dense_4_accuracy: 0.9824 - dense_1_accuracy: 0.9754 - dense_3_accuracy: 0.9774 - val_loss: 1.0196 - val_dense_4_loss: 0.6549 - val_dense_1_loss: 0.5628 - val_dense_3_loss: 0.6526 - val_dense_4_accuracy: 0.8496 - val_dense_1_accuracy: 0.8457 - val_dense_3_accuracy: 0.8522 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:11:30.730484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:11:30.740275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:11:31.215068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:11:33.234126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:11:33.254616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:11:33.273026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/108GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/108GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  108\n",
      "added to csv\n",
      "\n",
      "Epoch:  109\n",
      "96/96 - 60s - loss: 0.6772 - dense_4_loss: 0.4181 - dense_1_loss: 0.4195 - dense_3_loss: 0.4441 - dense_4_accuracy: 0.8553 - dense_1_accuracy: 0.8696 - dense_3_accuracy: 0.8452 - val_loss: 0.3233 - val_dense_4_loss: 0.1980 - val_dense_1_loss: 0.1962 - val_dense_3_loss: 0.2216 - val_dense_4_accuracy: 0.9271 - val_dense_1_accuracy: 0.9323 - val_dense_3_accuracy: 0.9173 - 60s/epoch - 629ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:12:49.161640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:12:49.170552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:12:49.180451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:12:51.179542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:12:51.675476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:12:51.695696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/109GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/109GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  109\n",
      "added to csv\n",
      "\n",
      "Epoch:  110\n",
      "96/96 - 60s - loss: 0.1055 - dense_4_loss: 0.0578 - dense_1_loss: 0.0780 - dense_3_loss: 0.0809 - dense_4_accuracy: 0.9785 - dense_1_accuracy: 0.9705 - dense_3_accuracy: 0.9723 - val_loss: 0.1405 - val_dense_4_loss: 0.0913 - val_dense_1_loss: 0.0774 - val_dense_3_loss: 0.0864 - val_dense_4_accuracy: 0.9733 - val_dense_1_accuracy: 0.9733 - val_dense_3_accuracy: 0.9701 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:14:08.107139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:14:08.116288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:14:08.124355: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:14:10.174879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:14:10.194529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:14:10.213349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/110GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/110GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  110\n",
      "added to csv\n",
      "\n",
      "Epoch:  111\n",
      "96/96 - 60s - loss: 0.0783 - dense_4_loss: 0.0429 - dense_1_loss: 0.0627 - dense_3_loss: 0.0553 - dense_4_accuracy: 0.9836 - dense_1_accuracy: 0.9777 - dense_3_accuracy: 0.9780 - val_loss: 0.1474 - val_dense_4_loss: 0.0904 - val_dense_1_loss: 0.0915 - val_dense_3_loss: 0.0986 - val_dense_4_accuracy: 0.9596 - val_dense_1_accuracy: 0.9661 - val_dense_3_accuracy: 0.9583 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:15:26.586952: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:15:26.595872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:15:26.604883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:15:28.644089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:15:28.663624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:15:28.682338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/111GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/111GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  111\n",
      "added to csv\n",
      "\n",
      "Epoch:  112\n",
      "96/96 - 61s - loss: 0.0875 - dense_4_loss: 0.0508 - dense_1_loss: 0.0641 - dense_3_loss: 0.0581 - dense_4_accuracy: 0.9821 - dense_1_accuracy: 0.9764 - dense_3_accuracy: 0.9769 - val_loss: 0.0881 - val_dense_4_loss: 0.0514 - val_dense_1_loss: 0.0708 - val_dense_3_loss: 0.0518 - val_dense_4_accuracy: 0.9844 - val_dense_1_accuracy: 0.9701 - val_dense_3_accuracy: 0.9818 - 61s/epoch - 631ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:16:45.108189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:16:45.117299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:16:45.125616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:16:47.604905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:16:47.624734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:16:47.643406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/112GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/112GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  112\n",
      "added to csv\n",
      "\n",
      "Epoch:  113\n",
      "96/96 - 60s - loss: 0.0629 - dense_4_loss: 0.0344 - dense_1_loss: 0.0492 - dense_3_loss: 0.0457 - dense_4_accuracy: 0.9875 - dense_1_accuracy: 0.9813 - dense_3_accuracy: 0.9840 - val_loss: 0.1066 - val_dense_4_loss: 0.0560 - val_dense_1_loss: 0.0934 - val_dense_3_loss: 0.0751 - val_dense_4_accuracy: 0.9818 - val_dense_1_accuracy: 0.9688 - val_dense_3_accuracy: 0.9753 - 60s/epoch - 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:18:03.623383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:18:03.632230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:18:03.640337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:18:05.670174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:18:05.689489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:18:05.708149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/113GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/113GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  113\n",
      "added to csv\n",
      "\n",
      "Epoch:  114\n",
      "96/96 - 60s - loss: 0.0305 - dense_4_loss: 0.0148 - dense_1_loss: 0.0315 - dense_3_loss: 0.0209 - dense_4_accuracy: 0.9948 - dense_1_accuracy: 0.9889 - dense_3_accuracy: 0.9932 - val_loss: 0.0942 - val_dense_4_loss: 0.0556 - val_dense_1_loss: 0.0677 - val_dense_3_loss: 0.0610 - val_dense_4_accuracy: 0.9857 - val_dense_1_accuracy: 0.9785 - val_dense_3_accuracy: 0.9831 - 60s/epoch - 630ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:19:22.655431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:19:22.664458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:19:22.673839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:19:24.706765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:19:24.727020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-01-19 13:19:24.745619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1024]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/114GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./GNmodels/114GN_LR_0.001_BS_64_IC_02400_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  114\n",
      "added to csv\n",
      "\n",
      "Epoch:  115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_epoch\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mlast_epoch:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m,start_epoch)\n\u001b[0;32m----> 4\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./GNmodels/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(start_epoch)\u001b[38;5;241m+\u001b[39mmodel_name)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved on epoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m,start_epoch)\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/keras/engine/training.py:1676\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1674\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1677\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m         ):\n\u001b[1;32m   1684\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/keras/engine/data_adapter.py:1375\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1376\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1377\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1380\u001b[0m )\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:647\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    646\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    649\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1126\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, validation_data=(x_val, y_val), shuffle=True)\n",
    "    model.save('./GNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff316b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_pred_label in y_pred_labels:\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d21b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwheatenv",
   "language": "python",
   "name": "dwheatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
