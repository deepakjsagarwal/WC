{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 00:12:12.590544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-06 00:12:13.843039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/tyagi/Desktop/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TRAIN_IMAGE_COUNT = 1200\n",
    "VAL_IMAGE_COUNT = 400\n",
    "TEST_IMAGE_COUNT = 400\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "LEARNING_RATE_BASE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "    \n",
    "FILTER = filter_method(0).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(0).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/V\"+str(variety).zfill(3)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n",
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    x_train= x_train + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    y_train = y_train + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    x_val= x_val + np.load(dataset_file_name(v)+\"_val_dataset.npy\").tolist()\n",
    "    y_val = y_val + np.load(dataset_file_name(v)+\"_val_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca90232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    print(\"Testing started\")\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "    \n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix_results,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_integer_format, labels_predicted_integer_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb608fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90729707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_block(x, filters, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def identity_block(x, filters):\n",
    "    x_identity = x\n",
    "\n",
    "    x = conv_block(x, filters)\n",
    "    x = layers.Add()([x, x_identity])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), use_bias=False, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = conv_block(x, filters=64, strides=1)\n",
    "    x = identity_block(x, filters=64)\n",
    "\n",
    "    x = conv_block(x, filters=128, strides=2)\n",
    "    x = identity_block(x, filters=128)\n",
    "\n",
    "    x = conv_block(x, filters=256, strides=2)\n",
    "    x = identity_block(x, filters=256)\n",
    "\n",
    "    x = conv_block(x, filters=512, strides=2)\n",
    "    x = identity_block(x, filters=512)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43cde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = np.array(x_train)\n",
    "labels_training = np.array(y_train)\n",
    "\n",
    "# Normalize the data\n",
    "x_training = normalizeDataWholeSeed(x_training,normalization_type='max')\n",
    "x_val_norm = normalizeDataWholeSeed(x_val,normalization_type=\"max\")\n",
    "test_dataset = normalizeDataWholeSeed(test_dataset,normalization_type='max')\n",
    "    \n",
    "# Extract some information\n",
    "num_training = x_training.shape[0]\n",
    "N_spatial = x_training.shape[1:3]\n",
    "N_bands = x_training.shape[3]\n",
    "batch_size = BATCH_SIZE\n",
    "num_batch_per_epoch = int(num_training/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ce95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(file_path, data_frame, header=False):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    if not file_exists or not header:\n",
    "        data_frame.to_csv(file_path, index=False, mode='w')\n",
    "    else:\n",
    "        data_frame.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08349c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HD 3086', 'PBW 291', 'DBW 187', 'DBW222']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9dcaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead0a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 00:19:20.249566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14614 MB memory:  -> device: 1, name: Quadro P5000, pci bus id: 0000:9b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RN_\"+\"_IC_\"+str(TRAIN_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "if REMOVE_NOISY_BANDS:\n",
    "    model_name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "if FILTER == \"savgol\":\n",
    "    model_name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "\n",
    "if start_epoch != 1:\n",
    "    model = tf.keras.models.load_model('./RNmodels/'+str(start_epoch-1)+model_name)\n",
    "else:\n",
    "    \n",
    "    input_shape = (30, 30, 168)\n",
    "    num_classes = 4\n",
    "    model = resnet18(input_shape, num_classes)\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627a2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74535028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 15, 15, 64)   526848      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     36864       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 64)     36864       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    73728       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 128)    147456      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 128)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 4, 4, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 2, 2, 256)    294912      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_10[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 2, 2, 256)    589824      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2, 2, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 1, 1, 512)    1179648     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 512)    2359296     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 1, 512)    0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 1, 1, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            2052        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,529,988\n",
      "Trainable params: 11,522,180\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3324c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 00:19:31.390191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 18s - loss: 1.4775 - acc: 0.3862 - val_loss: 1.8773 - val_acc: 0.4000 - 18s/epoch - 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  1\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.429375\n",
      "Confusion Matrix:\n",
      "[[ 14  12  96 278]\n",
      " [  2 149 181  68]\n",
      " [  5  84 194 117]\n",
      " [  5   2  63 330]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.04      0.07       400\n",
      "           1       0.60      0.37      0.46       400\n",
      "           2       0.36      0.48      0.42       400\n",
      "           3       0.42      0.82      0.55       400\n",
      "\n",
      "    accuracy                           0.43      1600\n",
      "   macro avg       0.48      0.43      0.37      1600\n",
      "weighted avg       0.48      0.43      0.37      1600\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "600/600 - 14s - loss: 1.1340 - acc: 0.4981 - val_loss: 1.1967 - val_acc: 0.4581 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  2\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.411875\n",
      "Confusion Matrix:\n",
      "[[ 89  63 233  15]\n",
      " [  1 267 132   0]\n",
      " [  3 182 214   1]\n",
      " [ 59  29 223  89]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.22      0.32       400\n",
      "           1       0.49      0.67      0.57       400\n",
      "           2       0.27      0.54      0.36       400\n",
      "           3       0.85      0.22      0.35       400\n",
      "\n",
      "    accuracy                           0.41      1600\n",
      "   macro avg       0.55      0.41      0.40      1600\n",
      "weighted avg       0.55      0.41      0.40      1600\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "600/600 - 14s - loss: 0.8905 - acc: 0.6192 - val_loss: 1.0212 - val_acc: 0.5825 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  3\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.609375\n",
      "Confusion Matrix:\n",
      "[[142  37 119 102]\n",
      " [ 19 250 106  25]\n",
      " [ 24 130 222  24]\n",
      " [ 26   4   9 361]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.35      0.46       400\n",
      "           1       0.59      0.62      0.61       400\n",
      "           2       0.49      0.56      0.52       400\n",
      "           3       0.71      0.90      0.79       400\n",
      "\n",
      "    accuracy                           0.61      1600\n",
      "   macro avg       0.61      0.61      0.60      1600\n",
      "weighted avg       0.61      0.61      0.60      1600\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "600/600 - 14s - loss: 0.6354 - acc: 0.7492 - val_loss: 2.0675 - val_acc: 0.3988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  4\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.4275\n",
      "Confusion Matrix:\n",
      "[[338   7  55   0]\n",
      " [138 124 138   0]\n",
      " [170  22 208   0]\n",
      " [371   4  11  14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.84      0.48       400\n",
      "           1       0.79      0.31      0.45       400\n",
      "           2       0.50      0.52      0.51       400\n",
      "           3       1.00      0.04      0.07       400\n",
      "\n",
      "    accuracy                           0.43      1600\n",
      "   macro avg       0.66      0.43      0.38      1600\n",
      "weighted avg       0.66      0.43      0.38      1600\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "600/600 - 14s - loss: 0.4455 - acc: 0.8244 - val_loss: 1.1643 - val_acc: 0.5975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  5\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.533125\n",
      "Confusion Matrix:\n",
      "[[118  73 209   0]\n",
      " [  7 284 109   0]\n",
      " [  3 126 271   0]\n",
      " [ 84  45  91 180]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.39       400\n",
      "           1       0.54      0.71      0.61       400\n",
      "           2       0.40      0.68      0.50       400\n",
      "           3       1.00      0.45      0.62       400\n",
      "\n",
      "    accuracy                           0.53      1600\n",
      "   macro avg       0.62      0.53      0.53      1600\n",
      "weighted avg       0.62      0.53      0.53      1600\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "600/600 - 14s - loss: 0.3380 - acc: 0.8692 - val_loss: 3.3794 - val_acc: 0.3531 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  6\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.3725\n",
      "Confusion Matrix:\n",
      "[[ 13  65 322   0]\n",
      " [  1 238 161   0]\n",
      " [  0  61 339   0]\n",
      " [  4  56 334   6]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.03      0.06       400\n",
      "           1       0.57      0.59      0.58       400\n",
      "           2       0.29      0.85      0.44       400\n",
      "           3       1.00      0.01      0.03       400\n",
      "\n",
      "    accuracy                           0.37      1600\n",
      "   macro avg       0.65      0.37      0.28      1600\n",
      "weighted avg       0.65      0.37      0.28      1600\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "600/600 - 14s - loss: 0.2805 - acc: 0.8956 - val_loss: 0.9397 - val_acc: 0.6600 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  7\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.640625\n",
      "Confusion Matrix:\n",
      "[[178  74 148   0]\n",
      " [ 21 301  78   0]\n",
      " [ 22  90 288   0]\n",
      " [ 69  20  53 258]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.45      0.52       400\n",
      "           1       0.62      0.75      0.68       400\n",
      "           2       0.51      0.72      0.60       400\n",
      "           3       1.00      0.65      0.78       400\n",
      "\n",
      "    accuracy                           0.64      1600\n",
      "   macro avg       0.69      0.64      0.64      1600\n",
      "weighted avg       0.69      0.64      0.64      1600\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "600/600 - 14s - loss: 0.2054 - acc: 0.9283 - val_loss: 3.4802 - val_acc: 0.3787 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  8\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.335625\n",
      "Confusion Matrix:\n",
      "[[ 53 269  78   0]\n",
      " [  4 384  12   0]\n",
      " [  3 297 100   0]\n",
      " [ 68 250  82   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.13      0.20       400\n",
      "           1       0.32      0.96      0.48       400\n",
      "           2       0.37      0.25      0.30       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.34      1600\n",
      "   macro avg       0.28      0.34      0.24      1600\n",
      "weighted avg       0.28      0.34      0.24      1600\n",
      "\n",
      "\n",
      "Epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.1888 - acc: 0.9294 - val_loss: 1.8876 - val_acc: 0.5387 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  9\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.48875\n",
      "Confusion Matrix:\n",
      "[[102 103 195   0]\n",
      " [  5 328  67   0]\n",
      " [  2 128 270   0]\n",
      " [ 54  70 194  82]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.26      0.36       400\n",
      "           1       0.52      0.82      0.64       400\n",
      "           2       0.37      0.68      0.48       400\n",
      "           3       1.00      0.20      0.34       400\n",
      "\n",
      "    accuracy                           0.49      1600\n",
      "   macro avg       0.63      0.49      0.45      1600\n",
      "weighted avg       0.63      0.49      0.45      1600\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "600/600 - 15s - loss: 0.1629 - acc: 0.9406 - val_loss: 3.0103 - val_acc: 0.5537 - 15s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  10\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.58625\n",
      "Confusion Matrix:\n",
      "[[316  27   1  56]\n",
      " [120 214   0  66]\n",
      " [210 103  11  76]\n",
      " [  3   0   0 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.79      0.60       400\n",
      "           1       0.62      0.54      0.58       400\n",
      "           2       0.92      0.03      0.05       400\n",
      "           3       0.67      0.99      0.80       400\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.67      0.59      0.51      1600\n",
      "weighted avg       0.67      0.59      0.51      1600\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "600/600 - 14s - loss: 0.1380 - acc: 0.9490 - val_loss: 3.5805 - val_acc: 0.5475 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  11\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.52\n",
      "Confusion Matrix:\n",
      "[[217 105  78   0]\n",
      " [ 19 336  45   0]\n",
      " [ 20 101 279   0]\n",
      " [189  27 184   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51       400\n",
      "           1       0.59      0.84      0.69       400\n",
      "           2       0.48      0.70      0.57       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.52      1600\n",
      "   macro avg       0.39      0.52      0.44      1600\n",
      "weighted avg       0.39      0.52      0.44      1600\n",
      "\n",
      "\n",
      "Epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.1133 - acc: 0.9585 - val_loss: 8.9380 - val_acc: 0.2669 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  12\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.26625\n",
      "Confusion Matrix:\n",
      "[[  0   1   0 399]\n",
      " [  0  23   0 377]\n",
      " [  0   1   3 396]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       400\n",
      "           1       0.92      0.06      0.11       400\n",
      "           2       1.00      0.01      0.01       400\n",
      "           3       0.25      1.00      0.41       400\n",
      "\n",
      "    accuracy                           0.27      1600\n",
      "   macro avg       0.54      0.27      0.13      1600\n",
      "weighted avg       0.54      0.27      0.13      1600\n",
      "\n",
      "\n",
      "Epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.1104 - acc: 0.9633 - val_loss: 3.1778 - val_acc: 0.4475 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  13\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.4175\n",
      "Confusion Matrix:\n",
      "[[221 177   2   0]\n",
      " [  9 391   0   0]\n",
      " [ 41 348  11   0]\n",
      " [232 116   7  45]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.55      0.49       400\n",
      "           1       0.38      0.98      0.55       400\n",
      "           2       0.55      0.03      0.05       400\n",
      "           3       1.00      0.11      0.20       400\n",
      "\n",
      "    accuracy                           0.42      1600\n",
      "   macro avg       0.59      0.42      0.32      1600\n",
      "weighted avg       0.59      0.42      0.32      1600\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "600/600 - 14s - loss: 0.0951 - acc: 0.9652 - val_loss: 1.8150 - val_acc: 0.6356 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  14\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.615625\n",
      "Confusion Matrix:\n",
      "[[ 82 280  28  10]\n",
      " [  1 396   2   1]\n",
      " [  1 282 115   2]\n",
      " [  0   8   0 392]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.20      0.34       400\n",
      "           1       0.41      0.99      0.58       400\n",
      "           2       0.79      0.29      0.42       400\n",
      "           3       0.97      0.98      0.97       400\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.79      0.62      0.58      1600\n",
      "weighted avg       0.79      0.62      0.58      1600\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "600/600 - 14s - loss: 0.1055 - acc: 0.9631 - val_loss: 0.7594 - val_acc: 0.7887 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  15\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.78\n",
      "Confusion Matrix:\n",
      "[[288  85  25   2]\n",
      " [ 36 341  18   5]\n",
      " [ 56 112 231   1]\n",
      " [ 10   2   0 388]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       400\n",
      "           1       0.63      0.85      0.73       400\n",
      "           2       0.84      0.58      0.69       400\n",
      "           3       0.98      0.97      0.97       400\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.80      0.78      0.78      1600\n",
      "weighted avg       0.80      0.78      0.78      1600\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "600/600 - 14s - loss: 0.0832 - acc: 0.9721 - val_loss: 2.4861 - val_acc: 0.5931 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  16\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.594375\n",
      "Confusion Matrix:\n",
      "[[368  32   0   0]\n",
      " [122 278   0   0]\n",
      " [192 186  22   0]\n",
      " [113   4   0 283]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.92      0.62       400\n",
      "           1       0.56      0.69      0.62       400\n",
      "           2       1.00      0.06      0.10       400\n",
      "           3       1.00      0.71      0.83       400\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.75      0.59      0.54      1600\n",
      "weighted avg       0.75      0.59      0.54      1600\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "600/600 - 14s - loss: 0.0754 - acc: 0.9740 - val_loss: 1.4864 - val_acc: 0.6169 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  17\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.60875\n",
      "Confusion Matrix:\n",
      "[[131  27  53 189]\n",
      " [ 30 220  31 119]\n",
      " [  7  32 223 138]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.33      0.46       400\n",
      "           1       0.79      0.55      0.65       400\n",
      "           2       0.73      0.56      0.63       400\n",
      "           3       0.47      1.00      0.64       400\n",
      "\n",
      "    accuracy                           0.61      1600\n",
      "   macro avg       0.69      0.61      0.60      1600\n",
      "weighted avg       0.69      0.61      0.60      1600\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "600/600 - 14s - loss: 0.0676 - acc: 0.9771 - val_loss: 4.9646 - val_acc: 0.4606 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  18\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.40625\n",
      "Confusion Matrix:\n",
      "[[268 132   0   0]\n",
      " [ 33 367   0   0]\n",
      " [103 297   0   0]\n",
      " [238 147   0  15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.67      0.51       400\n",
      "           1       0.39      0.92      0.55       400\n",
      "           2       0.00      0.00      0.00       400\n",
      "           3       1.00      0.04      0.07       400\n",
      "\n",
      "    accuracy                           0.41      1600\n",
      "   macro avg       0.45      0.41      0.28      1600\n",
      "weighted avg       0.45      0.41      0.28      1600\n",
      "\n",
      "\n",
      "Epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0757 - acc: 0.9735 - val_loss: 2.1342 - val_acc: 0.6406 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  19\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.578125\n",
      "Confusion Matrix:\n",
      "[[112 286   2   0]\n",
      " [  1 398   1   0]\n",
      " [  5 331  64   0]\n",
      " [  6  43   0 351]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.28      0.43       400\n",
      "           1       0.38      0.99      0.55       400\n",
      "           2       0.96      0.16      0.27       400\n",
      "           3       1.00      0.88      0.93       400\n",
      "\n",
      "    accuracy                           0.58      1600\n",
      "   macro avg       0.81      0.58      0.55      1600\n",
      "weighted avg       0.81      0.58      0.55      1600\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "600/600 - 14s - loss: 0.0615 - acc: 0.9781 - val_loss: 1.2290 - val_acc: 0.6775 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  20\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.675\n",
      "Confusion Matrix:\n",
      "[[250  11 110  29]\n",
      " [ 62 118  80 140]\n",
      " [ 31  15 313  41]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       400\n",
      "           1       0.82      0.29      0.43       400\n",
      "           2       0.62      0.78      0.69       400\n",
      "           3       0.66      1.00      0.79       400\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.71      0.68      0.65      1600\n",
      "weighted avg       0.71      0.68      0.65      1600\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "600/600 - 14s - loss: 0.0539 - acc: 0.9844 - val_loss: 6.3241 - val_acc: 0.3738 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  21\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.3925\n",
      "Confusion Matrix:\n",
      "[[396   4   0   0]\n",
      " [225 174   1   0]\n",
      " [292  50  58   0]\n",
      " [388   0  12   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.99      0.47       400\n",
      "           1       0.76      0.43      0.55       400\n",
      "           2       0.82      0.14      0.25       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.39      1600\n",
      "   macro avg       0.47      0.39      0.32      1600\n",
      "weighted avg       0.47      0.39      0.32      1600\n",
      "\n",
      "\n",
      "Epoch:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0474 - acc: 0.9842 - val_loss: 6.1103 - val_acc: 0.3106 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  22\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.30125\n",
      "Confusion Matrix:\n",
      "[[  1 356  43   0]\n",
      " [  0 395   5   0]\n",
      " [  0 314  86   0]\n",
      " [  1 349  50   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       400\n",
      "           1       0.28      0.99      0.44       400\n",
      "           2       0.47      0.21      0.29       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.31      0.30      0.18      1600\n",
      "weighted avg       0.31      0.30      0.18      1600\n",
      "\n",
      "\n",
      "Epoch:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0647 - acc: 0.9787 - val_loss: 1.5115 - val_acc: 0.7337 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  23\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.7575\n",
      "Confusion Matrix:\n",
      "[[352  41   7   0]\n",
      " [ 99 298   3   0]\n",
      " [120 114 166   0]\n",
      " [  4   0   0 396]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       400\n",
      "           1       0.66      0.74      0.70       400\n",
      "           2       0.94      0.41      0.58       400\n",
      "           3       1.00      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.80      0.76      0.75      1600\n",
      "weighted avg       0.80      0.76      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "600/600 - 14s - loss: 0.0549 - acc: 0.9819 - val_loss: 3.8435 - val_acc: 0.5750 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  24\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.55625\n",
      "Confusion Matrix:\n",
      "[[ 96 223   0  81]\n",
      " [  1 391   0   8]\n",
      " [ 20 336   3  41]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.24      0.37       400\n",
      "           1       0.41      0.98      0.58       400\n",
      "           2       1.00      0.01      0.01       400\n",
      "           3       0.75      1.00      0.86       400\n",
      "\n",
      "    accuracy                           0.56      1600\n",
      "   macro avg       0.75      0.56      0.46      1600\n",
      "weighted avg       0.75      0.56      0.46      1600\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "600/600 - 14s - loss: 0.0550 - acc: 0.9825 - val_loss: 0.8308 - val_acc: 0.7856 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  25\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.708125\n",
      "Confusion Matrix:\n",
      "[[147 199  50   4]\n",
      " [  8 381  11   0]\n",
      " [  3 137 260   0]\n",
      " [  4  42   9 345]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.37      0.52       400\n",
      "           1       0.50      0.95      0.66       400\n",
      "           2       0.79      0.65      0.71       400\n",
      "           3       0.99      0.86      0.92       400\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.80      0.71      0.70      1600\n",
      "weighted avg       0.80      0.71      0.70      1600\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "600/600 - 14s - loss: 0.0474 - acc: 0.9819 - val_loss: 1.6025 - val_acc: 0.6456 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  26\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.62\n",
      "Confusion Matrix:\n",
      "[[145  91   9 155]\n",
      " [  8 326   5  61]\n",
      " [ 13  93 121 173]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.36      0.51       400\n",
      "           1       0.64      0.81      0.72       400\n",
      "           2       0.90      0.30      0.45       400\n",
      "           3       0.51      1.00      0.67       400\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.73      0.62      0.59      1600\n",
      "weighted avg       0.73      0.62      0.59      1600\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "600/600 - 14s - loss: 0.0254 - acc: 0.9925 - val_loss: 2.0454 - val_acc: 0.6562 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  27\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.61\n",
      "Confusion Matrix:\n",
      "[[ 78 320   2   0]\n",
      " [  0 400   0   0]\n",
      " [  0 298  98   4]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33       400\n",
      "           1       0.39      1.00      0.56       400\n",
      "           2       0.98      0.24      0.39       400\n",
      "           3       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.61      1600\n",
      "   macro avg       0.84      0.61      0.57      1600\n",
      "weighted avg       0.84      0.61      0.57      1600\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "600/600 - 14s - loss: 0.0822 - acc: 0.9746 - val_loss: 25.4316 - val_acc: 0.2506 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  28\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.25\n",
      "Confusion Matrix:\n",
      "[[  0   0   0 400]\n",
      " [  0   0   0 400]\n",
      " [  0   0   0 400]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       400\n",
      "           1       0.00      0.00      0.00       400\n",
      "           2       0.00      0.00      0.00       400\n",
      "           3       0.25      1.00      0.40       400\n",
      "\n",
      "    accuracy                           0.25      1600\n",
      "   macro avg       0.06      0.25      0.10      1600\n",
      "weighted avg       0.06      0.25      0.10      1600\n",
      "\n",
      "\n",
      "Epoch:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0308 - acc: 0.9906 - val_loss: 2.8934 - val_acc: 0.6306 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  29\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.60125\n",
      "Confusion Matrix:\n",
      "[[281 119   0   0]\n",
      " [ 31 369   0   0]\n",
      " [122 263  15   0]\n",
      " [ 76  27   0 297]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.70      0.62       400\n",
      "           1       0.47      0.92      0.63       400\n",
      "           2       1.00      0.04      0.07       400\n",
      "           3       1.00      0.74      0.85       400\n",
      "\n",
      "    accuracy                           0.60      1600\n",
      "   macro avg       0.76      0.60      0.54      1600\n",
      "weighted avg       0.76      0.60      0.54      1600\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "600/600 - 14s - loss: 0.0262 - acc: 0.9919 - val_loss: 1.8442 - val_acc: 0.6581 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  30\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.650625\n",
      "Confusion Matrix:\n",
      "[[164  91  15 130]\n",
      " [ 26 327  11  36]\n",
      " [ 17  71 152 160]\n",
      " [  0   2   0 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.41      0.54       400\n",
      "           1       0.67      0.82      0.73       400\n",
      "           2       0.85      0.38      0.53       400\n",
      "           3       0.55      0.99      0.71       400\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.72      0.65      0.63      1600\n",
      "weighted avg       0.72      0.65      0.63      1600\n",
      "\n",
      "\n",
      "Epoch:  31\n",
      "600/600 - 14s - loss: 0.0551 - acc: 0.9819 - val_loss: 7.3344 - val_acc: 0.3719 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  31\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.32375\n",
      "Confusion Matrix:\n",
      "[[ 74 326   0   0]\n",
      " [  0 400   0   0]\n",
      " [  2 398   0   0]\n",
      " [ 19 337   0  44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.18      0.30       400\n",
      "           1       0.27      1.00      0.43       400\n",
      "           2       0.00      0.00      0.00       400\n",
      "           3       1.00      0.11      0.20       400\n",
      "\n",
      "    accuracy                           0.32      1600\n",
      "   macro avg       0.51      0.32      0.23      1600\n",
      "weighted avg       0.51      0.32      0.23      1600\n",
      "\n",
      "\n",
      "Epoch:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0265 - acc: 0.9912 - val_loss: 4.3904 - val_acc: 0.4069 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  32\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.403125\n",
      "Confusion Matrix:\n",
      "[[  6   4   7 383]\n",
      " [ 10 155  20 215]\n",
      " [  0   2  84 314]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.01      0.03       400\n",
      "           1       0.96      0.39      0.55       400\n",
      "           2       0.76      0.21      0.33       400\n",
      "           3       0.30      1.00      0.47       400\n",
      "\n",
      "    accuracy                           0.40      1600\n",
      "   macro avg       0.60      0.40      0.34      1600\n",
      "weighted avg       0.60      0.40      0.34      1600\n",
      "\n",
      "\n",
      "Epoch:  33\n",
      "600/600 - 14s - loss: 0.0797 - acc: 0.9748 - val_loss: 6.2172 - val_acc: 0.3081 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  33\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.299375\n",
      "Confusion Matrix:\n",
      "[[ 38 362   0   0]\n",
      " [  0 400   0   0]\n",
      " [  1 358  41   0]\n",
      " [  9 381  10   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.10      0.17       400\n",
      "           1       0.27      1.00      0.42       400\n",
      "           2       0.80      0.10      0.18       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.30      1600\n",
      "   macro avg       0.47      0.30      0.19      1600\n",
      "weighted avg       0.47      0.30      0.19      1600\n",
      "\n",
      "\n",
      "Epoch:  34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0226 - acc: 0.9931 - val_loss: 0.5924 - val_acc: 0.8506 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  34\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.81125\n",
      "Confusion Matrix:\n",
      "[[222  24 152   2]\n",
      " [ 31 299  70   0]\n",
      " [  1  21 378   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.56      0.68       400\n",
      "           1       0.87      0.75      0.80       400\n",
      "           2       0.63      0.94      0.76       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.84      0.81      0.81      1600\n",
      "weighted avg       0.84      0.81      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  35\n",
      "600/600 - 14s - loss: 0.0029 - acc: 0.9996 - val_loss: 0.5208 - val_acc: 0.8656 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  35\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.81\n",
      "Confusion Matrix:\n",
      "[[202  58 140   0]\n",
      " [ 17 342  41   0]\n",
      " [  2  43 354   1]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.51      0.65       400\n",
      "           1       0.77      0.85      0.81       400\n",
      "           2       0.66      0.89      0.76       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.83      0.81      0.80      1600\n",
      "weighted avg       0.83      0.81      0.80      1600\n",
      "\n",
      "\n",
      "Epoch:  36\n",
      "600/600 - 14s - loss: 5.9422e-04 - acc: 1.0000 - val_loss: 0.4444 - val_acc: 0.8963 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  36\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.828125\n",
      "Confusion Matrix:\n",
      "[[228  92  80   0]\n",
      " [ 14 364  22   0]\n",
      " [  3  53 344   0]\n",
      " [  7   1   3 389]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       400\n",
      "           1       0.71      0.91      0.80       400\n",
      "           2       0.77      0.86      0.81       400\n",
      "           3       1.00      0.97      0.99       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  37\n",
      "600/600 - 14s - loss: 2.6147e-04 - acc: 1.0000 - val_loss: 0.4491 - val_acc: 0.8975 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  37\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.831875\n",
      "Confusion Matrix:\n",
      "[[221  79 100   0]\n",
      " [ 12 362  26   0]\n",
      " [  2  48 350   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.69       400\n",
      "           1       0.74      0.91      0.81       400\n",
      "           2       0.73      0.88      0.80       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  38\n",
      "600/600 - 14s - loss: 1.7855e-04 - acc: 1.0000 - val_loss: 0.4597 - val_acc: 0.9000 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  38\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[217  79 104   0]\n",
      " [ 13 360  27   0]\n",
      " [  2  47 351   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.69       400\n",
      "           1       0.74      0.90      0.81       400\n",
      "           2       0.73      0.88      0.80       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  39\n",
      "600/600 - 14s - loss: 1.3083e-04 - acc: 1.0000 - val_loss: 0.4703 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  39\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[218  78 104   0]\n",
      " [ 13 359  28   0]\n",
      " [  2  47 351   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.69       400\n",
      "           1       0.74      0.90      0.81       400\n",
      "           2       0.73      0.88      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  40\n",
      "600/600 - 14s - loss: 9.7696e-05 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  40\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.8275\n",
      "Confusion Matrix:\n",
      "[[216  77 107   0]\n",
      " [ 13 359  28   0]\n",
      " [  2  47 351   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.68       400\n",
      "           1       0.74      0.90      0.81       400\n",
      "           2       0.72      0.88      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  41\n",
      "600/600 - 14s - loss: 7.3506e-05 - acc: 1.0000 - val_loss: 0.4923 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  41\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.828125\n",
      "Confusion Matrix:\n",
      "[[216  77 107   0]\n",
      " [ 12 359  29   0]\n",
      " [  2  46 352   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.54      0.68       400\n",
      "           1       0.74      0.90      0.81       400\n",
      "           2       0.72      0.88      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  42\n",
      "600/600 - 13s - loss: 5.5503e-05 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.9019 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  42\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[216  76 108   0]\n",
      " [ 12 359  29   0]\n",
      " [  2  45 353   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.54      0.68       400\n",
      "           1       0.75      0.90      0.82       400\n",
      "           2       0.72      0.88      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  43\n",
      "600/600 - 14s - loss: 4.1953e-05 - acc: 1.0000 - val_loss: 0.5157 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  43\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8275\n",
      "Confusion Matrix:\n",
      "[[214  74 112   0]\n",
      " [ 12 358  30   0]\n",
      " [  2  44 354   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.68       400\n",
      "           1       0.75      0.90      0.82       400\n",
      "           2       0.71      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  44\n",
      "600/600 - 14s - loss: 3.1730e-05 - acc: 1.0000 - val_loss: 0.5281 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  44\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.826875\n",
      "Confusion Matrix:\n",
      "[[213  74 113   0]\n",
      " [ 11 358  31   0]\n",
      " [  2  44 354   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       400\n",
      "           1       0.75      0.90      0.82       400\n",
      "           2       0.71      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  45\n",
      "600/600 - 14s - loss: 2.3964e-05 - acc: 1.0000 - val_loss: 0.5408 - val_acc: 0.8981 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  45\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8275\n",
      "Confusion Matrix:\n",
      "[[213  74 113   0]\n",
      " [ 12 358  30   0]\n",
      " [  2  43 355   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.53      0.68       400\n",
      "           1       0.75      0.90      0.82       400\n",
      "           2       0.71      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  46\n",
      "600/600 - 14s - loss: 1.8062e-05 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.8975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  46\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.828125\n",
      "Confusion Matrix:\n",
      "[[214  70 116   0]\n",
      " [ 12 358  30   0]\n",
      " [  2  43 355   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.68       400\n",
      "           1       0.76      0.90      0.82       400\n",
      "           2       0.71      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  47\n",
      "600/600 - 14s - loss: 1.3578e-05 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.8963 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  47\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.830625\n",
      "Confusion Matrix:\n",
      "[[215  69 116   0]\n",
      " [ 12 358  30   0]\n",
      " [  2  40 358   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.68       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  48\n",
      "600/600 - 14s - loss: 1.0189e-05 - acc: 1.0000 - val_loss: 0.5815 - val_acc: 0.8956 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  48\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.831875\n",
      "Confusion Matrix:\n",
      "[[215  69 116   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  39 359   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.54      0.68       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  49\n",
      "600/600 - 14s - loss: 7.6365e-06 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.8981 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  49\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.830625\n",
      "Confusion Matrix:\n",
      "[[213  70 117   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  39 359   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  50\n",
      "600/600 - 14s - loss: 5.7155e-06 - acc: 1.0000 - val_loss: 0.6088 - val_acc: 0.8975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  50\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.830625\n",
      "Confusion Matrix:\n",
      "[[213  72 115   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  39 359   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       400\n",
      "           1       0.76      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  51\n",
      "600/600 - 14s - loss: 4.2810e-06 - acc: 1.0000 - val_loss: 0.6227 - val_acc: 0.8981 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  51\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.829375\n",
      "Confusion Matrix:\n",
      "[[211  71 118   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  39 359   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  52\n",
      "600/600 - 14s - loss: 3.1940e-06 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  52\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[210  71 119   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  39 359   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.67       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.71      0.90      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  53\n",
      "600/600 - 14s - loss: 2.4172e-06 - acc: 1.0000 - val_loss: 0.6473 - val_acc: 0.8994 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  53\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[213  75 112   0]\n",
      " [ 11 359  30   0]\n",
      " [  2  42 356   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       400\n",
      "           1       0.75      0.90      0.82       400\n",
      "           2       0.71      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  54\n",
      "600/600 - 14s - loss: 1.9894e-06 - acc: 1.0000 - val_loss: 0.6675 - val_acc: 0.8975 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  54\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 10ms/step\n",
      "Accuracy: 0.82625\n",
      "Confusion Matrix:\n",
      "[[209  72 119   0]\n",
      " [ 11 358  31   0]\n",
      " [  2  41 357   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.52      0.67       400\n",
      "           1       0.76      0.90      0.82       400\n",
      "           2       0.70      0.89      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.82      1600\n",
      "weighted avg       0.85      0.83      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  55\n",
      "600/600 - 14s - loss: 0.2555 - acc: 0.9340 - val_loss: 5.2352 - val_acc: 0.4450 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  55\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.398125\n",
      "Confusion Matrix:\n",
      "[[261 139   0   0]\n",
      " [ 29 371   0   0]\n",
      " [ 78 318   4   0]\n",
      " [298 101   0   1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.65      0.49       400\n",
      "           1       0.40      0.93      0.56       400\n",
      "           2       1.00      0.01      0.02       400\n",
      "           3       1.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.40      1600\n",
      "   macro avg       0.70      0.40      0.27      1600\n",
      "weighted avg       0.70      0.40      0.27      1600\n",
      "\n",
      "\n",
      "Epoch:  56\n",
      "600/600 - 14s - loss: 0.0583 - acc: 0.9810 - val_loss: 3.9575 - val_acc: 0.5537 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  56\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.554375\n",
      "Confusion Matrix:\n",
      "[[329  61  10   0]\n",
      " [ 79 319   2   0]\n",
      " [ 48 113 239   0]\n",
      " [287  45  68   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.82      0.58       400\n",
      "           1       0.59      0.80      0.68       400\n",
      "           2       0.75      0.60      0.66       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.55      1600\n",
      "   macro avg       0.45      0.55      0.48      1600\n",
      "weighted avg       0.45      0.55      0.48      1600\n",
      "\n",
      "\n",
      "Epoch:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0091 - acc: 0.9979 - val_loss: 0.6565 - val_acc: 0.8481 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  57\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8125\n",
      "Confusion Matrix:\n",
      "[[265 113  22   0]\n",
      " [ 24 370   6   0]\n",
      " [ 23  82 295   0]\n",
      " [ 23   3   4 370]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       400\n",
      "           1       0.65      0.93      0.76       400\n",
      "           2       0.90      0.74      0.81       400\n",
      "           3       1.00      0.93      0.96       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.84      0.81      0.81      1600\n",
      "weighted avg       0.84      0.81      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  58\n",
      "600/600 - 14s - loss: 0.0205 - acc: 0.9925 - val_loss: 4.5922 - val_acc: 0.4231 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  58\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.43125\n",
      "Confusion Matrix:\n",
      "[[ 13  15 372   0]\n",
      " [  1 258 141   0]\n",
      " [  0  12 388   0]\n",
      " [  3   2 364  31]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.03      0.06       400\n",
      "           1       0.90      0.65      0.75       400\n",
      "           2       0.31      0.97      0.47       400\n",
      "           3       1.00      0.08      0.14       400\n",
      "\n",
      "    accuracy                           0.43      1600\n",
      "   macro avg       0.74      0.43      0.36      1600\n",
      "weighted avg       0.74      0.43      0.36      1600\n",
      "\n",
      "\n",
      "Epoch:  59\n",
      "600/600 - 14s - loss: 0.0399 - acc: 0.9877 - val_loss: 2.7147 - val_acc: 0.5900 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  59\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.63\n",
      "Confusion Matrix:\n",
      "[[ 23   4 358  15]\n",
      " [  7 192 199   2]\n",
      " [  0   3 397   0]\n",
      " [  0   0   4 396]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.06      0.11       400\n",
      "           1       0.96      0.48      0.64       400\n",
      "           2       0.41      0.99      0.58       400\n",
      "           3       0.96      0.99      0.97       400\n",
      "\n",
      "    accuracy                           0.63      1600\n",
      "   macro avg       0.78      0.63      0.58      1600\n",
      "weighted avg       0.78      0.63      0.58      1600\n",
      "\n",
      "\n",
      "Epoch:  60\n",
      "600/600 - 14s - loss: 0.0492 - acc: 0.9831 - val_loss: 0.8520 - val_acc: 0.8006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  60\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.75875\n",
      "Confusion Matrix:\n",
      "[[237 151  12   0]\n",
      " [ 18 382   0   0]\n",
      " [ 23 166 211   0]\n",
      " [ 11   5   0 384]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.59      0.69       400\n",
      "           1       0.54      0.95      0.69       400\n",
      "           2       0.95      0.53      0.68       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.83      0.76      0.76      1600\n",
      "weighted avg       0.83      0.76      0.76      1600\n",
      "\n",
      "\n",
      "Epoch:  61\n",
      "600/600 - 14s - loss: 0.0184 - acc: 0.9937 - val_loss: 2.5450 - val_acc: 0.6762 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  61\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.613125\n",
      "Confusion Matrix:\n",
      "[[228 172   0   0]\n",
      " [ 14 386   0   0]\n",
      " [ 66 299  35   0]\n",
      " [ 58  10   0 332]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60       400\n",
      "           1       0.45      0.96      0.61       400\n",
      "           2       1.00      0.09      0.16       400\n",
      "           3       1.00      0.83      0.91       400\n",
      "\n",
      "    accuracy                           0.61      1600\n",
      "   macro avg       0.77      0.61      0.57      1600\n",
      "weighted avg       0.77      0.61      0.57      1600\n",
      "\n",
      "\n",
      "Epoch:  62\n",
      "600/600 - 14s - loss: 0.0372 - acc: 0.9890 - val_loss: 1.8247 - val_acc: 0.6313 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  62\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.555\n",
      "Confusion Matrix:\n",
      "[[158  47 195   0]\n",
      " [  7 337  56   0]\n",
      " [  0  35 365   0]\n",
      " [ 38  16 318  28]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.40      0.52       400\n",
      "           1       0.77      0.84      0.81       400\n",
      "           2       0.39      0.91      0.55       400\n",
      "           3       1.00      0.07      0.13       400\n",
      "\n",
      "    accuracy                           0.56      1600\n",
      "   macro avg       0.74      0.55      0.50      1600\n",
      "weighted avg       0.74      0.56      0.50      1600\n",
      "\n",
      "\n",
      "Epoch:  63\n",
      "600/600 - 14s - loss: 0.0171 - acc: 0.9942 - val_loss: 4.6930 - val_acc: 0.4006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  63\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.39375\n",
      "Confusion Matrix:\n",
      "[[  0   4   8 388]\n",
      " [  0 103   7 290]\n",
      " [  0   8 127 265]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       400\n",
      "           1       0.90      0.26      0.40       400\n",
      "           2       0.89      0.32      0.47       400\n",
      "           3       0.30      1.00      0.46       400\n",
      "\n",
      "    accuracy                           0.39      1600\n",
      "   macro avg       0.52      0.39      0.33      1600\n",
      "weighted avg       0.52      0.39      0.33      1600\n",
      "\n",
      "\n",
      "Epoch:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0337 - acc: 0.9885 - val_loss: 4.4352 - val_acc: 0.5931 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  64\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.53875\n",
      "Confusion Matrix:\n",
      "[[ 84 312   0   4]\n",
      " [  1 399   0   0]\n",
      " [  8 385   6   1]\n",
      " [  0  27   0 373]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.21      0.34       400\n",
      "           1       0.36      1.00      0.52       400\n",
      "           2       1.00      0.01      0.03       400\n",
      "           3       0.99      0.93      0.96       400\n",
      "\n",
      "    accuracy                           0.54      1600\n",
      "   macro avg       0.81      0.54      0.46      1600\n",
      "weighted avg       0.81      0.54      0.46      1600\n",
      "\n",
      "\n",
      "Epoch:  65\n",
      "600/600 - 14s - loss: 0.0435 - acc: 0.9867 - val_loss: 2.1476 - val_acc: 0.5325 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  65\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.508125\n",
      "Confusion Matrix:\n",
      "[[213 185   2   0]\n",
      " [ 12 388   0   0]\n",
      " [ 34 213 153   0]\n",
      " [238  79  24  59]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.47       400\n",
      "           1       0.45      0.97      0.61       400\n",
      "           2       0.85      0.38      0.53       400\n",
      "           3       1.00      0.15      0.26       400\n",
      "\n",
      "    accuracy                           0.51      1600\n",
      "   macro avg       0.68      0.51      0.47      1600\n",
      "weighted avg       0.68      0.51      0.47      1600\n",
      "\n",
      "\n",
      "Epoch:  66\n",
      "600/600 - 14s - loss: 0.0186 - acc: 0.9944 - val_loss: 0.8141 - val_acc: 0.8169 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  66\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.7975\n",
      "Confusion Matrix:\n",
      "[[204  30 153  13]\n",
      " [ 26 294  77   3]\n",
      " [  3  17 378   2]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.51      0.64       400\n",
      "           1       0.86      0.73      0.79       400\n",
      "           2       0.62      0.94      0.75       400\n",
      "           3       0.96      1.00      0.98       400\n",
      "\n",
      "    accuracy                           0.80      1600\n",
      "   macro avg       0.83      0.80      0.79      1600\n",
      "weighted avg       0.83      0.80      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  67\n",
      "600/600 - 14s - loss: 0.0030 - acc: 0.9994 - val_loss: 0.5124 - val_acc: 0.8894 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  67\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.80625\n",
      "Confusion Matrix:\n",
      "[[179 131  90   0]\n",
      " [  8 372  20   0]\n",
      " [  4  54 342   0]\n",
      " [  1   0   2 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.45      0.60       400\n",
      "           1       0.67      0.93      0.78       400\n",
      "           2       0.75      0.85      0.80       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.84      0.81      0.79      1600\n",
      "weighted avg       0.84      0.81      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  68\n",
      "600/600 - 14s - loss: 0.0527 - acc: 0.9800 - val_loss: 6.5359 - val_acc: 0.4238 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  68\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.41125\n",
      "Confusion Matrix:\n",
      "[[371  29   0   0]\n",
      " [117 283   0   0]\n",
      " [270 126   4   0]\n",
      " [399   0   1   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.93      0.48       400\n",
      "           1       0.65      0.71      0.68       400\n",
      "           2       0.80      0.01      0.02       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.41      1600\n",
      "   macro avg       0.44      0.41      0.29      1600\n",
      "weighted avg       0.44      0.41      0.29      1600\n",
      "\n",
      "\n",
      "Epoch:  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 14s - loss: 0.0208 - acc: 0.9931 - val_loss: 0.8869 - val_acc: 0.8300 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  69\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.791875\n",
      "Confusion Matrix:\n",
      "[[226  10 164   0]\n",
      " [ 44 259  97   0]\n",
      " [  3  14 383   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67       400\n",
      "           1       0.92      0.65      0.76       400\n",
      "           2       0.59      0.96      0.73       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.83      0.79      0.79      1600\n",
      "weighted avg       0.83      0.79      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  70\n",
      "600/600 - 14s - loss: 0.0035 - acc: 0.9990 - val_loss: 0.6429 - val_acc: 0.8575 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  70\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.81875\n",
      "Confusion Matrix:\n",
      "[[245  20 134   1]\n",
      " [ 47 290  60   3]\n",
      " [ 10  15 375   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.70       400\n",
      "           1       0.89      0.72      0.80       400\n",
      "           2       0.66      0.94      0.77       400\n",
      "           3       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.84      0.82      0.82      1600\n",
      "weighted avg       0.84      0.82      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  71\n",
      "600/600 - 14s - loss: 5.3108e-04 - acc: 1.0000 - val_loss: 0.4476 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  71\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[233  66 101   0]\n",
      " [ 19 350  31   0]\n",
      " [  8  35 357   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.58      0.71       400\n",
      "           1       0.78      0.88      0.82       400\n",
      "           2       0.73      0.89      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  72\n",
      "600/600 - 14s - loss: 1.8838e-04 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  72\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.835625\n",
      "Confusion Matrix:\n",
      "[[229  72  99   0]\n",
      " [ 19 352  29   0]\n",
      " [  8  35 357   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70       400\n",
      "           1       0.77      0.88      0.82       400\n",
      "           2       0.73      0.89      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  73\n",
      "600/600 - 14s - loss: 1.3349e-04 - acc: 1.0000 - val_loss: 0.4536 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  73\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.83625\n",
      "Confusion Matrix:\n",
      "[[229  72  99   0]\n",
      " [ 18 354  28   0]\n",
      " [  8  36 356   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       400\n",
      "           1       0.77      0.89      0.82       400\n",
      "           2       0.74      0.89      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  74\n",
      "600/600 - 14s - loss: 1.0004e-04 - acc: 1.0000 - val_loss: 0.4604 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  74\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.835625\n",
      "Confusion Matrix:\n",
      "[[228  73  99   0]\n",
      " [ 18 355  27   0]\n",
      " [  9  36 355   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70       400\n",
      "           1       0.77      0.89      0.82       400\n",
      "           2       0.74      0.89      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  75\n",
      "600/600 - 14s - loss: 7.6153e-05 - acc: 1.0000 - val_loss: 0.4676 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  75\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.83625\n",
      "Confusion Matrix:\n",
      "[[228  72 100   0]\n",
      " [ 17 356  27   0]\n",
      " [  9  36 355   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       400\n",
      "           1       0.77      0.89      0.82       400\n",
      "           2       0.73      0.89      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  76\n",
      "600/600 - 14s - loss: 5.8413e-05 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  76\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.835\n",
      "Confusion Matrix:\n",
      "[[227  72 101   0]\n",
      " [ 17 355  28   0]\n",
      " [  9  36 355   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       400\n",
      "           1       0.77      0.89      0.82       400\n",
      "           2       0.73      0.89      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  77\n",
      "600/600 - 14s - loss: 4.4867e-05 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.9019 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  77\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.835\n",
      "Confusion Matrix:\n",
      "[[226  73 101   0]\n",
      " [ 18 355  27   0]\n",
      " [  9  35 356   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69       400\n",
      "           1       0.77      0.89      0.82       400\n",
      "           2       0.73      0.89      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  78\n",
      "600/600 - 14s - loss: 3.4416e-05 - acc: 1.0000 - val_loss: 0.4931 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  78\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.83625\n",
      "Confusion Matrix:\n",
      "[[226  73 101   0]\n",
      " [ 18 356  26   0]\n",
      " [  9  34 357   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69       400\n",
      "           1       0.77      0.89      0.83       400\n",
      "           2       0.74      0.89      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  79\n",
      "600/600 - 14s - loss: 2.6358e-05 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  79\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[227  73 100   0]\n",
      " [ 18 356  26   0]\n",
      " [  9  33 358   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69       400\n",
      "           1       0.77      0.89      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  80\n",
      "600/600 - 14s - loss: 2.0130e-05 - acc: 1.0000 - val_loss: 0.5120 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  80\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.838125\n",
      "Confusion Matrix:\n",
      "[[227  73 100   0]\n",
      " [ 17 357  26   0]\n",
      " [  9  33 358   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       400\n",
      "           1       0.77      0.89      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  81\n",
      "600/600 - 14s - loss: 1.5333e-05 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  81\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.836875\n",
      "Confusion Matrix:\n",
      "[[224  74 102   0]\n",
      " [ 17 358  25   0]\n",
      " [  9  33 358   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  82\n",
      "600/600 - 14s - loss: 1.1652e-05 - acc: 1.0000 - val_loss: 0.5331 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  82\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[224  74 102   0]\n",
      " [ 17 358  25   0]\n",
      " [  8  33 359   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  83\n",
      "600/600 - 14s - loss: 8.8262e-06 - acc: 1.0000 - val_loss: 0.5439 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  83\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.83875\n",
      "Confusion Matrix:\n",
      "[[224  74 102   0]\n",
      " [ 17 359  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  84\n",
      "600/600 - 14s - loss: 6.6707e-06 - acc: 1.0000 - val_loss: 0.5552 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  84\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.836875\n",
      "Confusion Matrix:\n",
      "[[221  75 104   0]\n",
      " [ 17 359  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.55      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  85\n",
      "600/600 - 14s - loss: 5.0290e-06 - acc: 1.0000 - val_loss: 0.5671 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  85\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[222  74 104   0]\n",
      " [ 17 359  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  86\n",
      "600/600 - 14s - loss: 3.7801e-06 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  86\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.836875\n",
      "Confusion Matrix:\n",
      "[[221  75 104   0]\n",
      " [ 17 359  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.55      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  87\n",
      "600/600 - 14s - loss: 2.8374e-06 - acc: 1.0000 - val_loss: 0.5903 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  87\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[222  75 103   0]\n",
      " [ 17 359  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  88\n",
      "600/600 - 14s - loss: 2.1279e-06 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  88\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[221  76 103   0]\n",
      " [ 16 360  24   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  89\n",
      "600/600 - 14s - loss: 1.5924e-06 - acc: 1.0000 - val_loss: 0.6140 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  89\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.838125\n",
      "Confusion Matrix:\n",
      "[[221  76 103   0]\n",
      " [ 16 360  24   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  90\n",
      "600/600 - 14s - loss: 1.1873e-06 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.9044 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  90\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.8375\n",
      "Confusion Matrix:\n",
      "[[221  76 103   0]\n",
      " [ 17 359  24   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  91\n",
      "600/600 - 14s - loss: 8.8485e-07 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  91\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.839375\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 17 360  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  92\n",
      "600/600 - 14s - loss: 6.5947e-07 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  92\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.839375\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 17 360  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  93\n",
      "600/600 - 14s - loss: 4.9059e-07 - acc: 1.0000 - val_loss: 0.6641 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  93\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.83875\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 17 359  24   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  94\n",
      "600/600 - 14s - loss: 3.6443e-07 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 0.9050 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  94\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.84\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 17 361  22   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  95\n",
      "600/600 - 14s - loss: 2.7075e-07 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  95\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.839375\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 17 360  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  96\n",
      "600/600 - 14s - loss: 2.0017e-07 - acc: 1.0000 - val_loss: 0.7002 - val_acc: 0.9031 - 14s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  96\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.840625\n",
      "Confusion Matrix:\n",
      "[[222  76 102   0]\n",
      " [ 15 362  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.91      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.83      1600\n",
      "weighted avg       0.86      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  97\n",
      "600/600 - 14s - loss: 1.4906e-07 - acc: 1.0000 - val_loss: 0.7124 - val_acc: 0.9019 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  97\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.84125\n",
      "Confusion Matrix:\n",
      "[[224  74 102   0]\n",
      " [ 16 361  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  98\n",
      "600/600 - 14s - loss: 1.1141e-07 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  98\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.84125\n",
      "Confusion Matrix:\n",
      "[[224  74 102   0]\n",
      " [ 16 361  23   0]\n",
      " [  6  33 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.74      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  99\n",
      "600/600 - 14s - loss: 8.7023e-08 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.9044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  99\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.84\n",
      "Confusion Matrix:\n",
      "[[223  77 100   0]\n",
      " [ 17 361  22   0]\n",
      " [  7  33 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       400\n",
      "           1       0.77      0.90      0.83       400\n",
      "           2       0.75      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.83      1600\n",
      "weighted avg       0.85      0.84      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  100\n",
      "600/600 - 14s - loss: 0.1393 - acc: 0.9627 - val_loss: 6.4866 - val_acc: 0.4387 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_none_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  100\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.406875\n",
      "Confusion Matrix:\n",
      "[[280 120   0   0]\n",
      " [ 30 370   0   0]\n",
      " [ 63 336   1   0]\n",
      " [229 171   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56       400\n",
      "           1       0.37      0.93      0.53       400\n",
      "           2       1.00      0.00      0.00       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.41      1600\n",
      "   macro avg       0.46      0.41      0.27      1600\n",
      "weighted avg       0.46      0.41      0.27      1600\n",
      "\n",
      "Testing time (s) = 2986.300165721914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_training, labels_training, batch_size=batch_size, epochs = 1, validation_data=(x_val_norm, y_val), verbose=2)\n",
    "    model.save('./RNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    \n",
    "    y_pred = model.predict(test_dataset)\n",
    "\n",
    "    y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_dataset_label, y_pred_label))\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d4ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.406875\n",
      "Confusion Matrix:\n",
      "[[280 120   0   0]\n",
      " [ 30 370   0   0]\n",
      " [ 63 336   1   0]\n",
      " [229 171   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56       400\n",
      "           1       0.37      0.93      0.53       400\n",
      "           2       1.00      0.00      0.00       400\n",
      "           3       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.41      1600\n",
      "   macro avg       0.46      0.41      0.27      1600\n",
      "weighted avg       0.46      0.41      0.27      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tyagi/Desktop/Deepak/Wheat-Classification/dwheatenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06167d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af1a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwheatenv",
   "language": "python",
   "name": "dwheatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
