{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 19:16:14.024817: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 19:16:15.280244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/tyagi/Desktop/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TRAIN_IMAGE_COUNT = 1200\n",
    "VAL_IMAGE_COUNT = 400\n",
    "TEST_IMAGE_COUNT = 400\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "LEARNING_RATE_BASE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "    \n",
    "FILTER = filter_method(2).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(0).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/V\"+str(variety).zfill(3)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n",
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    x_train= x_train + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    y_train = y_train + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    x_val= x_val + np.load(dataset_file_name(v)+\"_val_dataset.npy\").tolist()\n",
    "    y_val = y_val + np.load(dataset_file_name(v)+\"_val_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca90232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    print(\"Testing started\")\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "    \n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix_results,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_integer_format, labels_predicted_integer_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb608fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90729707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_block(x, filters, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def identity_block(x, filters):\n",
    "    x_identity = x\n",
    "\n",
    "    x = conv_block(x, filters)\n",
    "    x = layers.Add()([x, x_identity])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), use_bias=False, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = conv_block(x, filters=64, strides=1)\n",
    "    x = identity_block(x, filters=64)\n",
    "\n",
    "    x = conv_block(x, filters=128, strides=2)\n",
    "    x = identity_block(x, filters=128)\n",
    "\n",
    "    x = conv_block(x, filters=256, strides=2)\n",
    "    x = identity_block(x, filters=256)\n",
    "\n",
    "    x = conv_block(x, filters=512, strides=2)\n",
    "    x = identity_block(x, filters=512)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43cde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = np.array(x_train)\n",
    "labels_training = np.array(y_train)\n",
    "\n",
    "# Normalize the data\n",
    "x_training = normalizeDataWholeSeed(x_training,normalization_type='max')\n",
    "x_val_norm = normalizeDataWholeSeed(x_val,normalization_type=\"max\")\n",
    "test_dataset = normalizeDataWholeSeed(test_dataset,normalization_type='max')\n",
    "    \n",
    "# Extract some information\n",
    "num_training = x_training.shape[0]\n",
    "N_spatial = x_training.shape[1:3]\n",
    "N_bands = x_training.shape[3]\n",
    "batch_size = BATCH_SIZE\n",
    "num_batch_per_epoch = int(num_training/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ce95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(file_path, data_frame, header=False):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    if not file_exists or not header:\n",
    "        data_frame.to_csv(file_path, index=False, mode='w')\n",
    "    else:\n",
    "        data_frame.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08349c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HD 3086', 'PBW 291', 'DBW 187', 'DBW222']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9dcaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead0a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 19:21:16.347626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14545 MB memory:  -> device: 1, name: Quadro P5000, pci bus id: 0000:9b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RN_\"+\"_IC_\"+str(TRAIN_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "if REMOVE_NOISY_BANDS:\n",
    "    model_name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "if FILTER == \"savgol\":\n",
    "    model_name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "\n",
    "if start_epoch != 1:\n",
    "    model = tf.keras.models.load_model('./RNmodels/'+str(start_epoch-1)+model_name)\n",
    "else:\n",
    "    \n",
    "    input_shape = (30, 30, 168)\n",
    "    num_classes = 4\n",
    "    model = resnet18(input_shape, num_classes)\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627a2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74535028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 15, 15, 64)   526848      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     36864       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 64)     36864       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    73728       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 128)    147456      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 128)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 4, 4, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 2, 2, 256)    294912      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_10[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 2, 2, 256)    589824      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2, 2, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 1, 1, 512)    1179648     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 512)    2359296     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 1, 512)    0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 1, 1, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            2052        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,529,988\n",
      "Trainable params: 11,522,180\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3324c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 19:21:28.286638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 18s - loss: 1.5376 - acc: 0.3575 - val_loss: 2.5797 - val_acc: 0.3406 - 18s/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  1\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.348125\n",
      "Confusion Matrix:\n",
      "[[ 22   7  10 361]\n",
      " [ 44 121  79 156]\n",
      " [ 53  47  50 250]\n",
      " [ 26   3   7 364]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.06      0.08       400\n",
      "           1       0.68      0.30      0.42       400\n",
      "           2       0.34      0.12      0.18       400\n",
      "           3       0.32      0.91      0.48       400\n",
      "\n",
      "    accuracy                           0.35      1600\n",
      "   macro avg       0.37      0.35      0.29      1600\n",
      "weighted avg       0.37      0.35      0.29      1600\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "600/600 - 14s - loss: 1.2178 - acc: 0.4675 - val_loss: 1.2360 - val_acc: 0.4556 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  2\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.47375\n",
      "Confusion Matrix:\n",
      "[[151  16 104 129]\n",
      " [ 25 141 211  23]\n",
      " [ 38  94 222  46]\n",
      " [ 58   7  91 244]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.38      0.45       400\n",
      "           1       0.55      0.35      0.43       400\n",
      "           2       0.35      0.56      0.43       400\n",
      "           3       0.55      0.61      0.58       400\n",
      "\n",
      "    accuracy                           0.47      1600\n",
      "   macro avg       0.50      0.47      0.47      1600\n",
      "weighted avg       0.50      0.47      0.47      1600\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "600/600 - 13s - loss: 0.8967 - acc: 0.6288 - val_loss: 0.9104 - val_acc: 0.6012 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  3\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.603125\n",
      "Confusion Matrix:\n",
      "[[235  32 128   5]\n",
      " [ 35 218 143   4]\n",
      " [ 58 131 210   1]\n",
      " [ 45   6  47 302]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       400\n",
      "           1       0.56      0.55      0.55       400\n",
      "           2       0.40      0.53      0.45       400\n",
      "           3       0.97      0.76      0.85       400\n",
      "\n",
      "    accuracy                           0.60      1600\n",
      "   macro avg       0.64      0.60      0.62      1600\n",
      "weighted avg       0.64      0.60      0.62      1600\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "600/600 - 13s - loss: 0.6271 - acc: 0.7421 - val_loss: 0.8660 - val_acc: 0.6344 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  4\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.616875\n",
      "Confusion Matrix:\n",
      "[[310  23  63   4]\n",
      " [ 81 193 122   4]\n",
      " [109 111 177   3]\n",
      " [ 72   3  18 307]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64       400\n",
      "           1       0.58      0.48      0.53       400\n",
      "           2       0.47      0.44      0.45       400\n",
      "           3       0.97      0.77      0.86       400\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.64      0.62      0.62      1600\n",
      "weighted avg       0.64      0.62      0.62      1600\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "600/600 - 13s - loss: 0.4411 - acc: 0.8292 - val_loss: 1.3564 - val_acc: 0.5188 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  5\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.500625\n",
      "Confusion Matrix:\n",
      "[[246  44 110   0]\n",
      " [ 35 228 137   0]\n",
      " [ 49 118 233   0]\n",
      " [191  41  74  94]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.61      0.53       400\n",
      "           1       0.53      0.57      0.55       400\n",
      "           2       0.42      0.58      0.49       400\n",
      "           3       1.00      0.23      0.38       400\n",
      "\n",
      "    accuracy                           0.50      1600\n",
      "   macro avg       0.61      0.50      0.49      1600\n",
      "weighted avg       0.61      0.50      0.49      1600\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "600/600 - 14s - loss: 0.3374 - acc: 0.8752 - val_loss: 0.8829 - val_acc: 0.6819 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  6\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.643125\n",
      "Confusion Matrix:\n",
      "[[196  96  99   9]\n",
      " [ 17 327  49   7]\n",
      " [ 30 225 142   3]\n",
      " [ 13  14   9 364]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.49      0.60       400\n",
      "           1       0.49      0.82      0.62       400\n",
      "           2       0.47      0.35      0.41       400\n",
      "           3       0.95      0.91      0.93       400\n",
      "\n",
      "    accuracy                           0.64      1600\n",
      "   macro avg       0.67      0.64      0.64      1600\n",
      "weighted avg       0.67      0.64      0.64      1600\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "600/600 - 13s - loss: 0.2960 - acc: 0.8867 - val_loss: 0.8112 - val_acc: 0.7113 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  7\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.683125\n",
      "Confusion Matrix:\n",
      "[[196 103  77  24]\n",
      " [ 11 328  49  12]\n",
      " [ 17 191 179  13]\n",
      " [  7   2   1 390]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.49      0.62       400\n",
      "           1       0.53      0.82      0.64       400\n",
      "           2       0.58      0.45      0.51       400\n",
      "           3       0.89      0.97      0.93       400\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.71      0.68      0.67      1600\n",
      "weighted avg       0.71      0.68      0.67      1600\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "600/600 - 13s - loss: 0.1981 - acc: 0.9271 - val_loss: 1.1794 - val_acc: 0.6594 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  8\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.68375\n",
      "Confusion Matrix:\n",
      "[[356  36   8   0]\n",
      " [ 93 300   6   1]\n",
      " [151 171  76   2]\n",
      " [ 29   9   0 362]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.89      0.69       400\n",
      "           1       0.58      0.75      0.66       400\n",
      "           2       0.84      0.19      0.31       400\n",
      "           3       0.99      0.91      0.95       400\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.75      0.68      0.65      1600\n",
      "weighted avg       0.75      0.68      0.65      1600\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "600/600 - 14s - loss: 0.1738 - acc: 0.9396 - val_loss: 0.7837 - val_acc: 0.7544 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  9\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.6925\n",
      "Confusion Matrix:\n",
      "[[173 102 125   0]\n",
      " [  4 351  45   0]\n",
      " [  9 162 228   1]\n",
      " [ 11  19  14 356]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.43      0.58       400\n",
      "           1       0.55      0.88      0.68       400\n",
      "           2       0.55      0.57      0.56       400\n",
      "           3       1.00      0.89      0.94       400\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.75      0.69      0.69      1600\n",
      "weighted avg       0.75      0.69      0.69      1600\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "600/600 - 14s - loss: 0.1598 - acc: 0.9421 - val_loss: 1.2800 - val_acc: 0.6712 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  10\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.66625\n",
      "Confusion Matrix:\n",
      "[[371  20   5   4]\n",
      " [119 277   4   0]\n",
      " [182 146  72   0]\n",
      " [ 42  10   2 346]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67       400\n",
      "           1       0.61      0.69      0.65       400\n",
      "           2       0.87      0.18      0.30       400\n",
      "           3       0.99      0.86      0.92       400\n",
      "\n",
      "    accuracy                           0.67      1600\n",
      "   macro avg       0.75      0.67      0.63      1600\n",
      "weighted avg       0.75      0.67      0.63      1600\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "600/600 - 13s - loss: 0.1309 - acc: 0.9538 - val_loss: 0.8485 - val_acc: 0.7475 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  11\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.748125\n",
      "Confusion Matrix:\n",
      "[[327  61  12   0]\n",
      " [ 57 332  11   0]\n",
      " [ 95 130 175   0]\n",
      " [ 12  11  14 363]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.73       400\n",
      "           1       0.62      0.83      0.71       400\n",
      "           2       0.83      0.44      0.57       400\n",
      "           3       1.00      0.91      0.95       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.78      0.75      0.74      1600\n",
      "weighted avg       0.78      0.75      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "600/600 - 14s - loss: 0.1064 - acc: 0.9646 - val_loss: 0.7980 - val_acc: 0.7894 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  12\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.778125\n",
      "Confusion Matrix:\n",
      "[[323  46  27   4]\n",
      " [ 62 324  13   1]\n",
      " [112  77 204   7]\n",
      " [  6   0   0 394]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.72       400\n",
      "           1       0.72      0.81      0.77       400\n",
      "           2       0.84      0.51      0.63       400\n",
      "           3       0.97      0.98      0.98       400\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.79      0.78      0.77      1600\n",
      "weighted avg       0.79      0.78      0.77      1600\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "600/600 - 13s - loss: 0.0883 - acc: 0.9694 - val_loss: 1.1578 - val_acc: 0.7013 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  13\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.69\n",
      "Confusion Matrix:\n",
      "[[257 130  13   0]\n",
      " [ 12 385   3   0]\n",
      " [ 55 201 144   0]\n",
      " [ 35  42   5 318]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       400\n",
      "           1       0.51      0.96      0.66       400\n",
      "           2       0.87      0.36      0.51       400\n",
      "           3       1.00      0.80      0.89       400\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.77      0.69      0.68      1600\n",
      "weighted avg       0.77      0.69      0.68      1600\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "600/600 - 14s - loss: 0.1099 - acc: 0.9654 - val_loss: 1.3691 - val_acc: 0.6531 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  14\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.63\n",
      "Confusion Matrix:\n",
      "[[280  17   7  96]\n",
      " [ 79 230   5  86]\n",
      " [ 76  61  98 165]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       400\n",
      "           1       0.75      0.57      0.65       400\n",
      "           2       0.89      0.24      0.38       400\n",
      "           3       0.54      1.00      0.70       400\n",
      "\n",
      "    accuracy                           0.63      1600\n",
      "   macro avg       0.70      0.63      0.60      1600\n",
      "weighted avg       0.70      0.63      0.60      1600\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "600/600 - 14s - loss: 0.1015 - acc: 0.9656 - val_loss: 0.9195 - val_acc: 0.7437 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  15\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.744375\n",
      "Confusion Matrix:\n",
      "[[219  57  52  72]\n",
      " [ 29 311  23  37]\n",
      " [ 12  55 261  72]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.55      0.66       400\n",
      "           1       0.74      0.78      0.76       400\n",
      "           2       0.78      0.65      0.71       400\n",
      "           3       0.69      1.00      0.82       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.76      0.74      0.74      1600\n",
      "weighted avg       0.76      0.74      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "600/600 - 14s - loss: 0.0935 - acc: 0.9677 - val_loss: 0.9106 - val_acc: 0.7556 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  16\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.730625\n",
      "Confusion Matrix:\n",
      "[[128  60 165  47]\n",
      " [ 12 319  66   3]\n",
      " [  5  68 322   5]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.32      0.47       400\n",
      "           1       0.71      0.80      0.75       400\n",
      "           2       0.58      0.81      0.68       400\n",
      "           3       0.88      1.00      0.94       400\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.76      0.73      0.71      1600\n",
      "weighted avg       0.76      0.73      0.71      1600\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "600/600 - 14s - loss: 0.0736 - acc: 0.9775 - val_loss: 0.6763 - val_acc: 0.8244 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  17\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.80875\n",
      "Confusion Matrix:\n",
      "[[312  71  17   0]\n",
      " [ 52 341   7   0]\n",
      " [ 50 105 244   1]\n",
      " [  2   0   1 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       400\n",
      "           1       0.66      0.85      0.74       400\n",
      "           2       0.91      0.61      0.73       400\n",
      "           3       1.00      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.83      0.81      0.81      1600\n",
      "weighted avg       0.83      0.81      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "600/600 - 14s - loss: 0.0759 - acc: 0.9742 - val_loss: 0.7631 - val_acc: 0.8106 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  18\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.745\n",
      "Confusion Matrix:\n",
      "[[230  82  87   1]\n",
      " [ 30 359  10   1]\n",
      " [  9 148 243   0]\n",
      " [ 18   6  16 360]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67       400\n",
      "           1       0.60      0.90      0.72       400\n",
      "           2       0.68      0.61      0.64       400\n",
      "           3       0.99      0.90      0.94       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.77      0.74      0.74      1600\n",
      "weighted avg       0.77      0.74      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "600/600 - 14s - loss: 0.0738 - acc: 0.9760 - val_loss: 0.7298 - val_acc: 0.8069 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  19\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.74\n",
      "Confusion Matrix:\n",
      "[[183 160  57   0]\n",
      " [  6 386   8   0]\n",
      " [  9 132 259   0]\n",
      " [ 26  12   6 356]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.46      0.59       400\n",
      "           1       0.56      0.96      0.71       400\n",
      "           2       0.78      0.65      0.71       400\n",
      "           3       1.00      0.89      0.94       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.79      0.74      0.74      1600\n",
      "weighted avg       0.79      0.74      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "600/600 - 14s - loss: 0.0470 - acc: 0.9825 - val_loss: 1.1058 - val_acc: 0.7700 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  20\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.73625\n",
      "Confusion Matrix:\n",
      "[[143  58 199   0]\n",
      " [  4 317  79   0]\n",
      " [  1  27 372   0]\n",
      " [  5   6  43 346]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.36      0.52       400\n",
      "           1       0.78      0.79      0.78       400\n",
      "           2       0.54      0.93      0.68       400\n",
      "           3       1.00      0.86      0.93       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.81      0.74      0.73      1600\n",
      "weighted avg       0.81      0.74      0.73      1600\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "600/600 - 13s - loss: 0.1069 - acc: 0.9627 - val_loss: 0.6630 - val_acc: 0.8194 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  21\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.825\n",
      "Confusion Matrix:\n",
      "[[315  58  27   0]\n",
      " [ 48 349   3   0]\n",
      " [ 46  96 257   1]\n",
      " [  0   1   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       400\n",
      "           1       0.69      0.87      0.77       400\n",
      "           2       0.90      0.64      0.75       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.84      0.83      0.82      1600\n",
      "weighted avg       0.84      0.82      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "600/600 - 14s - loss: 0.0452 - acc: 0.9852 - val_loss: 0.7235 - val_acc: 0.8031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  22\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.794375\n",
      "Confusion Matrix:\n",
      "[[269  50  53  28]\n",
      " [ 41 319  16  24]\n",
      " [ 29  44 283  44]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.73       400\n",
      "           1       0.77      0.80      0.78       400\n",
      "           2       0.80      0.71      0.75       400\n",
      "           3       0.81      1.00      0.89       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.79      0.79      0.79      1600\n",
      "weighted avg       0.79      0.79      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "600/600 - 14s - loss: 0.0396 - acc: 0.9852 - val_loss: 3.5755 - val_acc: 0.4694 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  23\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.444375\n",
      "Confusion Matrix:\n",
      "[[113 287   0   0]\n",
      " [  1 399   0   0]\n",
      " [  8 355  37   0]\n",
      " [ 44 187   7 162]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.28      0.40       400\n",
      "           1       0.32      1.00      0.49       400\n",
      "           2       0.84      0.09      0.17       400\n",
      "           3       1.00      0.41      0.58       400\n",
      "\n",
      "    accuracy                           0.44      1600\n",
      "   macro avg       0.71      0.44      0.41      1600\n",
      "weighted avg       0.71      0.44      0.41      1600\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "600/600 - 14s - loss: 0.0664 - acc: 0.9790 - val_loss: 1.0352 - val_acc: 0.7525 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  24\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.73125\n",
      "Confusion Matrix:\n",
      "[[213  10 157  20]\n",
      " [ 22 192 140  46]\n",
      " [ 14   6 365  15]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.53      0.66       400\n",
      "           1       0.92      0.48      0.63       400\n",
      "           2       0.55      0.91      0.69       400\n",
      "           3       0.83      1.00      0.91       400\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.79      0.73      0.72      1600\n",
      "weighted avg       0.79      0.73      0.72      1600\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "600/600 - 14s - loss: 0.0337 - acc: 0.9881 - val_loss: 0.7752 - val_acc: 0.7987 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  25\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.784375\n",
      "Confusion Matrix:\n",
      "[[218  42 104  36]\n",
      " [ 22 315  55   8]\n",
      " [ 14  41 323  22]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67       400\n",
      "           1       0.79      0.79      0.79       400\n",
      "           2       0.67      0.81      0.73       400\n",
      "           3       0.86      1.00      0.92       400\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.79      0.78      0.78      1600\n",
      "weighted avg       0.79      0.78      0.78      1600\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "600/600 - 13s - loss: 0.0617 - acc: 0.9783 - val_loss: 0.8452 - val_acc: 0.7675 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  26\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.759375\n",
      "Confusion Matrix:\n",
      "[[184 117  38  61]\n",
      " [ 10 361  16  13]\n",
      " [ 28  84 270  18]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.46      0.59       400\n",
      "           1       0.64      0.90      0.75       400\n",
      "           2       0.83      0.68      0.75       400\n",
      "           3       0.81      1.00      0.90       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.78      0.76      0.75      1600\n",
      "weighted avg       0.78      0.76      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "600/600 - 14s - loss: 0.0687 - acc: 0.9765 - val_loss: 0.8147 - val_acc: 0.7806 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  27\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.791875\n",
      "Confusion Matrix:\n",
      "[[286  37  36  41]\n",
      " [ 38 322  27  13]\n",
      " [ 21  43 259  77]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77       400\n",
      "           1       0.80      0.81      0.80       400\n",
      "           2       0.80      0.65      0.72       400\n",
      "           3       0.75      1.00      0.86       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.80      0.79      0.79      1600\n",
      "weighted avg       0.80      0.79      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "600/600 - 14s - loss: 0.0413 - acc: 0.9840 - val_loss: 0.8436 - val_acc: 0.7681 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  28\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.76125\n",
      "Confusion Matrix:\n",
      "[[254  68  25  53]\n",
      " [ 29 355   5  11]\n",
      " [ 45  77 209  69]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70       400\n",
      "           1       0.71      0.89      0.79       400\n",
      "           2       0.87      0.52      0.65       400\n",
      "           3       0.75      1.00      0.86       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.78      0.76      0.75      1600\n",
      "weighted avg       0.78      0.76      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "600/600 - 13s - loss: 0.0342 - acc: 0.9892 - val_loss: 0.5227 - val_acc: 0.8644 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  29\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[275  73  50   2]\n",
      " [ 22 361  17   0]\n",
      " [ 27  81 291   1]\n",
      " [  0   1   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       400\n",
      "           1       0.70      0.90      0.79       400\n",
      "           2       0.81      0.73      0.77       400\n",
      "           3       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.84      0.83      0.83      1600\n",
      "weighted avg       0.84      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "600/600 - 14s - loss: 0.0586 - acc: 0.9812 - val_loss: 0.6787 - val_acc: 0.8081 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  30\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 11ms/step\n",
      "Accuracy: 0.796875\n",
      "Confusion Matrix:\n",
      "[[224  79  59  38]\n",
      " [ 13 360  20   7]\n",
      " [ 10  67 291  32]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       400\n",
      "           1       0.71      0.90      0.79       400\n",
      "           2       0.79      0.73      0.76       400\n",
      "           3       0.84      1.00      0.91       400\n",
      "\n",
      "    accuracy                           0.80      1600\n",
      "   macro avg       0.81      0.80      0.79      1600\n",
      "weighted avg       0.81      0.80      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  31\n",
      "600/600 - 14s - loss: 0.0282 - acc: 0.9908 - val_loss: 0.4745 - val_acc: 0.8763 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  31\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.843125\n",
      "Confusion Matrix:\n",
      "[[247  48 104   1]\n",
      " [ 23 330  47   0]\n",
      " [ 11  17 372   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73       400\n",
      "           1       0.84      0.82      0.83       400\n",
      "           2       0.71      0.93      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  32\n",
      "600/600 - 13s - loss: 0.0081 - acc: 0.9983 - val_loss: 0.6429 - val_acc: 0.8600 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  32\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.8225\n",
      "Confusion Matrix:\n",
      "[[223  43 133   1]\n",
      " [ 22 317  61   0]\n",
      " [  9  15 376   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.56      0.68       400\n",
      "           1       0.85      0.79      0.82       400\n",
      "           2       0.66      0.94      0.78       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.85      0.82      0.82      1600\n",
      "weighted avg       0.85      0.82      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  33\n",
      "600/600 - 14s - loss: 0.0032 - acc: 0.9994 - val_loss: 0.5222 - val_acc: 0.8763 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  33\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.84625\n",
      "Confusion Matrix:\n",
      "[[255  56  89   0]\n",
      " [ 24 345  31   0]\n",
      " [ 11  35 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74       400\n",
      "           1       0.79      0.86      0.83       400\n",
      "           2       0.75      0.89      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.85      0.85      0.84      1600\n",
      "weighted avg       0.85      0.85      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  34\n",
      "600/600 - 13s - loss: 0.1085 - acc: 0.9638 - val_loss: 0.7963 - val_acc: 0.7638 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  34\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[225  86  24  65]\n",
      " [ 10 371   6  13]\n",
      " [ 19 104 204  73]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69       400\n",
      "           1       0.66      0.93      0.77       400\n",
      "           2       0.87      0.51      0.64       400\n",
      "           3       0.73      1.00      0.84       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.79      0.75      0.74      1600\n",
      "weighted avg       0.79      0.75      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  35\n",
      "600/600 - 13s - loss: 0.0248 - acc: 0.9927 - val_loss: 1.4874 - val_acc: 0.6825 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  35\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.696875\n",
      "Confusion Matrix:\n",
      "[[ 51  65  40 244]\n",
      " [  2 356  25  17]\n",
      " [  4  37 308  51]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.13      0.22       400\n",
      "           1       0.78      0.89      0.83       400\n",
      "           2       0.83      0.77      0.80       400\n",
      "           3       0.56      1.00      0.72       400\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.76      0.70      0.64      1600\n",
      "weighted avg       0.76      0.70      0.64      1600\n",
      "\n",
      "\n",
      "Epoch:  36\n",
      "600/600 - 14s - loss: 0.0168 - acc: 0.9958 - val_loss: 0.6408 - val_acc: 0.8369 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  36\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.82875\n",
      "Confusion Matrix:\n",
      "[[265  30  85  20]\n",
      " [ 41 329  27   3]\n",
      " [ 17  42 332   9]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73       400\n",
      "           1       0.82      0.82      0.82       400\n",
      "           2       0.75      0.83      0.79       400\n",
      "           3       0.93      1.00      0.96       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.83      0.83      0.83      1600\n",
      "weighted avg       0.83      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  37\n",
      "600/600 - 14s - loss: 0.0637 - acc: 0.9787 - val_loss: 0.9939 - val_acc: 0.7894 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  37\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.7625\n",
      "Confusion Matrix:\n",
      "[[296  78  11  15]\n",
      " [ 43 350   2   5]\n",
      " [ 77 113 174  36]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       400\n",
      "           1       0.65      0.88      0.74       400\n",
      "           2       0.93      0.43      0.59       400\n",
      "           3       0.88      1.00      0.93       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.79      0.76      0.75      1600\n",
      "weighted avg       0.79      0.76      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  38\n",
      "600/600 - 14s - loss: 0.0337 - acc: 0.9904 - val_loss: 0.4691 - val_acc: 0.8725 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  38\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.84375\n",
      "Confusion Matrix:\n",
      "[[254  37 109   0]\n",
      " [ 19 347  34   0]\n",
      " [ 10  38 352   0]\n",
      " [  3   0   0 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.64      0.74       400\n",
      "           1       0.82      0.87      0.84       400\n",
      "           2       0.71      0.88      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  39\n",
      "600/600 - 14s - loss: 0.0100 - acc: 0.9971 - val_loss: 0.6780 - val_acc: 0.8163 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  39\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.795\n",
      "Confusion Matrix:\n",
      "[[295  19  86   0]\n",
      " [ 40 330  30   0]\n",
      " [ 19  25 356   0]\n",
      " [ 52   2  55 291]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       400\n",
      "           1       0.88      0.82      0.85       400\n",
      "           2       0.68      0.89      0.77       400\n",
      "           3       1.00      0.73      0.84       400\n",
      "\n",
      "    accuracy                           0.80      1600\n",
      "   macro avg       0.82      0.80      0.80      1600\n",
      "weighted avg       0.82      0.80      0.80      1600\n",
      "\n",
      "\n",
      "Epoch:  40\n",
      "600/600 - 13s - loss: 0.0047 - acc: 0.9992 - val_loss: 0.4767 - val_acc: 0.8825 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  40\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.858125\n",
      "Confusion Matrix:\n",
      "[[271  46  82   1]\n",
      " [ 21 360  19   0]\n",
      " [ 13  45 342   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77       400\n",
      "           1       0.80      0.90      0.85       400\n",
      "           2       0.77      0.85      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.86      0.86      0.86      1600\n",
      "weighted avg       0.86      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  41\n",
      "600/600 - 14s - loss: 4.8172e-04 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.8925 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  41\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.8575\n",
      "Confusion Matrix:\n",
      "[[255  57  88   0]\n",
      " [ 13 368  19   0]\n",
      " [ 11  40 349   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.79      0.92      0.85       400\n",
      "           2       0.77      0.87      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  42\n",
      "600/600 - 14s - loss: 1.9495e-04 - acc: 1.0000 - val_loss: 0.4821 - val_acc: 0.8938 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  42\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[255  56  89   0]\n",
      " [ 14 368  18   0]\n",
      " [ 10  38 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  43\n",
      "600/600 - 14s - loss: 1.3614e-04 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8950 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  43\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[254  56  90   0]\n",
      " [ 14 368  18   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  44\n",
      "600/600 - 13s - loss: 1.0098e-04 - acc: 1.0000 - val_loss: 0.5001 - val_acc: 0.8950 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  44\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[254  56  90   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.86       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  45\n",
      "600/600 - 13s - loss: 7.6168e-05 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8956 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  45\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[254  56  90   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.86       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  46\n",
      "600/600 - 14s - loss: 5.7870e-05 - acc: 1.0000 - val_loss: 0.5214 - val_acc: 0.8956 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  46\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[254  57  89   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  38 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  47\n",
      "600/600 - 14s - loss: 4.4050e-05 - acc: 1.0000 - val_loss: 0.5329 - val_acc: 0.8975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  47\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[254  57  89   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.86       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  48\n",
      "600/600 - 13s - loss: 3.3549e-05 - acc: 1.0000 - val_loss: 0.5450 - val_acc: 0.8975 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  48\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[254  57  89   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75       400\n",
      "           1       0.80      0.92      0.86       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  49\n",
      "600/600 - 13s - loss: 2.5535e-05 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.8969 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  49\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[253  58  89   0]\n",
      " [ 14 369  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.63      0.75       400\n",
      "           1       0.80      0.92      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  50\n",
      "600/600 - 14s - loss: 1.9409e-05 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.8969 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  50\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[252  59  89   0]\n",
      " [ 13 370  17   0]\n",
      " [ 10  37 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75       400\n",
      "           1       0.79      0.93      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  51\n",
      "600/600 - 14s - loss: 1.4728e-05 - acc: 1.0000 - val_loss: 0.5842 - val_acc: 0.8963 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  51\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[252  58  90   0]\n",
      " [ 13 370  17   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  52\n",
      "600/600 - 14s - loss: 1.1160e-05 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8956 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  52\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[250  60  90   0]\n",
      " [ 13 371  16   0]\n",
      " [ 10  35 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  53\n",
      "600/600 - 13s - loss: 8.4509e-06 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.8963 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  53\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[250  61  89   0]\n",
      " [ 13 371  16   0]\n",
      " [ 10  35 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       400\n",
      "           1       0.79      0.93      0.86       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  54\n",
      "600/600 - 14s - loss: 6.3891e-06 - acc: 1.0000 - val_loss: 0.6272 - val_acc: 0.8969 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  54\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[250  62  88   0]\n",
      " [ 13 371  16   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       400\n",
      "           1       0.79      0.93      0.85       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  55\n",
      "600/600 - 14s - loss: 4.8223e-06 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 0.8969 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  55\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.85875\n",
      "Confusion Matrix:\n",
      "[[249  64  87   0]\n",
      " [ 13 370  17   0]\n",
      " [ 10  35 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       400\n",
      "           1       0.79      0.93      0.85       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  56\n",
      "600/600 - 14s - loss: 3.6319e-06 - acc: 1.0000 - val_loss: 0.6572 - val_acc: 0.8969 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  56\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.858125\n",
      "Confusion Matrix:\n",
      "[[248  65  87   0]\n",
      " [ 13 370  17   0]\n",
      " [ 10  35 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74       400\n",
      "           1       0.79      0.93      0.85       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  57\n",
      "600/600 - 14s - loss: 2.7322e-06 - acc: 1.0000 - val_loss: 0.6725 - val_acc: 0.8981 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  57\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.85625\n",
      "Confusion Matrix:\n",
      "[[246  66  88   0]\n",
      " [ 13 369  18   0]\n",
      " [ 10  35 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.74       400\n",
      "           1       0.79      0.92      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  58\n",
      "600/600 - 13s - loss: 2.0516e-06 - acc: 1.0000 - val_loss: 0.6882 - val_acc: 0.8981 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  58\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855625\n",
      "Confusion Matrix:\n",
      "[[246  66  88   0]\n",
      " [ 13 369  18   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.74       400\n",
      "           1       0.78      0.92      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  59\n",
      "600/600 - 13s - loss: 1.5367e-06 - acc: 1.0000 - val_loss: 0.7040 - val_acc: 0.8988 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  59\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855625\n",
      "Confusion Matrix:\n",
      "[[246  67  87   0]\n",
      " [ 13 369  18   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.74       400\n",
      "           1       0.78      0.92      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  60\n",
      "600/600 - 14s - loss: 1.1510e-06 - acc: 1.0000 - val_loss: 0.7202 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  60\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.855625\n",
      "Confusion Matrix:\n",
      "[[246  67  87   0]\n",
      " [ 13 369  18   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.74       400\n",
      "           1       0.78      0.92      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  61\n",
      "600/600 - 14s - loss: 8.5905e-07 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  61\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.85625\n",
      "Confusion Matrix:\n",
      "[[247  67  86   0]\n",
      " [ 13 369  18   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74       400\n",
      "           1       0.78      0.92      0.85       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  62\n",
      "600/600 - 14s - loss: 6.4246e-07 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.8975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  62\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[245  67  87   1]\n",
      " [ 13 369  18   0]\n",
      " [ 10  36 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73       400\n",
      "           1       0.78      0.92      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  63\n",
      "600/600 - 13s - loss: 4.8386e-07 - acc: 1.0000 - val_loss: 0.7673 - val_acc: 0.8981 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  63\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[244  68  87   1]\n",
      " [ 12 371  17   0]\n",
      " [ 10  38 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.61      0.73       400\n",
      "           1       0.78      0.93      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  64\n",
      "600/600 - 14s - loss: 3.9376e-07 - acc: 1.0000 - val_loss: 0.7909 - val_acc: 0.8963 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  64\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.855625\n",
      "Confusion Matrix:\n",
      "[[244  66  89   1]\n",
      " [ 11 371  18   0]\n",
      " [  9  37 354   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.61      0.73       400\n",
      "           1       0.78      0.93      0.85       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  65\n",
      "600/600 - 14s - loss: 0.2470 - acc: 0.9348 - val_loss: 0.8543 - val_acc: 0.7500 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  65\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.754375\n",
      "Confusion Matrix:\n",
      "[[164   4 215  17]\n",
      " [ 18 251 131   0]\n",
      " [  1   5 392   2]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.41      0.56       400\n",
      "           1       0.97      0.63      0.76       400\n",
      "           2       0.53      0.98      0.69       400\n",
      "           3       0.95      1.00      0.98       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.84      0.75      0.75      1600\n",
      "weighted avg       0.84      0.75      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  66\n",
      "600/600 - 14s - loss: 0.0583 - acc: 0.9819 - val_loss: 0.4409 - val_acc: 0.8719 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  66\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.87625\n",
      "Confusion Matrix:\n",
      "[[304  23  73   0]\n",
      " [ 33 343  24   0]\n",
      " [ 19  25 356   0]\n",
      " [  0   1   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       400\n",
      "           1       0.88      0.86      0.87       400\n",
      "           2       0.79      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.88      0.88      0.88      1600\n",
      "weighted avg       0.88      0.88      0.88      1600\n",
      "\n",
      "\n",
      "Epoch:  67\n",
      "600/600 - 13s - loss: 0.0096 - acc: 0.9975 - val_loss: 0.4130 - val_acc: 0.8950 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  67\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[255  42 103   0]\n",
      " [ 19 360  21   0]\n",
      " [ 12  36 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.64      0.74       400\n",
      "           1       0.82      0.90      0.86       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  68\n",
      "600/600 - 13s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.4875 - val_acc: 0.8831 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  68\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.84375\n",
      "Confusion Matrix:\n",
      "[[246  37 117   0]\n",
      " [ 13 350  37   0]\n",
      " [ 13  32 355   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73       400\n",
      "           1       0.84      0.88      0.85       400\n",
      "           2       0.70      0.89      0.78       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  69\n",
      "600/600 - 14s - loss: 0.0303 - acc: 0.9900 - val_loss: 0.6042 - val_acc: 0.8637 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  69\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.810625\n",
      "Confusion Matrix:\n",
      "[[192 117  91   0]\n",
      " [ 13 378   9   0]\n",
      " [ 11  60 329   0]\n",
      " [  1   1   0 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.48      0.62       400\n",
      "           1       0.68      0.94      0.79       400\n",
      "           2       0.77      0.82      0.79       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.83      0.81      0.80      1600\n",
      "weighted avg       0.83      0.81      0.80      1600\n",
      "\n",
      "\n",
      "Epoch:  70\n",
      "600/600 - 14s - loss: 0.0432 - acc: 0.9871 - val_loss: 0.7983 - val_acc: 0.8025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  70\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.7875\n",
      "Confusion Matrix:\n",
      "[[158  20 203  19]\n",
      " [ 10 327  61   2]\n",
      " [  2  16 375   7]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.40      0.55       400\n",
      "           1       0.90      0.82      0.86       400\n",
      "           2       0.59      0.94      0.72       400\n",
      "           3       0.93      1.00      0.97       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.84      0.79      0.77      1600\n",
      "weighted avg       0.84      0.79      0.77      1600\n",
      "\n",
      "\n",
      "Epoch:  71\n",
      "600/600 - 14s - loss: 0.0081 - acc: 0.9985 - val_loss: 0.4342 - val_acc: 0.8906 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  71\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.83375\n",
      "Confusion Matrix:\n",
      "[[220  93  86   1]\n",
      " [  8 378  14   0]\n",
      " [ 13  51 336   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69       400\n",
      "           1       0.72      0.94      0.82       400\n",
      "           2       0.77      0.84      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  72\n",
      "600/600 - 14s - loss: 0.0054 - acc: 0.9985 - val_loss: 0.9048 - val_acc: 0.7656 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  72\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.76625\n",
      "Confusion Matrix:\n",
      "[[213   9  80  98]\n",
      " [ 37 281  43  39]\n",
      " [  8   6 332  54]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.65       400\n",
      "           1       0.95      0.70      0.81       400\n",
      "           2       0.73      0.83      0.78       400\n",
      "           3       0.68      1.00      0.81       400\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.80      0.77      0.76      1600\n",
      "weighted avg       0.80      0.77      0.76      1600\n",
      "\n",
      "\n",
      "Epoch:  73\n",
      "600/600 - 13s - loss: 0.0918 - acc: 0.9702 - val_loss: 0.8575 - val_acc: 0.8006 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  73\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.7475\n",
      "Confusion Matrix:\n",
      "[[ 95 183  83  39]\n",
      " [  0 381  17   2]\n",
      " [  2  48 320  30]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.24      0.38       400\n",
      "           1       0.62      0.95      0.75       400\n",
      "           2       0.76      0.80      0.78       400\n",
      "           3       0.85      1.00      0.92       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.80      0.75      0.71      1600\n",
      "weighted avg       0.80      0.75      0.71      1600\n",
      "\n",
      "\n",
      "Epoch:  74\n",
      "600/600 - 14s - loss: 0.0241 - acc: 0.9927 - val_loss: 0.4620 - val_acc: 0.8788 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  74\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.864375\n",
      "Confusion Matrix:\n",
      "[[266  73  60   1]\n",
      " [  7 382  11   0]\n",
      " [ 21  43 336   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77       400\n",
      "           1       0.77      0.95      0.85       400\n",
      "           2       0.83      0.84      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  75\n",
      "600/600 - 14s - loss: 0.0092 - acc: 0.9973 - val_loss: 0.4544 - val_acc: 0.8938 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  75\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.869375\n",
      "Confusion Matrix:\n",
      "[[272  28 100   0]\n",
      " [ 16 355  29   0]\n",
      " [ 14  21 365   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.77       400\n",
      "           1       0.88      0.89      0.88       400\n",
      "           2       0.74      0.91      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.87      1600\n",
      "weighted avg       0.88      0.87      0.87      1600\n",
      "\n",
      "\n",
      "Epoch:  76\n",
      "600/600 - 14s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4414 - val_acc: 0.8944 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  76\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.868125\n",
      "Confusion Matrix:\n",
      "[[273  41  86   0]\n",
      " [ 14 362  24   0]\n",
      " [ 14  31 355   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       400\n",
      "           1       0.83      0.91      0.87       400\n",
      "           2       0.76      0.89      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.87      1600\n",
      "weighted avg       0.88      0.87      0.87      1600\n",
      "\n",
      "\n",
      "Epoch:  77\n",
      "600/600 - 14s - loss: 2.6888e-04 - acc: 1.0000 - val_loss: 0.4495 - val_acc: 0.8975 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  77\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86625\n",
      "Confusion Matrix:\n",
      "[[268  51  81   0]\n",
      " [ 12 365  23   0]\n",
      " [ 15  30 355   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77       400\n",
      "           1       0.82      0.91      0.86       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.87      0.87      0.86      1600\n",
      "weighted avg       0.87      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  78\n",
      "600/600 - 13s - loss: 1.8097e-04 - acc: 1.0000 - val_loss: 0.4605 - val_acc: 0.9000 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  78\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.865\n",
      "Confusion Matrix:\n",
      "[[265  50  85   0]\n",
      " [ 12 366  22   0]\n",
      " [ 15  30 355   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       400\n",
      "           1       0.82      0.92      0.87       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  79\n",
      "600/600 - 13s - loss: 1.3147e-04 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.8994 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  79\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.864375\n",
      "Confusion Matrix:\n",
      "[[263  52  85   0]\n",
      " [ 11 367  22   0]\n",
      " [ 15  30 355   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.66      0.76       400\n",
      "           1       0.82      0.92      0.86       400\n",
      "           2       0.77      0.89      0.82       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  80\n",
      "600/600 - 13s - loss: 9.7763e-05 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8981 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  80\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.864375\n",
      "Confusion Matrix:\n",
      "[[260  55  85   0]\n",
      " [ 10 369  21   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76       400\n",
      "           1       0.81      0.92      0.86       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  81\n",
      "600/600 - 14s - loss: 7.3404e-05 - acc: 1.0000 - val_loss: 0.4962 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  81\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86625\n",
      "Confusion Matrix:\n",
      "[[261  55  84   0]\n",
      " [  9 371  20   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  82\n",
      "600/600 - 14s - loss: 5.5396e-05 - acc: 1.0000 - val_loss: 0.5089 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  82\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.866875\n",
      "Confusion Matrix:\n",
      "[[262  55  83   0]\n",
      " [  9 371  20   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.76       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  83\n",
      "600/600 - 14s - loss: 4.1877e-05 - acc: 1.0000 - val_loss: 0.5220 - val_acc: 0.9000 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  83\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[260  57  83   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.87      0.87      0.86      1600\n",
      "weighted avg       0.87      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  84\n",
      "600/600 - 14s - loss: 3.1656e-05 - acc: 1.0000 - val_loss: 0.5355 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  84\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.86625\n",
      "Confusion Matrix:\n",
      "[[260  58  82   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.87      0.87      0.86      1600\n",
      "weighted avg       0.87      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  85\n",
      "600/600 - 14s - loss: 2.3912e-05 - acc: 1.0000 - val_loss: 0.5492 - val_acc: 0.9000 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  85\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.866875\n",
      "Confusion Matrix:\n",
      "[[261  58  81   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  30 356   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  86\n",
      "600/600 - 14s - loss: 1.8055e-05 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  86\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.868125\n",
      "Confusion Matrix:\n",
      "[[262  58  80   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  30 356   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.87      1600\n",
      "weighted avg       0.88      0.87      0.87      1600\n",
      "\n",
      "\n",
      "Epoch:  87\n",
      "600/600 - 14s - loss: 1.3630e-05 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  87\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.8675\n",
      "Confusion Matrix:\n",
      "[[262  58  80   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  31 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  88\n",
      "600/600 - 14s - loss: 1.0272e-05 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  88\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.866875\n",
      "Confusion Matrix:\n",
      "[[261  58  81   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  31 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  89\n",
      "600/600 - 14s - loss: 7.7288e-06 - acc: 1.0000 - val_loss: 0.6077 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  89\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.866875\n",
      "Confusion Matrix:\n",
      "[[261  58  81   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  31 355   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.78      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  90\n",
      "600/600 - 14s - loss: 5.8038e-06 - acc: 1.0000 - val_loss: 0.6229 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  90\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.865\n",
      "Confusion Matrix:\n",
      "[[260  59  81   0]\n",
      " [ 10 371  19   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  91\n",
      "600/600 - 14s - loss: 4.3545e-06 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  91\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[260  59  81   0]\n",
      " [ 10 372  18   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.87      0.87      0.86      1600\n",
      "weighted avg       0.87      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  92\n",
      "600/600 - 14s - loss: 3.2682e-06 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  92\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.865\n",
      "Confusion Matrix:\n",
      "[[259  60  81   0]\n",
      " [ 10 372  18   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  93\n",
      "600/600 - 14s - loss: 2.4494e-06 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  93\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.864375\n",
      "Confusion Matrix:\n",
      "[[257  61  82   0]\n",
      " [  9 373  18   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  94\n",
      "600/600 - 14s - loss: 1.8343e-06 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  94\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.864375\n",
      "Confusion Matrix:\n",
      "[[256  61  83   0]\n",
      " [  9 374  17   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.75       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  95\n",
      "600/600 - 14s - loss: 1.3721e-06 - acc: 1.0000 - val_loss: 0.7018 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  95\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.865\n",
      "Confusion Matrix:\n",
      "[[257  61  82   0]\n",
      " [  9 374  17   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  96\n",
      "600/600 - 14s - loss: 1.0233e-06 - acc: 1.0000 - val_loss: 0.7182 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  96\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[257  61  82   0]\n",
      " [  8 375  17   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  97\n",
      "600/600 - 14s - loss: 7.6301e-07 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  97\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[257  61  82   0]\n",
      " [  8 375  17   0]\n",
      " [ 14  33 353   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  98\n",
      "600/600 - 14s - loss: 5.6781e-07 - acc: 1.0000 - val_loss: 0.7511 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  98\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[258  61  81   0]\n",
      " [  8 375  17   0]\n",
      " [ 14  34 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  99\n",
      "600/600 - 13s - loss: 4.2329e-07 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.8988 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  99\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.86625\n",
      "Confusion Matrix:\n",
      "[[258  61  81   0]\n",
      " [  8 376  16   0]\n",
      " [ 14  34 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  100\n",
      "600/600 - 14s - loss: 3.1513e-07 - acc: 1.0000 - val_loss: 0.7845 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  100\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[257  62  81   0]\n",
      " [  8 376  16   0]\n",
      " [ 14  34 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n",
      "Testing time (s) = 2986.8532210988924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_training, labels_training, batch_size=batch_size, epochs = 1, validation_data=(x_val_norm, y_val), verbose=2)\n",
    "    model.save('./RNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    \n",
    "    y_pred = model.predict(test_dataset)\n",
    "\n",
    "    y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_dataset_label, y_pred_label))\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d4ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.865625\n",
      "Confusion Matrix:\n",
      "[[257  62  81   0]\n",
      " [  8 376  16   0]\n",
      " [ 14  34 352   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.76       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.78      0.88      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.86      1600\n",
      "weighted avg       0.88      0.87      0.86      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06167d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af1a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwheatenv",
   "language": "python",
   "name": "dwheatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
