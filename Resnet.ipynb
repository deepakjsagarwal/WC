{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 13:22:05.734383: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 13:22:08.545257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/tyagi/Desktop/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TRAIN_IMAGE_COUNT = 1200\n",
    "VAL_IMAGE_COUNT = 400\n",
    "TEST_IMAGE_COUNT = 400\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "LEARNING_RATE_BASE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "    \n",
    "FILTER = filter_method(2).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(0).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/V\"+str(variety).zfill(3)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n",
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    x_train= x_train + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    y_train = y_train + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    x_val= x_val + np.load(dataset_file_name(v)+\"_val_dataset.npy\").tolist()\n",
    "    y_val = y_val + np.load(dataset_file_name(v)+\"_val_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca90232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    print(\"Testing started\")\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "    \n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix_results,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_integer_format, labels_predicted_integer_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb608fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90729707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_block(x, filters, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def identity_block(x, filters):\n",
    "    x_identity = x\n",
    "\n",
    "    x = conv_block(x, filters)\n",
    "    x = layers.Add()([x, x_identity])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), use_bias=False, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = conv_block(x, filters=64, strides=1)\n",
    "    x = identity_block(x, filters=64)\n",
    "\n",
    "    x = conv_block(x, filters=128, strides=2)\n",
    "    x = identity_block(x, filters=128)\n",
    "\n",
    "    x = conv_block(x, filters=256, strides=2)\n",
    "    x = identity_block(x, filters=256)\n",
    "\n",
    "    x = conv_block(x, filters=512, strides=2)\n",
    "    x = identity_block(x, filters=512)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43cde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = np.array(x_train)\n",
    "labels_training = np.array(y_train)\n",
    "\n",
    "# Normalize the data\n",
    "x_training = normalizeDataWholeSeed(x_training,normalization_type='max')\n",
    "x_val_norm = normalizeDataWholeSeed(x_val,normalization_type=\"max\")\n",
    "test_dataset = normalizeDataWholeSeed(test_dataset,normalization_type='max')\n",
    "    \n",
    "# Extract some information\n",
    "num_training = x_training.shape[0]\n",
    "N_spatial = x_training.shape[1:3]\n",
    "N_bands = x_training.shape[3]\n",
    "batch_size = BATCH_SIZE\n",
    "num_batch_per_epoch = int(num_training/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ce95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(file_path, data_frame, header=False):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    if not file_exists or not header:\n",
    "        data_frame.to_csv(file_path, index=False, mode='w')\n",
    "    else:\n",
    "        data_frame.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08349c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HD 3086', 'PBW 291', 'DBW 187', 'DBW222']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9dcaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead0a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 13:26:44.713676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14644 MB memory:  -> device: 1, name: Quadro P5000, pci bus id: 0000:9b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RN_\"+\"_IC_\"+str(TRAIN_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "if REMOVE_NOISY_BANDS:\n",
    "    model_name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "if FILTER == \"savgol\":\n",
    "    model_name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "\n",
    "if start_epoch != 1:\n",
    "    model = tf.keras.models.load_model('./RNmodels/'+str(start_epoch-1)+model_name)\n",
    "else:\n",
    "    \n",
    "    input_shape = (30, 30, 168)\n",
    "    num_classes = 4\n",
    "    model = resnet18(input_shape, num_classes)\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627a2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74535028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 15, 15, 64)   526848      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     36864       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 64)     36864       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    73728       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 128)    147456      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 128)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 4, 4, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 2, 2, 256)    294912      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_10[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 2, 2, 256)    589824      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2, 2, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 1, 1, 512)    1179648     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 512)    2359296     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 1, 512)    0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 1, 1, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            2052        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,529,988\n",
      "Trainable params: 11,522,180\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3324c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 13:26:54.258116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 15s - loss: 1.5547 - acc: 0.3642 - val_loss: 1.7001 - val_acc: 0.4181 - 15s/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  1\n",
      "added to csv\n",
      "\n",
      "Epoch:  2\n",
      "600/600 - 13s - loss: 1.1787 - acc: 0.4812 - val_loss: 1.6673 - val_acc: 0.4400 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  2\n",
      "added to csv\n",
      "\n",
      "Epoch:  3\n",
      "600/600 - 13s - loss: 0.7990 - acc: 0.6596 - val_loss: 1.6282 - val_acc: 0.4087 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  3\n",
      "added to csv\n",
      "\n",
      "Epoch:  4\n",
      "600/600 - 13s - loss: 0.5991 - acc: 0.7602 - val_loss: 1.8134 - val_acc: 0.3919 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  4\n",
      "added to csv\n",
      "\n",
      "Epoch:  5\n",
      "600/600 - 13s - loss: 0.4139 - acc: 0.8471 - val_loss: 1.6103 - val_acc: 0.5113 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  5\n",
      "added to csv\n",
      "\n",
      "Epoch:  6\n",
      "600/600 - 13s - loss: 0.3467 - acc: 0.8731 - val_loss: 0.9663 - val_acc: 0.6581 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  6\n",
      "added to csv\n",
      "\n",
      "Epoch:  7\n",
      "600/600 - 13s - loss: 0.2507 - acc: 0.9108 - val_loss: 0.9387 - val_acc: 0.7175 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  7\n",
      "added to csv\n",
      "\n",
      "Epoch:  8\n",
      "600/600 - 13s - loss: 0.2131 - acc: 0.9225 - val_loss: 1.0149 - val_acc: 0.6856 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  8\n",
      "added to csv\n",
      "\n",
      "Epoch:  9\n",
      "600/600 - 13s - loss: 0.1674 - acc: 0.9413 - val_loss: 1.4432 - val_acc: 0.6712 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  9\n",
      "added to csv\n",
      "\n",
      "Epoch:  10\n",
      "600/600 - 13s - loss: 0.1641 - acc: 0.9448 - val_loss: 1.1850 - val_acc: 0.6700 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  10\n",
      "added to csv\n",
      "\n",
      "Epoch:  11\n",
      "600/600 - 13s - loss: 0.1219 - acc: 0.9550 - val_loss: 1.2943 - val_acc: 0.6419 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  11\n",
      "added to csv\n",
      "\n",
      "Epoch:  12\n",
      "600/600 - 13s - loss: 0.1411 - acc: 0.9506 - val_loss: 0.4790 - val_acc: 0.8400 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  12\n",
      "added to csv\n",
      "\n",
      "Epoch:  13\n",
      "600/600 - 13s - loss: 0.0753 - acc: 0.9746 - val_loss: 1.8676 - val_acc: 0.5819 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  13\n",
      "added to csv\n",
      "\n",
      "Epoch:  14\n",
      "600/600 - 13s - loss: 0.0852 - acc: 0.9737 - val_loss: 0.7709 - val_acc: 0.7812 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  14\n",
      "added to csv\n",
      "\n",
      "Epoch:  15\n",
      "600/600 - 13s - loss: 0.0994 - acc: 0.9679 - val_loss: 3.0100 - val_acc: 0.4756 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  15\n",
      "added to csv\n",
      "\n",
      "Epoch:  16\n",
      "600/600 - 13s - loss: 0.0966 - acc: 0.9652 - val_loss: 1.4101 - val_acc: 0.7231 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  16\n",
      "added to csv\n",
      "\n",
      "Epoch:  17\n",
      "600/600 - 13s - loss: 0.0894 - acc: 0.9681 - val_loss: 1.0131 - val_acc: 0.7788 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  17\n",
      "added to csv\n",
      "\n",
      "Epoch:  18\n",
      "600/600 - 13s - loss: 0.0452 - acc: 0.9848 - val_loss: 1.7095 - val_acc: 0.6137 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  18\n",
      "added to csv\n",
      "\n",
      "Epoch:  19\n",
      "600/600 - 13s - loss: 0.0599 - acc: 0.9810 - val_loss: 0.9739 - val_acc: 0.7412 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  19\n",
      "added to csv\n",
      "\n",
      "Epoch:  20\n",
      "600/600 - 20s - loss: 0.0891 - acc: 0.9667 - val_loss: 0.4975 - val_acc: 0.8631 - 20s/epoch - 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  20\n",
      "added to csv\n",
      "\n",
      "Epoch:  21\n",
      "600/600 - 20s - loss: 0.0691 - acc: 0.9779 - val_loss: 0.4855 - val_acc: 0.8669 - 20s/epoch - 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  21\n",
      "added to csv\n",
      "\n",
      "Epoch:  22\n",
      "600/600 - 18s - loss: 0.0439 - acc: 0.9842 - val_loss: 0.8979 - val_acc: 0.7700 - 18s/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  22\n",
      "added to csv\n",
      "\n",
      "Epoch:  23\n",
      "600/600 - 20s - loss: 0.0802 - acc: 0.9754 - val_loss: 0.8056 - val_acc: 0.8250 - 20s/epoch - 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  23\n",
      "added to csv\n",
      "\n",
      "Epoch:  24\n",
      "600/600 - 20s - loss: 0.0400 - acc: 0.9848 - val_loss: 0.8818 - val_acc: 0.8144 - 20s/epoch - 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  24\n",
      "added to csv\n",
      "\n",
      "Epoch:  25\n",
      "600/600 - 19s - loss: 0.0117 - acc: 0.9971 - val_loss: 0.5321 - val_acc: 0.8831 - 19s/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  25\n",
      "added to csv\n",
      "\n",
      "Epoch:  26\n",
      "600/600 - 20s - loss: 0.0834 - acc: 0.9727 - val_loss: 0.7909 - val_acc: 0.8100 - 20s/epoch - 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  26\n",
      "added to csv\n",
      "\n",
      "Epoch:  27\n",
      "600/600 - 20s - loss: 0.0831 - acc: 0.9715 - val_loss: 0.4261 - val_acc: 0.8819 - 20s/epoch - 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  27\n",
      "added to csv\n",
      "\n",
      "Epoch:  28\n",
      "600/600 - 19s - loss: 0.0219 - acc: 0.9927 - val_loss: 0.6025 - val_acc: 0.8506 - 19s/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  28\n",
      "added to csv\n",
      "\n",
      "Epoch:  29\n",
      "600/600 - 18s - loss: 0.0533 - acc: 0.9823 - val_loss: 2.0132 - val_acc: 0.6225 - 18s/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  29\n",
      "added to csv\n",
      "\n",
      "Epoch:  30\n",
      "600/600 - 13s - loss: 0.0439 - acc: 0.9848 - val_loss: 0.5881 - val_acc: 0.8425 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  30\n",
      "added to csv\n",
      "\n",
      "Epoch:  31\n",
      "600/600 - 13s - loss: 0.0318 - acc: 0.9887 - val_loss: 0.9018 - val_acc: 0.7987 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  31\n",
      "added to csv\n",
      "\n",
      "Epoch:  32\n",
      "600/600 - 13s - loss: 0.0594 - acc: 0.9812 - val_loss: 0.5617 - val_acc: 0.8675 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  32\n",
      "added to csv\n",
      "\n",
      "Epoch:  33\n",
      "600/600 - 13s - loss: 0.0189 - acc: 0.9942 - val_loss: 0.4703 - val_acc: 0.8788 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  33\n",
      "added to csv\n",
      "\n",
      "Epoch:  34\n",
      "600/600 - 13s - loss: 0.0385 - acc: 0.9865 - val_loss: 0.6920 - val_acc: 0.8331 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  34\n",
      "added to csv\n",
      "\n",
      "Epoch:  35\n",
      "600/600 - 13s - loss: 0.0535 - acc: 0.9817 - val_loss: 0.5864 - val_acc: 0.8725 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  35\n",
      "added to csv\n",
      "\n",
      "Epoch:  36\n",
      "600/600 - 13s - loss: 0.0451 - acc: 0.9842 - val_loss: 0.6578 - val_acc: 0.8356 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  36\n",
      "added to csv\n",
      "\n",
      "Epoch:  37\n",
      "600/600 - 13s - loss: 0.0215 - acc: 0.9944 - val_loss: 0.6081 - val_acc: 0.8444 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  37\n",
      "added to csv\n",
      "\n",
      "Epoch:  38\n",
      "600/600 - 13s - loss: 0.0170 - acc: 0.9948 - val_loss: 1.7918 - val_acc: 0.6662 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  38\n",
      "added to csv\n",
      "\n",
      "Epoch:  39\n",
      "600/600 - 13s - loss: 0.0323 - acc: 0.9898 - val_loss: 1.2918 - val_acc: 0.7663 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  39\n",
      "added to csv\n",
      "\n",
      "Epoch:  40\n",
      "600/600 - 13s - loss: 0.0599 - acc: 0.9804 - val_loss: 0.4106 - val_acc: 0.8925 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  40\n",
      "added to csv\n",
      "\n",
      "Epoch:  41\n",
      "600/600 - 13s - loss: 0.0100 - acc: 0.9971 - val_loss: 0.5464 - val_acc: 0.8706 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  41\n",
      "added to csv\n",
      "\n",
      "Epoch:  42\n",
      "600/600 - 13s - loss: 0.0031 - acc: 0.9994 - val_loss: 0.4210 - val_acc: 0.9006 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  42\n",
      "added to csv\n",
      "\n",
      "Epoch:  43\n",
      "600/600 - 13s - loss: 5.7584e-04 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.9075 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  43\n",
      "added to csv\n",
      "\n",
      "Epoch:  44\n",
      "600/600 - 13s - loss: 2.0683e-04 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.9087 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  44\n",
      "added to csv\n",
      "\n",
      "Epoch:  45\n",
      "600/600 - 13s - loss: 1.4599e-04 - acc: 1.0000 - val_loss: 0.4264 - val_acc: 0.9075 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  45\n",
      "added to csv\n",
      "\n",
      "Epoch:  46\n",
      "600/600 - 13s - loss: 1.0946e-04 - acc: 1.0000 - val_loss: 0.4342 - val_acc: 0.9075 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  46\n",
      "added to csv\n",
      "\n",
      "Epoch:  47\n",
      "600/600 - 13s - loss: 8.3212e-05 - acc: 1.0000 - val_loss: 0.4424 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  47\n",
      "added to csv\n",
      "\n",
      "Epoch:  48\n",
      "600/600 - 13s - loss: 6.3599e-05 - acc: 1.0000 - val_loss: 0.4508 - val_acc: 0.9081 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  48\n",
      "added to csv\n",
      "\n",
      "Epoch:  49\n",
      "600/600 - 13s - loss: 4.8718e-05 - acc: 1.0000 - val_loss: 0.4597 - val_acc: 0.9087 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  49\n",
      "added to csv\n",
      "\n",
      "Epoch:  50\n",
      "600/600 - 13s - loss: 3.7359e-05 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.9094 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  50\n",
      "added to csv\n",
      "\n",
      "Epoch:  51\n",
      "600/600 - 13s - loss: 2.8589e-05 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.9094 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  51\n",
      "added to csv\n",
      "\n",
      "Epoch:  52\n",
      "600/600 - 13s - loss: 2.1830e-05 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.9094 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  52\n",
      "added to csv\n",
      "\n",
      "Epoch:  53\n",
      "600/600 - 13s - loss: 1.6625e-05 - acc: 1.0000 - val_loss: 0.4990 - val_acc: 0.9094 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  53\n",
      "added to csv\n",
      "\n",
      "Epoch:  54\n",
      "600/600 - 13s - loss: 1.2621e-05 - acc: 1.0000 - val_loss: 0.5099 - val_acc: 0.9087 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  54\n",
      "added to csv\n",
      "\n",
      "Epoch:  55\n",
      "600/600 - 13s - loss: 9.5638e-06 - acc: 1.0000 - val_loss: 0.5212 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  55\n",
      "added to csv\n",
      "\n",
      "Epoch:  56\n",
      "600/600 - 13s - loss: 7.2270e-06 - acc: 1.0000 - val_loss: 0.5327 - val_acc: 0.9087 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  56\n",
      "added to csv\n",
      "\n",
      "Epoch:  57\n",
      "600/600 - 13s - loss: 5.4526e-06 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.9087 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  57\n",
      "added to csv\n",
      "\n",
      "Epoch:  58\n",
      "600/600 - 13s - loss: 4.1079e-06 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  58\n",
      "added to csv\n",
      "\n",
      "Epoch:  59\n",
      "600/600 - 13s - loss: 3.0884e-06 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.9075 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  59\n",
      "added to csv\n",
      "\n",
      "Epoch:  60\n",
      "600/600 - 13s - loss: 2.3198e-06 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.9081 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  60\n",
      "added to csv\n",
      "\n",
      "Epoch:  61\n",
      "600/600 - 13s - loss: 1.7407e-06 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  61\n",
      "added to csv\n",
      "\n",
      "Epoch:  62\n",
      "600/600 - 13s - loss: 1.3050e-06 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.9087 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  62\n",
      "added to csv\n",
      "\n",
      "Epoch:  63\n",
      "600/600 - 13s - loss: 9.7801e-07 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.9087 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  63\n",
      "added to csv\n",
      "\n",
      "Epoch:  64\n",
      "600/600 - 13s - loss: 7.3376e-07 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  64\n",
      "added to csv\n",
      "\n",
      "Epoch:  65\n",
      "600/600 - 13s - loss: 5.5412e-07 - acc: 1.0000 - val_loss: 0.6491 - val_acc: 0.9100 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  65\n",
      "added to csv\n",
      "\n",
      "Epoch:  66\n",
      "600/600 - 13s - loss: 4.3395e-07 - acc: 1.0000 - val_loss: 0.6644 - val_acc: 0.9075 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  66\n",
      "added to csv\n",
      "\n",
      "Epoch:  67\n",
      "600/600 - 13s - loss: 0.2842 - acc: 0.9337 - val_loss: 0.3873 - val_acc: 0.8769 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  67\n",
      "added to csv\n",
      "\n",
      "Epoch:  68\n",
      "600/600 - 13s - loss: 0.0665 - acc: 0.9779 - val_loss: 0.3895 - val_acc: 0.8950 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  68\n",
      "added to csv\n",
      "\n",
      "Epoch:  69\n",
      "600/600 - 13s - loss: 0.0052 - acc: 0.9994 - val_loss: 0.4600 - val_acc: 0.8875 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  69\n",
      "added to csv\n",
      "\n",
      "Epoch:  70\n",
      "600/600 - 13s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4144 - val_acc: 0.9044 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  70\n",
      "added to csv\n",
      "\n",
      "Epoch:  71\n",
      "600/600 - 13s - loss: 4.3255e-04 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.9019 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  71\n",
      "added to csv\n",
      "\n",
      "Epoch:  72\n",
      "600/600 - 13s - loss: 2.8337e-04 - acc: 1.0000 - val_loss: 0.4372 - val_acc: 0.9062 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  72\n",
      "added to csv\n",
      "\n",
      "Epoch:  73\n",
      "600/600 - 13s - loss: 2.0049e-04 - acc: 1.0000 - val_loss: 0.4489 - val_acc: 0.9062 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  73\n",
      "added to csv\n",
      "\n",
      "Epoch:  74\n",
      "600/600 - 13s - loss: 1.4524e-04 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.9069 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  74\n",
      "added to csv\n",
      "\n",
      "Epoch:  75\n",
      "600/600 - 13s - loss: 1.0659e-04 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  75\n",
      "added to csv\n",
      "\n",
      "Epoch:  76\n",
      "600/600 - 13s - loss: 7.8811e-05 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.9069 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  76\n",
      "added to csv\n",
      "\n",
      "Epoch:  77\n",
      "600/600 - 13s - loss: 5.8519e-05 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.9062 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  77\n",
      "added to csv\n",
      "\n",
      "Epoch:  78\n",
      "600/600 - 13s - loss: 4.3540e-05 - acc: 1.0000 - val_loss: 0.5060 - val_acc: 0.9050 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  78\n",
      "added to csv\n",
      "\n",
      "Epoch:  79\n",
      "600/600 - 13s - loss: 3.2438e-05 - acc: 1.0000 - val_loss: 0.5176 - val_acc: 0.9062 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  79\n",
      "added to csv\n",
      "\n",
      "Epoch:  80\n",
      "600/600 - 13s - loss: 2.4197e-05 - acc: 1.0000 - val_loss: 0.5295 - val_acc: 0.9062 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  80\n",
      "added to csv\n",
      "\n",
      "Epoch:  81\n",
      "600/600 - 13s - loss: 1.8055e-05 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.9056 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  81\n",
      "added to csv\n",
      "\n",
      "Epoch:  82\n",
      "600/600 - 13s - loss: 1.3479e-05 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.9056 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  82\n",
      "added to csv\n",
      "\n",
      "Epoch:  83\n",
      "600/600 - 13s - loss: 1.0056e-05 - acc: 1.0000 - val_loss: 0.5665 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  83\n",
      "added to csv\n",
      "\n",
      "Epoch:  84\n",
      "600/600 - 13s - loss: 7.5018e-06 - acc: 1.0000 - val_loss: 0.5791 - val_acc: 0.9062 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  84\n",
      "added to csv\n",
      "\n",
      "Epoch:  85\n",
      "600/600 - 13s - loss: 5.5944e-06 - acc: 1.0000 - val_loss: 0.5918 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  85\n",
      "added to csv\n",
      "\n",
      "Epoch:  86\n",
      "600/600 - 13s - loss: 4.1763e-06 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.9069 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  86\n",
      "added to csv\n",
      "\n",
      "Epoch:  87\n",
      "600/600 - 13s - loss: 3.1167e-06 - acc: 1.0000 - val_loss: 0.6174 - val_acc: 0.9081 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  87\n",
      "added to csv\n",
      "\n",
      "Epoch:  88\n",
      "600/600 - 13s - loss: 2.3289e-06 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.9075 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  88\n",
      "added to csv\n",
      "\n",
      "Epoch:  89\n",
      "600/600 - 13s - loss: 1.7438e-06 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  89\n",
      "added to csv\n",
      "\n",
      "Epoch:  90\n",
      "600/600 - 13s - loss: 1.3064e-06 - acc: 1.0000 - val_loss: 0.6566 - val_acc: 0.9069 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  90\n",
      "added to csv\n",
      "\n",
      "Epoch:  91\n",
      "600/600 - 13s - loss: 9.8002e-07 - acc: 1.0000 - val_loss: 0.6699 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  91\n",
      "added to csv\n",
      "\n",
      "Epoch:  92\n",
      "600/600 - 13s - loss: 7.3296e-07 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.9075 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  92\n",
      "added to csv\n",
      "\n",
      "Epoch:  93\n",
      "600/600 - 13s - loss: 5.5057e-07 - acc: 1.0000 - val_loss: 0.6979 - val_acc: 0.9081 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  93\n",
      "added to csv\n",
      "\n",
      "Epoch:  94\n",
      "600/600 - 13s - loss: 4.1338e-07 - acc: 1.0000 - val_loss: 0.7124 - val_acc: 0.9075 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  94\n",
      "added to csv\n",
      "\n",
      "Epoch:  95\n",
      "600/600 - 13s - loss: 3.1188e-07 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.9075 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  95\n",
      "added to csv\n",
      "\n",
      "Epoch:  96\n",
      "600/600 - 13s - loss: 2.4033e-07 - acc: 1.0000 - val_loss: 0.7429 - val_acc: 0.9069 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  96\n",
      "added to csv\n",
      "\n",
      "Epoch:  97\n",
      "600/600 - 13s - loss: 0.2201 - acc: 0.9490 - val_loss: 1.3801 - val_acc: 0.6619 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  97\n",
      "added to csv\n",
      "\n",
      "Epoch:  98\n",
      "600/600 - 13s - loss: 0.0695 - acc: 0.9762 - val_loss: 0.3415 - val_acc: 0.9038 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  98\n",
      "added to csv\n",
      "\n",
      "Epoch:  99\n",
      "600/600 - 13s - loss: 0.0083 - acc: 0.9983 - val_loss: 0.3710 - val_acc: 0.9044 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  99\n",
      "added to csv\n",
      "\n",
      "Epoch:  100\n",
      "600/600 - 13s - loss: 9.6051e-04 - acc: 1.0000 - val_loss: 0.3903 - val_acc: 0.9094 - 13s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_msc_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  100\n",
      "added to csv\n",
      "Testing time (s) = 2939.351486396976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_training, labels_training, batch_size=batch_size, epochs = 1, validation_data=(x_val_norm, y_val), verbose=2)\n",
    "    model.save('./RNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d4ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.88875\n",
      "Confusion Matrix:\n",
      "[[270  46  84   0]\n",
      " [  8 381  11   0]\n",
      " [  6  22 372   0]\n",
      " [  0   0   1 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79       400\n",
      "           1       0.85      0.95      0.90       400\n",
      "           2       0.79      0.93      0.86       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.90      0.89      0.89      1600\n",
      "weighted avg       0.90      0.89      0.89      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06167d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3138b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwheatenv",
   "language": "python",
   "name": "dwheatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
