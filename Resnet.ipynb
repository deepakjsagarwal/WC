{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 21:03:38.497857: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 21:03:40.197593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3c2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/tyagi/Desktop/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TRAIN_IMAGE_COUNT = 1200\n",
    "VAL_IMAGE_COUNT = 400\n",
    "TEST_IMAGE_COUNT = 400\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "LEARNING_RATE_BASE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "    \n",
    "FILTER = filter_method(1).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(0).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/V\"+str(variety).zfill(3)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n",
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    x_train= x_train + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    y_train = y_train + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    x_val= x_val + np.load(dataset_file_name(v)+\"_val_dataset.npy\").tolist()\n",
    "    y_val = y_val + np.load(dataset_file_name(v)+\"_val_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca90232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    print(\"Testing started\")\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "    \n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix_results,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_integer_format, labels_predicted_integer_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb608fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90729707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_block(x, filters, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3, 3), use_bias=False, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def identity_block(x, filters):\n",
    "    x_identity = x\n",
    "\n",
    "    x = conv_block(x, filters)\n",
    "    x = layers.Add()([x, x_identity])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet18(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution layer\n",
    "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), use_bias=False, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = conv_block(x, filters=64, strides=1)\n",
    "    x = identity_block(x, filters=64)\n",
    "\n",
    "    x = conv_block(x, filters=128, strides=2)\n",
    "    x = identity_block(x, filters=128)\n",
    "\n",
    "    x = conv_block(x, filters=256, strides=2)\n",
    "    x = identity_block(x, filters=256)\n",
    "\n",
    "    x = conv_block(x, filters=512, strides=2)\n",
    "    x = identity_block(x, filters=512)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43cde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = np.array(x_train)\n",
    "labels_training = np.array(y_train)\n",
    "\n",
    "# Normalize the data\n",
    "x_training = normalizeDataWholeSeed(x_training,normalization_type='max')\n",
    "x_val_norm = normalizeDataWholeSeed(x_val,normalization_type=\"max\")\n",
    "test_dataset = normalizeDataWholeSeed(test_dataset,normalization_type='max')\n",
    "    \n",
    "# Extract some information\n",
    "num_training = x_training.shape[0]\n",
    "N_spatial = x_training.shape[1:3]\n",
    "N_bands = x_training.shape[3]\n",
    "batch_size = BATCH_SIZE\n",
    "num_batch_per_epoch = int(num_training/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ce95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_to_csv(file_path, data_frame, header=False):\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    if not file_exists or not header:\n",
    "        data_frame.to_csv(file_path, index=False, mode='w')\n",
    "    else:\n",
    "        data_frame.to_csv(file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08349c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HD 3086', 'PBW 291', 'DBW 187', 'DBW222']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9dcaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead0a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 21:08:48.414651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14554 MB memory:  -> device: 1, name: Quadro P5000, pci bus id: 0000:9b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RN_\"+\"_IC_\"+str(TRAIN_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)\n",
    "if REMOVE_NOISY_BANDS:\n",
    "    model_name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "if FILTER == \"savgol\":\n",
    "    model_name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "\n",
    "if start_epoch != 1:\n",
    "    model = tf.keras.models.load_model('./RNmodels/'+str(start_epoch-1)+model_name)\n",
    "else:\n",
    "    \n",
    "    input_shape = (30, 30, 168)\n",
    "    num_classes = 4\n",
    "    model = resnet18(input_shape, num_classes)\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627a2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74535028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 168  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 15, 15, 64)   526848      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     36864       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 64)     36864       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     36864       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    73728       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 128)    147456      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147456      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 128)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 4, 4, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 2, 2, 256)    294912      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_10[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 2, 2, 256)    589824      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 2, 2, 256)    589824      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 2, 2, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 1, 1, 512)    1179648     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 512)    2359296     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 1, 1, 512)    2359296     ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 1, 512)    0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 1, 1, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_12[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            2052        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,529,988\n",
      "Trainable params: 11,522,180\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3324c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 21:08:58.351349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 17s - loss: 1.5680 - acc: 0.3517 - val_loss: 2.2247 - val_acc: 0.3537 - 17s/epoch - 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/1RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  1\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.38875\n",
      "Confusion Matrix:\n",
      "[[ 49   5  22 324]\n",
      " [ 22 120 112 146]\n",
      " [ 23  36 117 224]\n",
      " [ 34   2  28 336]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.12      0.19       400\n",
      "           1       0.74      0.30      0.43       400\n",
      "           2       0.42      0.29      0.34       400\n",
      "           3       0.33      0.84      0.47       400\n",
      "\n",
      "    accuracy                           0.39      1600\n",
      "   macro avg       0.47      0.39      0.36      1600\n",
      "weighted avg       0.47      0.39      0.36      1600\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "600/600 - 14s - loss: 1.2246 - acc: 0.4650 - val_loss: 1.0964 - val_acc: 0.5025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/2RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  2\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.468125\n",
      "Confusion Matrix:\n",
      "[[217  76  70  37]\n",
      " [ 46 266  81   7]\n",
      " [ 36 231 119  14]\n",
      " [ 86  67 100 147]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55       400\n",
      "           1       0.42      0.67      0.51       400\n",
      "           2       0.32      0.30      0.31       400\n",
      "           3       0.72      0.37      0.49       400\n",
      "\n",
      "    accuracy                           0.47      1600\n",
      "   macro avg       0.50      0.47      0.46      1600\n",
      "weighted avg       0.50      0.47      0.46      1600\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "600/600 - 14s - loss: 0.8486 - acc: 0.6448 - val_loss: 0.9864 - val_acc: 0.5675 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/3RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  3\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.54375\n",
      "Confusion Matrix:\n",
      "[[246  39 114   1]\n",
      " [ 43 249 107   1]\n",
      " [ 46 147 207   0]\n",
      " [ 72  22 138 168]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61       400\n",
      "           1       0.54      0.62      0.58       400\n",
      "           2       0.37      0.52      0.43       400\n",
      "           3       0.99      0.42      0.59       400\n",
      "\n",
      "    accuracy                           0.54      1600\n",
      "   macro avg       0.63      0.54      0.55      1600\n",
      "weighted avg       0.63      0.54      0.55      1600\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "600/600 - 13s - loss: 0.5807 - acc: 0.7671 - val_loss: 0.8404 - val_acc: 0.6525 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/4RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  4\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.631875\n",
      "Confusion Matrix:\n",
      "[[179 101 112   8]\n",
      " [ 15 325  53   7]\n",
      " [ 19 236 143   2]\n",
      " [  9  18   9 364]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.45      0.58       400\n",
      "           1       0.48      0.81      0.60       400\n",
      "           2       0.45      0.36      0.40       400\n",
      "           3       0.96      0.91      0.93       400\n",
      "\n",
      "    accuracy                           0.63      1600\n",
      "   macro avg       0.67      0.63      0.63      1600\n",
      "weighted avg       0.67      0.63      0.63      1600\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "600/600 - 13s - loss: 0.4086 - acc: 0.8440 - val_loss: 1.0522 - val_acc: 0.6519 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/5RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  5\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.650625\n",
      "Confusion Matrix:\n",
      "[[274   8  89  29]\n",
      " [ 97 188  79  36]\n",
      " [110  84 188  18]\n",
      " [  9   0   0 391]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62       400\n",
      "           1       0.67      0.47      0.55       400\n",
      "           2       0.53      0.47      0.50       400\n",
      "           3       0.82      0.98      0.89       400\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.65      0.65      0.64      1600\n",
      "weighted avg       0.65      0.65      0.64      1600\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "600/600 - 13s - loss: 0.3265 - acc: 0.8773 - val_loss: 0.9254 - val_acc: 0.6650 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/6RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  6\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.680625\n",
      "Confusion Matrix:\n",
      "[[238  37  83  42]\n",
      " [ 46 265  72  17]\n",
      " [ 60 135 189  16]\n",
      " [  2   1   0 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       400\n",
      "           1       0.61      0.66      0.63       400\n",
      "           2       0.55      0.47      0.51       400\n",
      "           3       0.84      0.99      0.91       400\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.67      0.68      0.67      1600\n",
      "weighted avg       0.67      0.68      0.67      1600\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "600/600 - 13s - loss: 0.2781 - acc: 0.9023 - val_loss: 0.8065 - val_acc: 0.7119 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/7RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  7\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.70125\n",
      "Confusion Matrix:\n",
      "[[304  45  48   3]\n",
      " [ 59 303  36   2]\n",
      " [ 93 156 151   0]\n",
      " [ 28   3   5 364]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69       400\n",
      "           1       0.60      0.76      0.67       400\n",
      "           2       0.63      0.38      0.47       400\n",
      "           3       0.99      0.91      0.95       400\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.71      0.70      0.69      1600\n",
      "weighted avg       0.71      0.70      0.69      1600\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "600/600 - 13s - loss: 0.2147 - acc: 0.9235 - val_loss: 0.9212 - val_acc: 0.7088 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/8RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  8\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.68\n",
      "Confusion Matrix:\n",
      "[[158 107 111  24]\n",
      " [ 12 331  47  10]\n",
      " [  8 176 215   1]\n",
      " [  6   6   4 384]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.54       400\n",
      "           1       0.53      0.83      0.65       400\n",
      "           2       0.57      0.54      0.55       400\n",
      "           3       0.92      0.96      0.94       400\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.72      0.68      0.67      1600\n",
      "weighted avg       0.72      0.68      0.67      1600\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "600/600 - 14s - loss: 0.1849 - acc: 0.9385 - val_loss: 1.2832 - val_acc: 0.6231 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/9RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  9\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.610625\n",
      "Confusion Matrix:\n",
      "[[115 116  34 135]\n",
      " [  7 342  13  38]\n",
      " [ 17 174 120  89]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.29      0.43       400\n",
      "           1       0.54      0.85      0.66       400\n",
      "           2       0.72      0.30      0.42       400\n",
      "           3       0.60      1.00      0.75       400\n",
      "\n",
      "    accuracy                           0.61      1600\n",
      "   macro avg       0.67      0.61      0.57      1600\n",
      "weighted avg       0.67      0.61      0.57      1600\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "600/600 - 14s - loss: 0.1446 - acc: 0.9492 - val_loss: 1.3711 - val_acc: 0.6263 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/10RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  10\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.56125\n",
      "Confusion Matrix:\n",
      "[[231 149  20   0]\n",
      " [ 34 362   4   0]\n",
      " [ 44 267  89   0]\n",
      " [ 86  86  12 216]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       400\n",
      "           1       0.42      0.91      0.57       400\n",
      "           2       0.71      0.22      0.34       400\n",
      "           3       1.00      0.54      0.70       400\n",
      "\n",
      "    accuracy                           0.56      1600\n",
      "   macro avg       0.68      0.56      0.55      1600\n",
      "weighted avg       0.68      0.56      0.55      1600\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "600/600 - 14s - loss: 0.1539 - acc: 0.9456 - val_loss: 0.8681 - val_acc: 0.7481 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/11RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  11\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.74625\n",
      "Confusion Matrix:\n",
      "[[314  21  63   2]\n",
      " [ 97 243  59   1]\n",
      " [ 58  66 276   0]\n",
      " [ 25   5   9 361]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.70       400\n",
      "           1       0.73      0.61      0.66       400\n",
      "           2       0.68      0.69      0.68       400\n",
      "           3       0.99      0.90      0.95       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.76      0.75      0.75      1600\n",
      "weighted avg       0.76      0.75      0.75      1600\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "600/600 - 14s - loss: 0.1320 - acc: 0.9527 - val_loss: 0.9031 - val_acc: 0.7500 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/12RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  12\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.701875\n",
      "Confusion Matrix:\n",
      "[[209 151  32   8]\n",
      " [  7 385   8   0]\n",
      " [ 25 217 157   1]\n",
      " [ 10  16   2 372]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.52      0.64       400\n",
      "           1       0.50      0.96      0.66       400\n",
      "           2       0.79      0.39      0.52       400\n",
      "           3       0.98      0.93      0.95       400\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.77      0.70      0.69      1600\n",
      "weighted avg       0.77      0.70      0.69      1600\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "600/600 - 14s - loss: 0.0938 - acc: 0.9667 - val_loss: 1.0903 - val_acc: 0.7031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/13RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  13\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.753125\n",
      "Confusion Matrix:\n",
      "[[336  29  14  21]\n",
      " [ 77 292  14  17]\n",
      " [109  77 177  37]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73       400\n",
      "           1       0.73      0.73      0.73       400\n",
      "           2       0.86      0.44      0.59       400\n",
      "           3       0.84      1.00      0.91       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.77      0.75      0.74      1600\n",
      "weighted avg       0.77      0.75      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "600/600 - 13s - loss: 0.0987 - acc: 0.9650 - val_loss: 1.4545 - val_acc: 0.6350 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/14RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  14\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.65\n",
      "Confusion Matrix:\n",
      "[[132  40  62 166]\n",
      " [ 15 277  25  83]\n",
      " [ 15  49 231 105]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.33      0.47       400\n",
      "           1       0.76      0.69      0.72       400\n",
      "           2       0.73      0.58      0.64       400\n",
      "           3       0.53      1.00      0.69       400\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.71      0.65      0.63      1600\n",
      "weighted avg       0.71      0.65      0.63      1600\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "600/600 - 14s - loss: 0.0731 - acc: 0.9742 - val_loss: 0.9687 - val_acc: 0.7538 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/15RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  15\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.76875\n",
      "Confusion Matrix:\n",
      "[[273  30  96   1]\n",
      " [ 59 272  69   0]\n",
      " [ 39  21 340   0]\n",
      " [ 41   1  13 345]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       400\n",
      "           1       0.84      0.68      0.75       400\n",
      "           2       0.66      0.85      0.74       400\n",
      "           3       1.00      0.86      0.92       400\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.79      0.77      0.77      1600\n",
      "weighted avg       0.79      0.77      0.77      1600\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "600/600 - 14s - loss: 0.1045 - acc: 0.9638 - val_loss: 1.2397 - val_acc: 0.7050 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/16RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  16\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.71625\n",
      "Confusion Matrix:\n",
      "[[317  18  64   1]\n",
      " [ 79 248  73   0]\n",
      " [ 61  26 313   0]\n",
      " [103   1  28 268]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.79      0.66       400\n",
      "           1       0.85      0.62      0.72       400\n",
      "           2       0.65      0.78      0.71       400\n",
      "           3       1.00      0.67      0.80       400\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.77      0.72      0.72      1600\n",
      "weighted avg       0.77      0.72      0.72      1600\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "600/600 - 14s - loss: 0.0805 - acc: 0.9715 - val_loss: 0.7104 - val_acc: 0.8138 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/17RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  17\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.743125\n",
      "Confusion Matrix:\n",
      "[[154  99 147   0]\n",
      " [ 12 366  22   0]\n",
      " [  1 107 292   0]\n",
      " [  5   5  13 377]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.39      0.54       400\n",
      "           1       0.63      0.92      0.75       400\n",
      "           2       0.62      0.73      0.67       400\n",
      "           3       1.00      0.94      0.97       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.79      0.74      0.73      1600\n",
      "weighted avg       0.79      0.74      0.73      1600\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "600/600 - 14s - loss: 0.0779 - acc: 0.9762 - val_loss: 1.1521 - val_acc: 0.7494 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/18RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  18\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.726875\n",
      "Confusion Matrix:\n",
      "[[200   4 196   0]\n",
      " [ 38 195 167   0]\n",
      " [ 10   8 382   0]\n",
      " [  5   0   9 386]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61       400\n",
      "           1       0.94      0.49      0.64       400\n",
      "           2       0.51      0.95      0.66       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.81      0.73      0.72      1600\n",
      "weighted avg       0.81      0.73      0.72      1600\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "600/600 - 14s - loss: 0.0652 - acc: 0.9769 - val_loss: 1.1714 - val_acc: 0.7044 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/19RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  19\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.701875\n",
      "Confusion Matrix:\n",
      "[[ 85  44 108 163]\n",
      " [ 11 325  40  24]\n",
      " [  5  40 313  42]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.21      0.34       400\n",
      "           1       0.79      0.81      0.80       400\n",
      "           2       0.68      0.78      0.73       400\n",
      "           3       0.64      1.00      0.78       400\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.74      0.70      0.66      1600\n",
      "weighted avg       0.74      0.70      0.66      1600\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "600/600 - 14s - loss: 0.0695 - acc: 0.9790 - val_loss: 1.5199 - val_acc: 0.6019 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/20RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  20\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.6225\n",
      "Confusion Matrix:\n",
      "[[119  17  55 209]\n",
      " [ 24 240  80  56]\n",
      " [ 14  19 237 130]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.30      0.43       400\n",
      "           1       0.87      0.60      0.71       400\n",
      "           2       0.64      0.59      0.61       400\n",
      "           3       0.50      1.00      0.67       400\n",
      "\n",
      "    accuracy                           0.62      1600\n",
      "   macro avg       0.69      0.62      0.61      1600\n",
      "weighted avg       0.69      0.62      0.61      1600\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "600/600 - 14s - loss: 0.0486 - acc: 0.9852 - val_loss: 0.6433 - val_acc: 0.8294 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/21RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  21\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.795\n",
      "Confusion Matrix:\n",
      "[[250  90  60   0]\n",
      " [ 16 376   8   0]\n",
      " [ 20 119 261   0]\n",
      " [  4   9   2 385]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.62      0.72       400\n",
      "           1       0.63      0.94      0.76       400\n",
      "           2       0.79      0.65      0.71       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.80      1600\n",
      "   macro avg       0.82      0.79      0.79      1600\n",
      "weighted avg       0.82      0.80      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "600/600 - 14s - loss: 0.1108 - acc: 0.9654 - val_loss: 0.6827 - val_acc: 0.8075 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/22RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  22\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.791875\n",
      "Confusion Matrix:\n",
      "[[199  47 111  43]\n",
      " [ 14 337  37  12]\n",
      " [ 12  34 331  23]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64       400\n",
      "           1       0.81      0.84      0.82       400\n",
      "           2       0.69      0.83      0.75       400\n",
      "           3       0.84      1.00      0.91       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.80      0.79      0.78      1600\n",
      "weighted avg       0.80      0.79      0.78      1600\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "600/600 - 14s - loss: 0.0333 - acc: 0.9912 - val_loss: 5.6442 - val_acc: 0.3269 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/23RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  23\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.315625\n",
      "Confusion Matrix:\n",
      "[[ 13   0   2 385]\n",
      " [  3  59   0 338]\n",
      " [  0   1  33 366]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.03      0.06       400\n",
      "           1       0.98      0.15      0.26       400\n",
      "           2       0.94      0.08      0.15       400\n",
      "           3       0.27      1.00      0.42       400\n",
      "\n",
      "    accuracy                           0.32      1600\n",
      "   macro avg       0.75      0.32      0.22      1600\n",
      "weighted avg       0.75      0.32      0.22      1600\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "600/600 - 14s - loss: 0.0255 - acc: 0.9921 - val_loss: 1.4559 - val_acc: 0.7281 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/24RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  24\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.68875\n",
      "Confusion Matrix:\n",
      "[[201 193   6   0]\n",
      " [  5 395   0   0]\n",
      " [ 32 246 122   0]\n",
      " [  8   7   1 384]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.50      0.62       400\n",
      "           1       0.47      0.99      0.64       400\n",
      "           2       0.95      0.30      0.46       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.81      0.69      0.67      1600\n",
      "weighted avg       0.81      0.69      0.67      1600\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "600/600 - 14s - loss: 0.0888 - acc: 0.9688 - val_loss: 2.2250 - val_acc: 0.5587 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/25RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  25\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.523125\n",
      "Confusion Matrix:\n",
      "[[ 69  35  24 272]\n",
      " [  4 140  11 245]\n",
      " [  9  38 228 125]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.17      0.29       400\n",
      "           1       0.66      0.35      0.46       400\n",
      "           2       0.87      0.57      0.69       400\n",
      "           3       0.38      1.00      0.55       400\n",
      "\n",
      "    accuracy                           0.52      1600\n",
      "   macro avg       0.69      0.52      0.50      1600\n",
      "weighted avg       0.69      0.52      0.50      1600\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "600/600 - 14s - loss: 0.0571 - acc: 0.9815 - val_loss: 0.7845 - val_acc: 0.8144 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/26RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  26\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.7675\n",
      "Confusion Matrix:\n",
      "[[187 153  60   0]\n",
      " [  3 394   3   0]\n",
      " [ 11 135 254   0]\n",
      " [  0   4   3 393]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.47      0.62       400\n",
      "           1       0.57      0.98      0.73       400\n",
      "           2       0.79      0.64      0.71       400\n",
      "           3       1.00      0.98      0.99       400\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.82      0.77      0.76      1600\n",
      "weighted avg       0.82      0.77      0.76      1600\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "600/600 - 14s - loss: 0.0316 - acc: 0.9881 - val_loss: 1.2140 - val_acc: 0.7362 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/27RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  27\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.694375\n",
      "Confusion Matrix:\n",
      "[[152 226  17   5]\n",
      " [  3 396   0   1]\n",
      " [ 26 200 164  10]\n",
      " [  0   1   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.38      0.52       400\n",
      "           1       0.48      0.99      0.65       400\n",
      "           2       0.91      0.41      0.56       400\n",
      "           3       0.96      1.00      0.98       400\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.80      0.69      0.68      1600\n",
      "weighted avg       0.80      0.69      0.68      1600\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "600/600 - 14s - loss: 0.0307 - acc: 0.9906 - val_loss: 0.9253 - val_acc: 0.7862 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/28RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  28\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.81875\n",
      "Confusion Matrix:\n",
      "[[341  12  42   5]\n",
      " [ 94 256  37  13]\n",
      " [ 51  13 316  20]\n",
      " [  3   0   0 397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       400\n",
      "           1       0.91      0.64      0.75       400\n",
      "           2       0.80      0.79      0.79       400\n",
      "           3       0.91      0.99      0.95       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.83      0.82      0.82      1600\n",
      "weighted avg       0.83      0.82      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "600/600 - 14s - loss: 0.0507 - acc: 0.9842 - val_loss: 1.1394 - val_acc: 0.7625 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/29RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  29\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.73125\n",
      "Confusion Matrix:\n",
      "[[239  12 149   0]\n",
      " [ 40 281  79   0]\n",
      " [  4  16 380   0]\n",
      " [ 32   0  98 270]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67       400\n",
      "           1       0.91      0.70      0.79       400\n",
      "           2       0.54      0.95      0.69       400\n",
      "           3       1.00      0.68      0.81       400\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.80      0.73      0.74      1600\n",
      "weighted avg       0.80      0.73      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "600/600 - 14s - loss: 0.0773 - acc: 0.9769 - val_loss: 0.6010 - val_acc: 0.8438 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/30RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  30\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.845\n",
      "Confusion Matrix:\n",
      "[[325  44  31   0]\n",
      " [ 41 352   7   0]\n",
      " [ 46  79 275   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       400\n",
      "           1       0.74      0.88      0.80       400\n",
      "           2       0.88      0.69      0.77       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.84      1600\n",
      "weighted avg       0.85      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  31\n",
      "600/600 - 14s - loss: 0.0170 - acc: 0.9956 - val_loss: 1.6464 - val_acc: 0.6169 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/31RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  31\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.594375\n",
      "Confusion Matrix:\n",
      "[[ 73  39  42 246]\n",
      " [  5 242  35 118]\n",
      " [  3   4 236 157]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.18      0.30       400\n",
      "           1       0.85      0.60      0.71       400\n",
      "           2       0.75      0.59      0.66       400\n",
      "           3       0.43      1.00      0.61       400\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.73      0.59      0.57      1600\n",
      "weighted avg       0.73      0.59      0.57      1600\n",
      "\n",
      "\n",
      "Epoch:  32\n",
      "600/600 - 14s - loss: 0.0441 - acc: 0.9850 - val_loss: 0.8269 - val_acc: 0.7912 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/32RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  32\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.770625\n",
      "Confusion Matrix:\n",
      "[[251  60  43  46]\n",
      " [ 32 323  25  20]\n",
      " [ 25  63 261  51]\n",
      " [  2   0   0 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       400\n",
      "           1       0.72      0.81      0.76       400\n",
      "           2       0.79      0.65      0.72       400\n",
      "           3       0.77      0.99      0.87       400\n",
      "\n",
      "    accuracy                           0.77      1600\n",
      "   macro avg       0.78      0.77      0.76      1600\n",
      "weighted avg       0.78      0.77      0.76      1600\n",
      "\n",
      "\n",
      "Epoch:  33\n",
      "600/600 - 14s - loss: 0.0331 - acc: 0.9877 - val_loss: 0.7554 - val_acc: 0.8269 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/33RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  33\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.789375\n",
      "Confusion Matrix:\n",
      "[[260 121  18   1]\n",
      " [ 11 385   3   1]\n",
      " [ 45 130 220   5]\n",
      " [  2   0   0 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.72       400\n",
      "           1       0.61      0.96      0.74       400\n",
      "           2       0.91      0.55      0.69       400\n",
      "           3       0.98      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.83      0.79      0.79      1600\n",
      "weighted avg       0.83      0.79      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  34\n",
      "600/600 - 14s - loss: 0.0279 - acc: 0.9896 - val_loss: 2.1881 - val_acc: 0.6244 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/34RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  34\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.651875\n",
      "Confusion Matrix:\n",
      "[[357  18  25   0]\n",
      " [127 263  10   0]\n",
      " [ 80  69 251   0]\n",
      " [199   1  28 172]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.89      0.61       400\n",
      "           1       0.75      0.66      0.70       400\n",
      "           2       0.80      0.63      0.70       400\n",
      "           3       1.00      0.43      0.60       400\n",
      "\n",
      "    accuracy                           0.65      1600\n",
      "   macro avg       0.75      0.65      0.65      1600\n",
      "weighted avg       0.75      0.65      0.65      1600\n",
      "\n",
      "\n",
      "Epoch:  35\n",
      "600/600 - 14s - loss: 0.0468 - acc: 0.9837 - val_loss: 0.5582 - val_acc: 0.8700 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/35RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  35\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.82\n",
      "Confusion Matrix:\n",
      "[[223  39 138   0]\n",
      " [ 24 334  42   0]\n",
      " [  4  35 361   0]\n",
      " [  2   0   4 394]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.56      0.68       400\n",
      "           1       0.82      0.83      0.83       400\n",
      "           2       0.66      0.90      0.76       400\n",
      "           3       1.00      0.98      0.99       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.84      0.82      0.82      1600\n",
      "weighted avg       0.84      0.82      0.82      1600\n",
      "\n",
      "\n",
      "Epoch:  36\n",
      "600/600 - 14s - loss: 0.0181 - acc: 0.9950 - val_loss: 0.5604 - val_acc: 0.8481 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/36RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  36\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[273  46  81   0]\n",
      " [ 31 350  19   0]\n",
      " [ 18  42 340   0]\n",
      " [ 19   3  13 365]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.74       400\n",
      "           1       0.79      0.88      0.83       400\n",
      "           2       0.75      0.85      0.80       400\n",
      "           3       1.00      0.91      0.95       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.84      0.83      0.83      1600\n",
      "weighted avg       0.84      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  37\n",
      "600/600 - 14s - loss: 0.0409 - acc: 0.9881 - val_loss: 0.8243 - val_acc: 0.8206 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/37RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  37\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.754375\n",
      "Confusion Matrix:\n",
      "[[143  43 214   0]\n",
      " [ 10 344  46   0]\n",
      " [  2  17 381   0]\n",
      " [  8   1  52 339]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.36      0.51       400\n",
      "           1       0.85      0.86      0.85       400\n",
      "           2       0.55      0.95      0.70       400\n",
      "           3       1.00      0.85      0.92       400\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.82      0.75      0.74      1600\n",
      "weighted avg       0.82      0.75      0.74      1600\n",
      "\n",
      "\n",
      "Epoch:  38\n",
      "600/600 - 14s - loss: 0.0091 - acc: 0.9979 - val_loss: 0.5081 - val_acc: 0.8819 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/38RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  38\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.856875\n",
      "Confusion Matrix:\n",
      "[[285  17  97   1]\n",
      " [ 36 326  38   0]\n",
      " [ 21  17 361   1]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77       400\n",
      "           1       0.91      0.81      0.86       400\n",
      "           2       0.73      0.90      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.86      0.86      0.86      1600\n",
      "weighted avg       0.86      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  39\n",
      "600/600 - 14s - loss: 0.0015 - acc: 0.9998 - val_loss: 0.4021 - val_acc: 0.8994 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/39RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  39\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[241  57 102   0]\n",
      " [ 10 375  15   0]\n",
      " [ 14  34 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.87       400\n",
      "           2       0.75      0.88      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  40\n",
      "600/600 - 14s - loss: 2.9397e-04 - acc: 1.0000 - val_loss: 0.4117 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/40RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  40\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.853125\n",
      "Confusion Matrix:\n",
      "[[245  45 110   0]\n",
      " [ 16 368  16   0]\n",
      " [ 14  33 353   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.61      0.72       400\n",
      "           1       0.83      0.92      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  41\n",
      "600/600 - 14s - loss: 1.5571e-04 - acc: 1.0000 - val_loss: 0.4214 - val_acc: 0.9025 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/41RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  41\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[244  47 109   0]\n",
      " [ 12 372  16   0]\n",
      " [ 14  33 353   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73       400\n",
      "           1       0.82      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  42\n",
      "600/600 - 14s - loss: 1.1295e-04 - acc: 1.0000 - val_loss: 0.4306 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/42RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  42\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[244  47 109   0]\n",
      " [ 12 372  16   0]\n",
      " [ 14  33 353   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73       400\n",
      "           1       0.82      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  43\n",
      "600/600 - 14s - loss: 8.4719e-05 - acc: 1.0000 - val_loss: 0.4399 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/43RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  43\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85375\n",
      "Confusion Matrix:\n",
      "[[243  49 108   0]\n",
      " [ 12 372  16   0]\n",
      " [ 14  34 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73       400\n",
      "           1       0.82      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  44\n",
      "600/600 - 14s - loss: 6.4455e-05 - acc: 1.0000 - val_loss: 0.4496 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/44RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  44\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[243  49 108   0]\n",
      " [ 11 373  16   0]\n",
      " [ 13  34 353   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73       400\n",
      "           1       0.82      0.93      0.87       400\n",
      "           2       0.74      0.88      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  45\n",
      "600/600 - 14s - loss: 4.9339e-05 - acc: 1.0000 - val_loss: 0.4595 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/45RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  45\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85375\n",
      "Confusion Matrix:\n",
      "[[242  50 108   0]\n",
      " [ 11 373  16   0]\n",
      " [ 13  35 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  46\n",
      "600/600 - 14s - loss: 3.7854e-05 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/46RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  46\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.85375\n",
      "Confusion Matrix:\n",
      "[[242  50 108   0]\n",
      " [ 11 373  16   0]\n",
      " [ 13  35 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  47\n",
      "600/600 - 14s - loss: 2.9005e-05 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/47RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  47\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85375\n",
      "Confusion Matrix:\n",
      "[[242  50 108   0]\n",
      " [ 11 373  16   0]\n",
      " [ 13  35 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  48\n",
      "600/600 - 14s - loss: 2.2183e-05 - acc: 1.0000 - val_loss: 0.4913 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/48RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  48\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[243  50 107   0]\n",
      " [ 10 374  16   0]\n",
      " [ 13  35 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73       400\n",
      "           1       0.81      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  49\n",
      "600/600 - 14s - loss: 1.6925e-05 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.9031 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/49RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  49\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[244  49 107   0]\n",
      " [  9 374  17   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73       400\n",
      "           1       0.81      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  50\n",
      "600/600 - 14s - loss: 1.2866e-05 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/50RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  50\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[243  49 108   0]\n",
      " [  9 374  17   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73       400\n",
      "           1       0.81      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  51\n",
      "600/600 - 14s - loss: 9.7357e-06 - acc: 1.0000 - val_loss: 0.5266 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/51RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  51\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[242  49 109   0]\n",
      " [  9 374  17   0]\n",
      " [ 13  35 352   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.82      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  52\n",
      "600/600 - 14s - loss: 7.3558e-06 - acc: 1.0000 - val_loss: 0.5390 - val_acc: 0.9000 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/52RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  52\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85375\n",
      "Confusion Matrix:\n",
      "[[242  49 109   0]\n",
      " [  9 374  17   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.81      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.87      0.85      0.85      1600\n",
      "weighted avg       0.87      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  53\n",
      "600/600 - 14s - loss: 5.5479e-06 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/53RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  53\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.851875\n",
      "Confusion Matrix:\n",
      "[[241  51 108   0]\n",
      " [ 10 373  17   0]\n",
      " [ 13  37 350   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  54\n",
      "600/600 - 14s - loss: 4.1764e-06 - acc: 1.0000 - val_loss: 0.5652 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/54RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  54\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.8525\n",
      "Confusion Matrix:\n",
      "[[241  52 107   0]\n",
      " [ 10 373  17   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.81      0.93      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  55\n",
      "600/600 - 14s - loss: 3.1385e-06 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/55RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  55\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.851875\n",
      "Confusion Matrix:\n",
      "[[240  54 106   0]\n",
      " [ 10 373  17   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.81      0.93      0.86       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  56\n",
      "600/600 - 14s - loss: 2.3583e-06 - acc: 1.0000 - val_loss: 0.5925 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/56RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  56\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.853125\n",
      "Confusion Matrix:\n",
      "[[240  54 106   0]\n",
      " [ 10 375  15   0]\n",
      " [ 13  36 351   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.81      0.94      0.87       400\n",
      "           2       0.74      0.88      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  57\n",
      "600/600 - 14s - loss: 1.7687e-06 - acc: 1.0000 - val_loss: 0.6063 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/57RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  57\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.851875\n",
      "Confusion Matrix:\n",
      "[[239  55 106   0]\n",
      " [ 10 375  15   0]\n",
      " [ 13  37 350   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  58\n",
      "600/600 - 14s - loss: 1.3286e-06 - acc: 1.0000 - val_loss: 0.6207 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/58RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  58\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.851875\n",
      "Confusion Matrix:\n",
      "[[239  55 106   0]\n",
      " [ 10 375  15   0]\n",
      " [ 13  37 350   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  59\n",
      "600/600 - 14s - loss: 9.9912e-07 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.9013 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/59RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  59\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.851875\n",
      "Confusion Matrix:\n",
      "[[239  55 106   0]\n",
      " [ 10 375  15   0]\n",
      " [ 13  37 350   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.87       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  60\n",
      "600/600 - 14s - loss: 7.5144e-07 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.9019 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/60RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  60\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.850625\n",
      "Confusion Matrix:\n",
      "[[239  55 106   0]\n",
      " [ 11 374  15   0]\n",
      " [ 13  38 349   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.74      0.87      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  61\n",
      "600/600 - 14s - loss: 5.6639e-07 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.9006 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/61RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  61\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.850625\n",
      "Confusion Matrix:\n",
      "[[239  56 105   0]\n",
      " [ 11 374  15   0]\n",
      " [ 13  38 349   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.74      0.87      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  62\n",
      "600/600 - 14s - loss: 4.2786e-07 - acc: 1.0000 - val_loss: 0.6809 - val_acc: 0.8988 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/62RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  62\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85125\n",
      "Confusion Matrix:\n",
      "[[240  55 105   0]\n",
      " [ 11 374  15   0]\n",
      " [ 13  38 349   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.72       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.74      0.87      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  63\n",
      "600/600 - 14s - loss: 3.4677e-07 - acc: 1.0000 - val_loss: 0.6971 - val_acc: 0.9000 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/63RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  63\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.848125\n",
      "Confusion Matrix:\n",
      "[[235  56 109   0]\n",
      " [ 11 373  16   0]\n",
      " [ 13  37 350   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.59      0.71       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.74      0.88      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.84      1600\n",
      "weighted avg       0.86      0.85      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  64\n",
      "600/600 - 14s - loss: 0.2315 - acc: 0.9348 - val_loss: 0.3488 - val_acc: 0.8913 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/64RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  64\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.831875\n",
      "Confusion Matrix:\n",
      "[[218  89  93   0]\n",
      " [  7 381  12   0]\n",
      " [  6  49 345   0]\n",
      " [ 10   1   2 387]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.55      0.68       400\n",
      "           1       0.73      0.95      0.83       400\n",
      "           2       0.76      0.86      0.81       400\n",
      "           3       1.00      0.97      0.98       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.85      0.83      0.83      1600\n",
      "weighted avg       0.85      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  65\n",
      "600/600 - 13s - loss: 0.0500 - acc: 0.9833 - val_loss: 0.4506 - val_acc: 0.8769 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/65RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  65\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.856875\n",
      "Confusion Matrix:\n",
      "[[293  53  54   0]\n",
      " [ 23 367  10   0]\n",
      " [ 22  66 312   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       400\n",
      "           1       0.76      0.92      0.83       400\n",
      "           2       0.83      0.78      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.86      0.86      0.86      1600\n",
      "weighted avg       0.86      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  66\n",
      "600/600 - 14s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.9124 - val_acc: 0.7731 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/66RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  66\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.76375\n",
      "Confusion Matrix:\n",
      "[[256   5 114  25]\n",
      " [ 55 223  47  75]\n",
      " [ 15   1 343  41]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       400\n",
      "           1       0.97      0.56      0.71       400\n",
      "           2       0.68      0.86      0.76       400\n",
      "           3       0.74      1.00      0.85       400\n",
      "\n",
      "    accuracy                           0.76      1600\n",
      "   macro avg       0.79      0.76      0.76      1600\n",
      "weighted avg       0.79      0.76      0.76      1600\n",
      "\n",
      "\n",
      "Epoch:  67\n",
      "600/600 - 14s - loss: 0.0470 - acc: 0.9848 - val_loss: 0.9569 - val_acc: 0.7675 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/67RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  67\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.830625\n",
      "Confusion Matrix:\n",
      "[[312   9  50  29]\n",
      " [ 74 270  48   8]\n",
      " [ 36  12 347   5]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       400\n",
      "           1       0.93      0.68      0.78       400\n",
      "           2       0.78      0.87      0.82       400\n",
      "           3       0.90      1.00      0.95       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.84      0.83      0.83      1600\n",
      "weighted avg       0.84      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  68\n",
      "600/600 - 14s - loss: 0.0266 - acc: 0.9908 - val_loss: 0.4105 - val_acc: 0.8906 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/68RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  68\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85625\n",
      "Confusion Matrix:\n",
      "[[261  52  87   0]\n",
      " [ 22 358  20   0]\n",
      " [ 15  32 353   0]\n",
      " [  1   0   1 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.75       400\n",
      "           1       0.81      0.90      0.85       400\n",
      "           2       0.77      0.88      0.82       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.86      0.86      0.85      1600\n",
      "weighted avg       0.86      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  69\n",
      "600/600 - 14s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.5152 - val_acc: 0.8825 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/69RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  69\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.8675\n",
      "Confusion Matrix:\n",
      "[[284  31  85   0]\n",
      " [ 23 343  34   0]\n",
      " [ 16  19 365   0]\n",
      " [  2   0   2 396]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       400\n",
      "           1       0.87      0.86      0.87       400\n",
      "           2       0.75      0.91      0.82       400\n",
      "           3       1.00      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.87      0.87      0.87      1600\n",
      "weighted avg       0.87      0.87      0.87      1600\n",
      "\n",
      "\n",
      "Epoch:  70\n",
      "600/600 - 13s - loss: 0.0721 - acc: 0.9804 - val_loss: 0.5734 - val_acc: 0.8644 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/70RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  70\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.86125\n",
      "Confusion Matrix:\n",
      "[[313  53  34   0]\n",
      " [ 24 374   2   0]\n",
      " [ 40  67 293   0]\n",
      " [  2   0   0 398]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       400\n",
      "           1       0.76      0.94      0.84       400\n",
      "           2       0.89      0.73      0.80       400\n",
      "           3       1.00      0.99      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  71\n",
      "600/600 - 14s - loss: 0.0140 - acc: 0.9967 - val_loss: 0.5130 - val_acc: 0.8813 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/71RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  71\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.839375\n",
      "Confusion Matrix:\n",
      "[[250  86  64   0]\n",
      " [  4 388   8   0]\n",
      " [ 22  65 313   0]\n",
      " [  7   0   1 392]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73       400\n",
      "           1       0.72      0.97      0.83       400\n",
      "           2       0.81      0.78      0.80       400\n",
      "           3       1.00      0.98      0.99       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.85      0.84      0.84      1600\n",
      "weighted avg       0.85      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  72\n",
      "600/600 - 14s - loss: 0.0322 - acc: 0.9894 - val_loss: 0.4972 - val_acc: 0.8856 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/72RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  72\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.873125\n",
      "Confusion Matrix:\n",
      "[[299  18  83   0]\n",
      " [ 34 342  24   0]\n",
      " [ 24  19 357   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       400\n",
      "           1       0.90      0.85      0.88       400\n",
      "           2       0.77      0.89      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.87      1600\n",
      "   macro avg       0.88      0.87      0.87      1600\n",
      "weighted avg       0.88      0.87      0.87      1600\n",
      "\n",
      "\n",
      "Epoch:  73\n",
      "600/600 - 14s - loss: 0.0338 - acc: 0.9890 - val_loss: 1.1667 - val_acc: 0.7212 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/73RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  73\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 15ms/step\n",
      "Accuracy: 0.74125\n",
      "Confusion Matrix:\n",
      "[[114  28 108 150]\n",
      " [ 20 314  55  11]\n",
      " [  6  20 358  16]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.28      0.42       400\n",
      "           1       0.87      0.79      0.82       400\n",
      "           2       0.69      0.90      0.78       400\n",
      "           3       0.69      1.00      0.82       400\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.77      0.74      0.71      1600\n",
      "weighted avg       0.77      0.74      0.71      1600\n",
      "\n",
      "\n",
      "Epoch:  74\n",
      "600/600 - 14s - loss: 0.0142 - acc: 0.9954 - val_loss: 0.5275 - val_acc: 0.8906 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/74RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  74\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.81875\n",
      "Confusion Matrix:\n",
      "[[202  65 133   0]\n",
      " [  7 385   8   0]\n",
      " [  6  58 336   0]\n",
      " [  8   0   5 387]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.51      0.65       400\n",
      "           1       0.76      0.96      0.85       400\n",
      "           2       0.70      0.84      0.76       400\n",
      "           3       1.00      0.97      0.98       400\n",
      "\n",
      "    accuracy                           0.82      1600\n",
      "   macro avg       0.84      0.82      0.81      1600\n",
      "weighted avg       0.84      0.82      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  75\n",
      "600/600 - 14s - loss: 0.0150 - acc: 0.9944 - val_loss: 2.3499 - val_acc: 0.7088 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/75RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  75\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.69625\n",
      "Confusion Matrix:\n",
      "[[276   0 124   0]\n",
      " [110  65 225   0]\n",
      " [ 10   0 390   0]\n",
      " [  9   0   8 383]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       400\n",
      "           1       1.00      0.16      0.28       400\n",
      "           2       0.52      0.97      0.68       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.80      0.70      0.66      1600\n",
      "weighted avg       0.80      0.70      0.66      1600\n",
      "\n",
      "\n",
      "Epoch:  76\n",
      "600/600 - 14s - loss: 0.0469 - acc: 0.9831 - val_loss: 0.6642 - val_acc: 0.8331 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/76RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  76\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.805625\n",
      "Confusion Matrix:\n",
      "[[247 130  22   1]\n",
      " [  8 390   2   0]\n",
      " [ 21 127 252   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73       400\n",
      "           1       0.60      0.97      0.74       400\n",
      "           2       0.91      0.63      0.75       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.85      0.81      0.81      1600\n",
      "weighted avg       0.85      0.81      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  77\n",
      "600/600 - 14s - loss: 0.0096 - acc: 0.9973 - val_loss: 0.4447 - val_acc: 0.8881 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/77RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  77\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.84125\n",
      "Confusion Matrix:\n",
      "[[242 110  48   0]\n",
      " [  6 390   4   0]\n",
      " [ 18  67 315   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.60      0.73       400\n",
      "           1       0.69      0.97      0.81       400\n",
      "           2       0.86      0.79      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  78\n",
      "600/600 - 14s - loss: 0.0110 - acc: 0.9969 - val_loss: 0.5012 - val_acc: 0.8900 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/78RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  78\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.855\n",
      "Confusion Matrix:\n",
      "[[276  21 103   0]\n",
      " [ 21 356  23   0]\n",
      " [ 12  40 348   0]\n",
      " [ 10   0   2 388]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       400\n",
      "           1       0.85      0.89      0.87       400\n",
      "           2       0.73      0.87      0.79       400\n",
      "           3       1.00      0.97      0.98       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  79\n",
      "600/600 - 14s - loss: 0.0461 - acc: 0.9829 - val_loss: 0.6633 - val_acc: 0.8500 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/79RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  79\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.854375\n",
      "Confusion Matrix:\n",
      "[[317  58  24   1]\n",
      " [ 39 359   2   0]\n",
      " [ 33  76 291   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       400\n",
      "           1       0.73      0.90      0.80       400\n",
      "           2       0.92      0.73      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.85      1600\n",
      "weighted avg       0.86      0.85      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  80\n",
      "600/600 - 14s - loss: 0.0140 - acc: 0.9956 - val_loss: 0.5129 - val_acc: 0.8875 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/80RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  80\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.841875\n",
      "Confusion Matrix:\n",
      "[[230  29 141   0]\n",
      " [ 19 344  37   0]\n",
      " [  4  22 373   1]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.57      0.70       400\n",
      "           1       0.87      0.86      0.87       400\n",
      "           2       0.68      0.93      0.78       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  81\n",
      "600/600 - 14s - loss: 0.0093 - acc: 0.9969 - val_loss: 0.5543 - val_acc: 0.8712 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/81RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  81\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.834375\n",
      "Confusion Matrix:\n",
      "[[239 115  46   0]\n",
      " [ 11 387   2   0]\n",
      " [ 15  75 310   0]\n",
      " [  1   0   0 399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72       400\n",
      "           1       0.67      0.97      0.79       400\n",
      "           2       0.87      0.78      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.86      0.83      0.83      1600\n",
      "weighted avg       0.86      0.83      0.83      1600\n",
      "\n",
      "\n",
      "Epoch:  82\n",
      "600/600 - 14s - loss: 0.0081 - acc: 0.9981 - val_loss: 0.5274 - val_acc: 0.8869 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/82RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  82\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.844375\n",
      "Confusion Matrix:\n",
      "[[220  53 127   0]\n",
      " [ 15 364  21   0]\n",
      " [  5  28 367   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.55      0.69       400\n",
      "           1       0.82      0.91      0.86       400\n",
      "           2       0.71      0.92      0.80       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.86      0.84      0.84      1600\n",
      "weighted avg       0.86      0.84      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  83\n",
      "600/600 - 14s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.7910 - val_acc: 0.8288 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/83RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  83\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.790625\n",
      "Confusion Matrix:\n",
      "[[197 162  41   0]\n",
      " [  2 397   1   0]\n",
      " [ 10 102 288   0]\n",
      " [  9   3   5 383]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.49      0.64       400\n",
      "           1       0.60      0.99      0.75       400\n",
      "           2       0.86      0.72      0.78       400\n",
      "           3       1.00      0.96      0.98       400\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.84      0.79      0.79      1600\n",
      "weighted avg       0.84      0.79      0.79      1600\n",
      "\n",
      "\n",
      "Epoch:  84\n",
      "600/600 - 14s - loss: 0.0557 - acc: 0.9833 - val_loss: 1.7645 - val_acc: 0.6731 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/84RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  84\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.7325\n",
      "Confusion Matrix:\n",
      "[[224  12  18 146]\n",
      " [132 237  17  14]\n",
      " [ 40  24 311  25]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.56       400\n",
      "           1       0.87      0.59      0.70       400\n",
      "           2       0.90      0.78      0.83       400\n",
      "           3       0.68      1.00      0.81       400\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.75      0.73      0.73      1600\n",
      "weighted avg       0.75      0.73      0.73      1600\n",
      "\n",
      "\n",
      "Epoch:  85\n",
      "600/600 - 14s - loss: 0.0328 - acc: 0.9894 - val_loss: 0.4980 - val_acc: 0.8819 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/85RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  85\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.815\n",
      "Confusion Matrix:\n",
      "[[193  98 109   0]\n",
      " [  7 386   7   0]\n",
      " [  4  71 325   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.48      0.64       400\n",
      "           1       0.70      0.96      0.81       400\n",
      "           2       0.74      0.81      0.77       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.84      0.81      0.81      1600\n",
      "weighted avg       0.84      0.81      0.81      1600\n",
      "\n",
      "\n",
      "Epoch:  86\n",
      "600/600 - 14s - loss: 0.0030 - acc: 0.9996 - val_loss: 0.4179 - val_acc: 0.9038 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/86RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  86\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.846875\n",
      "Confusion Matrix:\n",
      "[[233  79  88   0]\n",
      " [  7 381  12   0]\n",
      " [ 10  49 341   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.72       400\n",
      "           1       0.75      0.95      0.84       400\n",
      "           2       0.77      0.85      0.81       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.85      0.84      1600\n",
      "weighted avg       0.86      0.85      0.84      1600\n",
      "\n",
      "\n",
      "Epoch:  87\n",
      "600/600 - 14s - loss: 4.4216e-04 - acc: 1.0000 - val_loss: 0.4076 - val_acc: 0.9075 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/87RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  87\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85875\n",
      "Confusion Matrix:\n",
      "[[244  62  94   0]\n",
      " [  9 370  21   0]\n",
      " [ 10  30 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.76      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  88\n",
      "600/600 - 13s - loss: 2.2791e-04 - acc: 1.0000 - val_loss: 0.4151 - val_acc: 0.9100 - 13s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/88RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  88\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.85875\n",
      "Confusion Matrix:\n",
      "[[244  62  94   0]\n",
      " [  9 370  21   0]\n",
      " [ 10  30 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.76      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  89\n",
      "600/600 - 14s - loss: 1.6206e-04 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.9100 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/89RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  89\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.85875\n",
      "Confusion Matrix:\n",
      "[[243  62  95   0]\n",
      " [  9 372  19   0]\n",
      " [ 10  31 359   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.73       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.76      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  90\n",
      "600/600 - 14s - loss: 1.2015e-04 - acc: 1.0000 - val_loss: 0.4330 - val_acc: 0.9112 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/90RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  90\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[243  62  95   0]\n",
      " [  9 373  18   0]\n",
      " [ 10  31 359   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.73       400\n",
      "           1       0.80      0.93      0.86       400\n",
      "           2       0.76      0.90      0.82       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  91\n",
      "600/600 - 14s - loss: 9.0262e-05 - acc: 1.0000 - val_loss: 0.4425 - val_acc: 0.9119 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/91RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  91\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[242  63  95   0]\n",
      " [  9 374  17   0]\n",
      " [  9  31 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  92\n",
      "600/600 - 14s - loss: 6.8236e-05 - acc: 1.0000 - val_loss: 0.4524 - val_acc: 0.9106 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/92RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  92\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.860625\n",
      "Confusion Matrix:\n",
      "[[242  63  95   0]\n",
      " [  9 375  16   0]\n",
      " [  9  31 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  93\n",
      "600/600 - 14s - loss: 5.1713e-05 - acc: 1.0000 - val_loss: 0.4627 - val_acc: 0.9106 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/93RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  93\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.860625\n",
      "Confusion Matrix:\n",
      "[[241  64  95   0]\n",
      " [  8 376  16   0]\n",
      " [  9  31 360   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.86      1600\n",
      "weighted avg       0.87      0.86      0.86      1600\n",
      "\n",
      "\n",
      "Epoch:  94\n",
      "600/600 - 14s - loss: 3.9148e-05 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.9100 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/94RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  94\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[239  64  97   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  95\n",
      "600/600 - 14s - loss: 2.9591e-05 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.9100 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/95RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  95\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[238  67  95   0]\n",
      " [  8 376  16   0]\n",
      " [  9  29 362   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.77      0.91      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  96\n",
      "600/600 - 14s - loss: 2.2307e-05 - acc: 1.0000 - val_loss: 0.4955 - val_acc: 0.9100 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/96RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  96\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.859375\n",
      "Confusion Matrix:\n",
      "[[238  67  95   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.73       400\n",
      "           1       0.79      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  97\n",
      "600/600 - 14s - loss: 1.6773e-05 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.9100 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/97RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  97\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[239  66  95   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       400\n",
      "           1       0.80      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  98\n",
      "600/600 - 14s - loss: 1.2578e-05 - acc: 1.0000 - val_loss: 0.5192 - val_acc: 0.9087 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/98RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  98\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.85875\n",
      "Confusion Matrix:\n",
      "[[237  67  96   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72       400\n",
      "           1       0.79      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  99\n",
      "600/600 - 14s - loss: 9.4226e-06 - acc: 1.0000 - val_loss: 0.5315 - val_acc: 0.9081 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/99RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  99\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 13ms/step\n",
      "Accuracy: 0.858125\n",
      "Confusion Matrix:\n",
      "[[236  68  96   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72       400\n",
      "           1       0.79      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "\n",
      "Epoch:  100\n",
      "600/600 - 14s - loss: 7.0553e-06 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.9081 - 14s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./RNmodels/100RN__IC_01200_FilledArea_0.9_BandNo_60_ImageHeight_30_ImageWidth_30_FILTER_snv_FeatureExtraction_none/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved on epoch:  100\n",
      "added to csv\n",
      "50/50 [==============================] - 1s 12ms/step\n",
      "Accuracy: 0.856875\n",
      "Confusion Matrix:\n",
      "[[234  69  97   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.72       400\n",
      "           1       0.79      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n",
      "Testing time (s) = 2933.324796756031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "tic = start_timer()\n",
    "while start_epoch<=last_epoch:\n",
    "    print(\"\\nEpoch: \",start_epoch)\n",
    "    history = model.fit(x_training, labels_training, batch_size=batch_size, epochs = 1, validation_data=(x_val_norm, y_val), verbose=2)\n",
    "    model.save('./RNmodels/'+str(start_epoch)+model_name)\n",
    "    print(\"Model saved on epoch: \",start_epoch)\n",
    "    \n",
    "    history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    save_to_csv('./csvs/'+model_name+'.csv', history_dataframe, header=True)\n",
    "    print(\"added to csv\")\n",
    "    \n",
    "    y_pred = model.predict(test_dataset)\n",
    "\n",
    "    y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_dataset_label, y_pred_label))\n",
    "    start_epoch+=1\n",
    "    \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d4ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 14ms/step\n",
      "Accuracy: 0.856875\n",
      "Confusion Matrix:\n",
      "[[234  69  97   0]\n",
      " [  8 376  16   0]\n",
      " [  9  30 361   0]\n",
      " [  0   0   0 400]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.72       400\n",
      "           1       0.79      0.94      0.86       400\n",
      "           2       0.76      0.90      0.83       400\n",
      "           3       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           0.86      1600\n",
      "   macro avg       0.87      0.86      0.85      1600\n",
      "weighted avg       0.87      0.86      0.85      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_dataset_label, y_pred_label)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_dataset_label, y_pred_label)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_dataset_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06167d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm,index =[i for i in VARIETIES],columns=[i for i in VARIETIES])\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},fmt='.0f') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af1a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwheatenv",
   "language": "python",
   "name": "dwheatenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
